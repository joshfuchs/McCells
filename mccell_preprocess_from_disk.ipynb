{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e960408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import cellxgene_census\n",
    "\n",
    "import pronto\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pronto.warnings.ProntoWarning)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import copy\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from torcheval.metrics.functional import multilabel_accuracy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b883e3",
   "metadata": {},
   "source": [
    "## Load Cell MetatData from the Census. \n",
    "\n",
    "Great-lakes does not have internet access, so we pull in the data outside first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fc4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene and cell type info stored on Turbo\n",
    "os.chdir('/nfs/turbo/umms-welchjd/mccell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a235181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gene list\n",
    "biomart = pd.read_csv('mart_export.txt')\n",
    "\n",
    "coding_only = biomart[biomart['Gene type'] == 'protein_coding']\n",
    "\n",
    "gene_list = coding_only['Gene stable ID'].to_list()\n",
    "\n",
    "var_val_filter = '''feature_id in {}'''.format(gene_list)\n",
    "\n",
    "# load the cell type list\n",
    "cell_type_list_name = 'cell_type_list.txt'\n",
    "with open(cell_type_list_name,'rb') as fp:\n",
    "    cell_type_list = pickle.load(fp)\n",
    "\n",
    "obs_val_filter = '''assay == \"10x 3\\' v3\" and is_primary_data == True and cell_type_ontology_term_id in {}'''.format(cell_type_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a2a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "census = cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c9d9e",
   "metadata": {},
   "source": [
    "Now, get the metadata for our search. We can then use this to preprocess everything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c8d948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = ['cell_type_ontology_term_id']\n",
    "\n",
    "\n",
    "cell_obs_metadata = (\n",
    "    census[\"census_data\"][\"homo_sapiens\"].obs.read(value_filter = obs_val_filter,\n",
    "                                                   column_names=target_column).concat().to_pandas()\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7fbaecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type_ontology_term_id</th>\n",
       "      <th>assay</th>\n",
       "      <th>is_primary_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CL:0000763</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CL:0000763</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CL:0000763</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CL:0000763</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CL:0000542</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726024</th>\n",
       "      <td>CL:0000860</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726025</th>\n",
       "      <td>CL:0000860</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726026</th>\n",
       "      <td>CL:0000860</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726027</th>\n",
       "      <td>CL:0000940</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726028</th>\n",
       "      <td>CL:0000623</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2726029 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cell_type_ontology_term_id      assay  is_primary_data\n",
       "0                       CL:0000763  10x 3' v3             True\n",
       "1                       CL:0000763  10x 3' v3             True\n",
       "2                       CL:0000763  10x 3' v3             True\n",
       "3                       CL:0000763  10x 3' v3             True\n",
       "4                       CL:0000542  10x 3' v3             True\n",
       "...                            ...        ...              ...\n",
       "2726024                 CL:0000860  10x 3' v3             True\n",
       "2726025                 CL:0000860  10x 3' v3             True\n",
       "2726026                 CL:0000860  10x 3' v3             True\n",
       "2726027                 CL:0000940  10x 3' v3             True\n",
       "2726028                 CL:0000623  10x 3' v3             True\n",
       "\n",
       "[2726029 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_obs_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e81be",
   "metadata": {},
   "source": [
    "## Load the Cell Ontology\n",
    "\n",
    "The Cell Ontology also needs to be loaded for access. \n",
    "\n",
    "You can visualize the ontology using https://www.ebi.ac.uk/ols4/ontologies/cl\n",
    "\n",
    "And you can download the ontology file here: https://obofoundry.org/ontology/cl.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1d4e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/scratch/welchjd_root/welchjd99/fujoshua')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6015ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = pronto.Ontology.from_obo_library('cl.owl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a5a4e",
   "metadata": {},
   "source": [
    "## Data and Ontology Preprocessing\n",
    "\n",
    "To prepare the data for modeling, we need to perform some preprocessing on the data and the ontology. We'll use three functions to make this happen. Full descriptions of these functions can be found in the functions. \n",
    "\n",
    "\n",
    "- set_internal_node_values: build a dictionary to set which internal nodes are to be used in the loss calculation for internal nodes in the data\n",
    "\n",
    "- build_parent_mask: builds a masking matrix to use for masking internal node loss values\n",
    "\n",
    "- preprocess_data_ontology: this function encodes the AnnData object, splits apart the target values and primary data, and calculates some important variables from the Cell Ontology for later use \n",
    "\n",
    "- transform_data: transforms the data with log(1+x)\n",
    "\n",
    "- split_format_data: splits the data into train and validation sets, and moves the variables to PyTorch tensors \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ed19f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_internal_node_values(internal_values,all_parent_nodes):\n",
    "    '''\n",
    "    Creates a dictionary where each key is an internal cell type and the values are the cell types\n",
    "    we want to include when calculating the loss. We do not want to consider direct descendents of the\n",
    "    internal cell type, so those are removed. \n",
    "    \n",
    "    In other words, when calculating the loss for an internal node, we want to include all internal \n",
    "    nodes in the ontology EXCEPT those that are direct descendants of the target internal node. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    internal_values : list\n",
    "        list of internal values that are included in the dataset\n",
    "            \n",
    "    all_parent_nodes : list\n",
    "        from the dataset, a list of parent nodes in the ontology. Used to remove portions of\n",
    "        the Ontology where we do not have child data\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    parent_dict : dictionary\n",
    "        keys are internal_values and values are all internal cell ontology terms EXCEPT descendents \n",
    "        of the internal value. The internal value is always included\n",
    "    '''\n",
    "    \n",
    "    parent_dict = {}\n",
    "\n",
    "    # loop through each value to calculate the values to include in parent_dict for that\n",
    "    # internal value\n",
    "    for internal_node in internal_values:\n",
    "        # 1) get the children of this internal_node\n",
    "        child_nodes = []\n",
    "        for term in cl[internal_node].subclasses(distance=None,with_self=False).to_set():\n",
    "            child_nodes.append(term.id)\n",
    "        \n",
    "        # 2) remove those values from all_parent_nodes\n",
    "        cell_types_to_include = [x for x in all_parent_nodes if x not in child_nodes]\n",
    "        \n",
    "        # 3) create dictionary\n",
    "        parent_dict[internal_node] = cell_types_to_include\n",
    "    \n",
    "    return(parent_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22715b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parent_mask(leaf_values,internal_values,ontology_df,parent_dict):\n",
    "    '''\n",
    "    Function to build a masking matrix for use when calculating the internal loss\n",
    "    \n",
    "    Uses parent_dict to denote, for internal cell types, which parents to include in the loss\n",
    "    calculation. \n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    leaf_values : list\n",
    "        list composed of all leaf values included in the dataset\n",
    "        includes internal nodes that do not have sub-values in the dataset, and thus are\n",
    "        treated an leaf nodes\n",
    "\n",
    "    internal_values : list\n",
    "        list composed of interanal nodes in the dataset\n",
    "\n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where indices (rows) are all leaf and parent cell IDs from the portion of \n",
    "        the ontology being queried, and columns are all leafs in portion of ontology being queried. \n",
    "        \n",
    "        Dataframe is binary. For each parent node, element = 1 if parent node is an ancestor\n",
    "        of corresponding leaf node.\n",
    "        \n",
    "    parent_dict : dictionary\n",
    "        keys are internal_values and values are all internal cell ontology terms EXCEPT descendents \n",
    "        of the internal value. The internal value is always included\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cell_parents_mask : tensor\n",
    "        tensor of shape ik, where i = parent IDs and k = each cell type in the dataset\n",
    "        binary tensor where 1 means for that cell type, that parent ID will be included\n",
    "        in the internal loss calculation\n",
    "        and 0 means for that cell type, that parent ID is excluded in the internal loss\n",
    "        calculation\n",
    "    \n",
    "    '''\n",
    "    num_leafs = len(leaf_values)\n",
    "    num_parents = ontology_df.shape[0]\n",
    "\n",
    "    # internal_values are included as column values AND rows\n",
    "\n",
    "\n",
    "    # for cell_parents_to_include, each column is a cell type included in the\n",
    "    # dataset, so it is length = len(leaf_values) + len(internal_values)\n",
    "    # the row values are the total number of parents included for the dataset \n",
    "    # for each internal value, we need to pick (1/0) if we include that parent\n",
    "    # for the loss. For this, we reference parents_dict\n",
    "    # WHAT is the order of the cell IDs for the rows???? This is important\n",
    "    # This needs to match what we are already doing later, so let's go figure that out FIRST. \n",
    "\n",
    "    # for the leaf values, we want to include ALL parents in the \n",
    "    # loss calculation. So, we initialize the tensor as a ones tensor\n",
    "    # based on the number of leaf values and the number of parents\n",
    "    cell_parents_mask = torch.ones(num_parents,num_leafs)\n",
    "\n",
    "    # now we can deal with the internal values. For these, we will not\n",
    "    # include all parents. We will use parent_dict to select which to include\n",
    "\n",
    "\n",
    "    # first, get a list of all the parents. The ordering of this list\n",
    "    # is used later to propogate probabilities up the ontology.\n",
    "    list_of_parents = ontology_df.index.tolist()\n",
    "\n",
    "    # now, we need to loop through each internal value\n",
    "    # internal_values is ordered as -9999 + n\n",
    "    # this will be helpful later when we need to pull these values out. \n",
    "    # so the columns here are ordered at 0 to (number of leaf values), then -9999\n",
    "    # to (number of internal values)\n",
    "\n",
    "    for cell_id in internal_values:\n",
    "        # get the list of parent cell IDs we want to include for this\n",
    "        # particular internal_values\n",
    "        parent_list_for_cell = parent_dict[cell_id]\n",
    "\n",
    "        # loop through the parent_list_for cell, create a new binary list where\n",
    "        # list is 1 if the parent is in the list_of_parents, otherwise 0\n",
    "        parent_binary_list = [1 if parent in parent_list_for_cell else 0 for parent in list_of_parents]\n",
    "\n",
    "        # convert the list to a tensor and reshape for concatenation\n",
    "        parent_binary_tensor = torch.tensor(parent_binary_list).reshape(-1,1)\n",
    "\n",
    "        # append to cell_parents_to_include. \n",
    "        # we append along columns\n",
    "        cell_parents_mask = torch.cat((cell_parents_mask,parent_binary_tensor),1)\n",
    "\n",
    "    return(cell_parents_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3a45b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_ontology(obs_metadata, target_column,upper_limit = None, cl_only = False, include_leafs = False):\n",
    "    '''\n",
    "    This function perfroms preprocessing on ann AnnData object to prepare it for modelling. It will encode the \n",
    "    target column and returns x_data and y_data for modelling\n",
    "    \n",
    "    This function also preprocesses the ontology to build a pandas dataframe that can be used to \n",
    "    calculate predicted probabilities. This will enable simple matrix multiplication to calculate\n",
    "    probabilities and loss.\n",
    "    \n",
    "    Can have an upper limit to the ontology if upper_limit is set\n",
    "    \n",
    "    \n",
    "    Assumes there is an active census object already open as cl. \n",
    "\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cell_obs_metadata : Pandas DataFrame\n",
    "        DataFrame from census.obs.read() \n",
    "        \n",
    "    target_column : string\n",
    "        string of target column (from cell metadata) to encode\n",
    "     \n",
    "    upper_limit : string\n",
    "        if you want to specify an upper limit in the ontology, set this to \n",
    "        the upper limit (inclusive)\n",
    "        Default: None (no limit to ontology)\n",
    "        \n",
    "    cl_only : boolean\n",
    "        option to only include the Cell Ontology (CL) in the dataframe\n",
    "        True means only those cell IDs that start with CL are included\n",
    "        Default: False\n",
    "        \n",
    "    include_leafs : boolean\n",
    "        option to include leafs in the list of parent cell IDs\n",
    "        Default is False because we are calculating the leaf loss differently\n",
    "        Default: False\n",
    "        \n",
    "    Returns\n",
    "    -------        \n",
    "    mapping_dict : Dictionary\n",
    "        dictionary mapping the Cell Ontology IDs (keys) to the encoded values (values)\n",
    "        Values >= 0 are leaf nodes\n",
    "        Values < 0 are internal nodes\n",
    "\n",
    "    leaf_values : list\n",
    "        list composed of all leaf values included in the dataset\n",
    "        includes internal nodes that do not have sub-values in the dataset, and thus are\n",
    "        treated an leaf nodes\n",
    "\n",
    "    internal_values : list\n",
    "        list composed of interanal nodes in the dataset\n",
    "\n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where indices (rows) are all leaf and parent cell IDs from the portion of \n",
    "        the ontology being queried, and columns are all leafs in portion of ontology being queried. \n",
    "        \n",
    "        Dataframe is binary. For each parent node, element = 1 if parent node is an ancestor\n",
    "        of corresponding leaf node.\n",
    "        \n",
    "    parent_dict : dictionary\n",
    "        keys are internal_values and values are all cell ontology terms within the same distance\n",
    "        from the top node. \n",
    "        \n",
    "    cell_parent_mask : tensor\n",
    "        tensor of shape ik, where i = parent IDs and k = each cell type in the dataset\n",
    "        binary tensor where 1 means for that cell type, that parent ID will be included\n",
    "        in the internal loss calculation\n",
    "        and 0 means for that cell type, that parent ID is excluded in the internal loss\n",
    "        calculation\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # select the labels. \n",
    "    labels = obs_metadata[target_column]\n",
    "    \n",
    "    # encode the target column\n",
    "    #lb = LabelEncoder()\n",
    "    #labels['encoded_labels'] = lb.fit_transform(labels[target_column])\n",
    "    \n",
    "    # we want to only encode the targets that are leafs. We will leave \n",
    "    # internal nodes as the CL number in order to assist with masking \n",
    "    # the appropriate parent nodes \n",
    "    # first, get list of all cell values\n",
    "    all_cell_values = labels[target_column].unique().to_list()\n",
    "    \n",
    "    # identify which values are leafs\n",
    "    # we use positive number for leaf values\n",
    "    # and negative number for internal nodes\n",
    "    mapping_dict = {}\n",
    "    leaf_values = []\n",
    "    internal_values = []\n",
    "    encoded_leaf_val = 0\n",
    "    encoded_internal_val = -9999\n",
    "    for term in all_cell_values:\n",
    "        if cl[term].is_leaf():\n",
    "            mapping_dict[term] = encoded_leaf_val\n",
    "            leaf_values.append(term)\n",
    "            encoded_leaf_val += 1\n",
    "        else:\n",
    "            # check if internal values have associated sub-values in the dataset\n",
    "            #    sub-values do not have to be leafs\n",
    "            # if so, add value as internal values\n",
    "            # if not, prune ontology so consider \n",
    "            term_subvalues = []\n",
    "            # get leaf values of this term\n",
    "            for sub_term in cl[term].subclasses(distance=None,with_self=False).to_set():\n",
    "                    term_subvalues.append(sub_term.id)\n",
    "            \n",
    "            # get values in all_call_values in term_leafs\n",
    "            intersection_list = list(set(all_cell_values).intersection(term_subvalues))\n",
    "            if len(intersection_list) == 0:\n",
    "                mapping_dict[term] = encoded_leaf_val\n",
    "                leaf_values.append(term)\n",
    "                encoded_leaf_val += 1\n",
    "            else:\n",
    "                mapping_dict[term] = encoded_internal_val\n",
    "                internal_values.append(term)\n",
    "                encoded_internal_val += 1            \n",
    "            \n",
    "            \n",
    "    # use the leaf_mapping_dict to \n",
    "    labels['encoded_labels'] = labels[target_column].map(mapping_dict)\n",
    "    \n",
    "    x_data = adata.X.copy()\n",
    "    y_data = labels['encoded_labels']\n",
    "    \n",
    "    #########\n",
    "    # now get a list of all parent nodes for each value in the dataset\n",
    "    # if we want to include leafs, set with_self= True\n",
    "    # else, set with_self = False\n",
    "    \n",
    "    all_parent_nodes = []\n",
    "    for target in all_cell_values:\n",
    "        for term in cl[target].superclasses(distance=None,with_self=include_leafs).to_set():\n",
    "            all_parent_nodes.append(term.id)\n",
    "            #if target == 'CL:0000904':\n",
    "            #    print(term)\n",
    "            \n",
    "    # ensure that we do not have duplicate values\n",
    "    all_parent_nodes = list(set(all_parent_nodes))\n",
    "\n",
    "    # select only the Cell Ontology IDs if cl_only = True\n",
    "    if cl_only:\n",
    "        all_parent_nodes = [x for x in all_parent_nodes if x.startswith('CL')]\n",
    "    \n",
    "    # if there is an upper limit, \n",
    "    if upper_limit is not None:\n",
    "        # get upper limit nodes\n",
    "        upper_limit_nodes = []\n",
    "        for term in cl[upper_limit].superclasses(distance=None,with_self=False).to_set():\n",
    "            upper_limit_nodes.append(term.id)\n",
    "\n",
    "        # remove these nodes from the parent_nodes list\n",
    "        all_parent_nodes = [x for x in all_parent_nodes if x not in upper_limit_nodes]\n",
    "        \n",
    "    # create a dictionary that maps parents to reduce the ontology_df when\n",
    "    # dealing with internal nodes\n",
    "    #parent_dict = set_internal_node_relationships_by_depth(internal_values,upper_limit,all_parent_nodes)\n",
    "    parent_dict = set_internal_node_values(internal_values,all_parent_nodes)\n",
    "    \n",
    "    # create the dataframe\n",
    "    # use all_cell_values for the columns, because we need both leafs and\n",
    "    # internals nodes for mapping\n",
    "    ontology_df = pd.DataFrame(data=0, index = all_parent_nodes,\n",
    "                                              columns = all_cell_values)\n",
    "    \n",
    "    # populate the dataframe with 1 if column is a sub-node \n",
    "    # for that particular cell ID\n",
    "    # with_self = True because we need to include the leafs here\n",
    "    for cell_id in ontology_df.index:\n",
    "        for term in cl[cell_id].subclasses(distance=None,with_self=True).to_set():\n",
    "            if term.id in ontology_df.columns:\n",
    "                ontology_df.loc[cell_id,[term.id]] = [1]\n",
    "\n",
    "    # create a dictionary that maps parents to reduce the ontology_df when\n",
    "    # dealing with internal nodes\n",
    "    #parent_dict = {}\n",
    "    #for parent in internal_values:\n",
    "    #    super_parent_list = []\n",
    "    #    for term in cl[parent].superclasses(distance=None,with_self=True).to_set():\n",
    "    #         if term.id in all_parent_nodes:\n",
    "    #            super_parent_list.append(term.id)\n",
    "    #    parent_dict[parent] = super_parent_list\n",
    "\n",
    "    # build a matrix used to mask parent values\n",
    "    cell_parent_mask = build_parent_mask(leaf_values,internal_values,ontology_df,parent_dict)\n",
    "    \n",
    "    return(mapping_dict, leaf_values, internal_values, ontology_df, parent_dict, cell_parent_mask)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bb613d",
   "metadata": {},
   "source": [
    "## Main Loop For Preprocessing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38aac839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          CL:0000763\n",
       "1          CL:0000763\n",
       "2          CL:0000763\n",
       "3          CL:0000763\n",
       "4          CL:0000542\n",
       "              ...    \n",
       "2726024    CL:0000860\n",
       "2726025    CL:0000860\n",
       "2726026    CL:0000860\n",
       "2726027    CL:0000940\n",
       "2726028    CL:0000623\n",
       "Name: cell_type_ontology_term_id, Length: 2726029, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_obs_metadata[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36351857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcd264a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start preprocess data and ontology\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cell_type_ontology_term_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m upper_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCL:0000988\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# leukocyte = 738, hematopoietic = 988\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart preprocess data and ontology\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m mapping_dict, leaf_values,internal_values, \\\n\u001b[0;32m----> 7\u001b[0m     ontology_df, parent_dict, cell_parent_mask \u001b[38;5;241m=\u001b[39m  \u001b[43mpreprocess_data_ontology\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_obs_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                                           \u001b[49m\u001b[43mupper_limit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mupper_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mcl_only\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_leafs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m###del adata\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# create dataframe that only includes leaf nodes\u001b[39;00m\n\u001b[1;32m     14\u001b[0m ontology_leaf_df \u001b[38;5;241m=\u001b[39m ontology_df[leaf_values]\n",
      "Cell \u001b[0;32mIn[26], line 87\u001b[0m, in \u001b[0;36mpreprocess_data_ontology\u001b[0;34m(obs_metadata, target_column, upper_limit, cl_only, include_leafs)\u001b[0m\n\u001b[1;32m     77\u001b[0m labels \u001b[38;5;241m=\u001b[39m obs_metadata[target_column]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# encode the target column\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m#lb = LabelEncoder()\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#labels['encoded_labels'] = lb.fit_transform(labels[target_column])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# the appropriate parent nodes \u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# first, get list of all cell values\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m all_cell_values \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# identify which values are leafs\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# we use positive number for leaf values\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# and negative number for internal nodes\u001b[39;00m\n\u001b[1;32m     92\u001b[0m mapping_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/core/indexes/range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cell_type_ontology_term_id'"
     ]
    }
   ],
   "source": [
    "target_column = 'cell_type_ontology_term_id'\n",
    "\n",
    "upper_limit = 'CL:0000988' # leukocyte = 738, hematopoietic = 988\n",
    "\n",
    "print('start preprocess data and ontology')\n",
    "mapping_dict, leaf_values,internal_values, \\\n",
    "    ontology_df, parent_dict, cell_parent_mask =  preprocess_data_ontology(cell_obs_metadata, target_column,\n",
    "                                                                           upper_limit = upper_limit, \n",
    "                                                                 cl_only = True, include_leafs = False)\n",
    "\n",
    "###del adata\n",
    "\n",
    "# create dataframe that only includes leaf nodes\n",
    "ontology_leaf_df = ontology_df[leaf_values]\n",
    "\n",
    "\n",
    "print('Preprocessing complete. There are {0} leaf values and {1} internal values.'.format(len(leaf_values),len(internal_values)\n",
    "                                                                                         ))\n",
    "print('There are {0} cells in the training set and {1} cells in the validation set, both contain {2} genes.'.format(X_train.shape[0],X_val.shape[0],X_train.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270f11e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
