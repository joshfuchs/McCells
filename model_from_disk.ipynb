{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf4e25ff",
   "metadata": {},
   "source": [
    "Tutorial from https://chanzuckerberg.github.io/cellxgene-census/notebooks/experimental/pytorch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b822fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellxgene_census\n",
    "import cellxgene_census.experimental.ml as census_ml\n",
    "import tiledbsoma as soma\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9355266f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellxgene_census.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e491b4",
   "metadata": {},
   "source": [
    "## Load the Saved Outputs from McCell_preprocessing\n",
    "\n",
    "# Are any of these dependent on the order of the X data in the preprocessing. If so, we would want to be careful\n",
    "\n",
    "- cell_parent_mask\n",
    "- Mapping_dict\n",
    "- Ontology_df\n",
    "- Internal_values\n",
    "- leaf_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6c952ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the date in yyyy-mm-dd format\n",
    "date = '2024-02-22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea04d7b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2024-02-22_ontology_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ontology_df_name \u001b[38;5;241m=\u001b[39m date \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_ontology_df.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m ontology_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43montology_df_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m mapping_dict_name \u001b[38;5;241m=\u001b[39m date \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mapping_dict_df.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m mapping_dict_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(mapping_dict_name,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2024-02-22_ontology_df.csv'"
     ]
    }
   ],
   "source": [
    "ontology_df_name = date + '_ontology_df.csv'\n",
    "ontology_df = pd.read_csv(ontology_df_name,index_col=0)\n",
    "\n",
    "\n",
    "mapping_dict_name = date + '_mapping_dict_df.csv'\n",
    "mapping_dict_df = pd.read_csv(mapping_dict_name,index_col=0)\n",
    "mapping_dict = mapping_dict_df.T.to_dict('list')\n",
    "# the values are stored as a list. convert to single value\n",
    "for key, value in mapping_dict.items():\n",
    "    mapping_dict[key] = value[0]\n",
    "\n",
    "leaf_values_name = date + '_leaf_values'\n",
    "internal_values_name = date + '_internal_values'\n",
    "with open(leaf_values_name,'rb') as fp:\n",
    "    leaf_values = pickle.load(fp)\n",
    "with open(internal_values_name,'rb') as fp:\n",
    "    internal_values = pickle.load(fp)\n",
    "\n",
    "\n",
    "cell_parent_mask_name = date + '_cell_parent_mask.pt'\n",
    "cell_parent_mask = torch.load(cell_parent_mask_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caceac8",
   "metadata": {},
   "source": [
    "## Build the Experiment and the DataPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5274b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene and cell type info stored on Turbo\n",
    "os.chdir('/nfs/turbo/umms-welchjd/mccell')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2d95a",
   "metadata": {},
   "source": [
    "First, let's load the gene list and cell type list that we want from the Census. Then we construct the ```var_val_filter``` and ```obs_val_filter``` for querying the census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91823465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gene list\n",
    "biomart = pd.read_csv('mart_export.txt')\n",
    "\n",
    "coding_only = biomart[biomart['Gene type'] == 'protein_coding']\n",
    "\n",
    "gene_list = coding_only['Gene stable ID'].to_list()\n",
    "\n",
    "var_val_filter = '''feature_id in {}'''.format(gene_list)\n",
    "\n",
    "# load the cell type list\n",
    "cell_type_list_name = 'cell_type_list.txt'\n",
    "with open(cell_type_list_name,'rb') as fp:\n",
    "    cell_type_list = pickle.load(fp)\n",
    "\n",
    "obs_val_filter = '''assay == \"10x 3\\' v3\" and is_primary_data == True and cell_type_ontology_term_id in {}'''.format(cell_type_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0f26d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#organism = \"Homo sapiens\"\n",
    "col_names = {\"obs\": [\"cell_type_ontology_term_id\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192a33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the Census and create the Experiment\n",
    "census = cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\")\n",
    "experiment = census[\"census_data\"][\"homo_sapiens\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "437e76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_datapipe = census_ml.ExperimentDataPipe(\n",
    "    experiment,\n",
    "    measurement_name=\"RNA\",\n",
    "    X_name=\"raw\",\n",
    "    obs_query=soma.AxisQuery(value_filter=obs_val_filter),\n",
    "    var_query=soma.AxisQuery(value_filter=var_val_filter),\n",
    "    obs_column_names=[\"cell_type_ontology_term_id\"],\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    soma_chunk_size=10_000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54f2e94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19966"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_datapipe.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1373237",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapipe, test_datapipe = experiment_datapipe.random_split(weights={\"train\": 0.8, \"test\": 0.2}, seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15b58334",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = census_ml.experiment_dataloader(train_datapipe)\n",
    "test_dataloader = census_ml.experiment_dataloader(test_datapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1062363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00ada2e8",
   "metadata": {},
   "source": [
    "## Build Neural Network Classifier\n",
    "\n",
    "First, we need to select and define the input and output dimensions from the data. The number of neurons for the hidden nodes is defined manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07043911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of features (len of X cols)\n",
    "# select the number of gene columns\n",
    "input_dim = experiment_datapipe.shape[1]#X_train.size(dim=1) #adata.X.shape[1] \n",
    "\n",
    "# number of neurons for hidden layers\n",
    "hidden_layer_1 = 256\n",
    "hidden_layer_2 = 128\n",
    "\n",
    "# number of classes (unique of y)\n",
    "output_dim = torch.unique(y_train[y_train >= 0]).size(dim=0) #labels['encoded_labels'].nunique()\n",
    "\n",
    "print(input_dim,hidden_layer_1,hidden_layer_2,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d64bec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim,hidden_layer_1)\n",
    "        self.linear2 = nn.Linear(hidden_layer_1,hidden_layer_2)\n",
    "        self.linear3 = nn.Linear(hidden_layer_2,output_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_layer_1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_layer_2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "    \n",
    "    def get_last_layer(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c1c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483cfde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = census[\"census_data\"][\"homo_sapiens\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff18319",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_datapipe = census_ml.ExperimentDataPipe(\n",
    "    experiment,\n",
    "    measurement_name=\"RNA\",\n",
    "    X_name=\"raw\",\n",
    "    obs_query=soma.AxisQuery(value_filter=\"tissue_general == 'tongue' and is_primary_data == True\"),\n",
    "    obs_column_names=[\"cell_type\"],\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    soma_chunk_size=10_000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8414ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15020, 60664)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_datapipe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27802bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapipe, test_datapipe = experiment_datapipe.random_split(weights={\"train\": 0.8, \"test\": 0.2}, seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c03005b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dataloader = census_ml.experiment_dataloader(train_datapipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "591f903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()  # noqa: UP008\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09072f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch = batch\n",
    "\n",
    "        X_batch = X_batch.float().to(device)\n",
    "\n",
    "        # Perform prediction\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # Determine the predicted label\n",
    "        probabilities = torch.nn.functional.softmax(outputs, 1)\n",
    "        predictions = torch.argmax(probabilities, axis=1)\n",
    "\n",
    "        # Compute the loss and perform back propagation\n",
    "\n",
    "        # Exclude the cell_type labels, which are in the second column\n",
    "        y_batch = y_batch[:, 1]\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        train_correct += (predictions == y_batch).sum().item()\n",
    "        train_total += len(predictions)\n",
    "\n",
    "        loss = loss_fn(outputs, y_batch.long())\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= train_total\n",
    "    train_accuracy = train_correct / train_total\n",
    "    return train_loss, train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dac0b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0185056 Accuracy 0.2145\n",
      "Epoch 2: Train Loss: 0.0162072 Accuracy 0.2665\n",
      "Epoch 3: Train Loss: 0.0149051 Accuracy 0.3136\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# The size of the input dimension is the number of genes\n",
    "input_dim = experiment_datapipe.shape[1]\n",
    "\n",
    "# The size of the output dimension is the number of distinct cell_type values\n",
    "cell_type_encoder = experiment_datapipe.obs_encoders[\"cell_type\"]\n",
    "output_dim = len(cell_type_encoder.classes_)\n",
    "\n",
    "model = LogisticRegression(input_dim, output_dim).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-05)\n",
    "\n",
    "for epoch in range(3):\n",
    "    train_loss, train_accuracy = train_epoch(model, experiment_dataloader, loss_fn, optimizer, device)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.7f} Accuracy {train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9d6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dataloader = census_ml.experiment_dataloader(test_datapipe)\n",
    "X_batch, y_batch = next(iter(experiment_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f0a8a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1,\n",
       "        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 7, 1, 1, 1, 1, 1, 7,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 7, 7, 1, 1, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "model.to(device)\n",
    "outputs = model(X_batch.to(device))\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(outputs, 1)\n",
    "predictions = torch.argmax(probabilities, axis=1)\n",
    "\n",
    "display(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82ac91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e3a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a857404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cae82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8bc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f489a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ddfd0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "census = cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f4df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\") as census:\n",
    "    cell_metadata = census[\"census_data\"][\"homo_sapiens\"].obs.read(\n",
    "        value_filter = \"sex == 'female' and cell_type in ['microglial cell', 'neuron']\",\n",
    "        column_names = [\"assay\", \"cell_type\", \"tissue\", \"tissue_general\", \"suspension_type\", \"disease\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1309ae24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tiledbsoma._read_iters.TableReadIter at 0x152b7f2edff0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302a947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf15d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment 'file:///scratch/welchjd_root/welchjd99/fujoshua/soma/census_data/homo_sapiens' (CLOSED for 'r')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census[\"census_data\"][\"homo_sapiens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce8ff43",
   "metadata": {},
   "outputs": [
    {
     "ename": "TileDBError",
     "evalue": "[TileDB::Array] Error: Cannot get array schema; Array is not open",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTileDBError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcensus\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcensus_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhomo_sapiens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_filter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex == \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfemale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m and cell_type in [\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmicroglial cell\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneuron\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcell_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtissue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtissue_general\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuspension_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisease\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/tiledbsoma/_dataframe.py:359\u001b[0m, in \u001b[0;36mDataFrame.read\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    349\u001b[0m sr \u001b[38;5;241m=\u001b[39m clib\u001b[38;5;241m.\u001b[39mSOMADataFrame\u001b[38;5;241m.\u001b[39mopen(\n\u001b[1;32m    350\u001b[0m     uri\u001b[38;5;241m=\u001b[39mhandle\u001b[38;5;241m.\u001b[39muri,\n\u001b[1;32m    351\u001b[0m     mode\u001b[38;5;241m=\u001b[39mclib\u001b[38;5;241m.\u001b[39mOpenMode\u001b[38;5;241m.\u001b[39mread,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     timestamp\u001b[38;5;241m=\u001b[39mhandle\u001b[38;5;241m.\u001b[39mtimestamp \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, handle\u001b[38;5;241m.\u001b[39mtimestamp),\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value_filter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     sr\u001b[38;5;241m.\u001b[39mset_condition(QueryCondition(value_filter), \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_reader_coords(sr, coords)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# # TODO: batch_size\u001b[39;00m\n",
      "\u001b[0;31mTileDBError\u001b[0m: [TileDB::Array] Error: Cannot get array schema; Array is not open"
     ]
    }
   ],
   "source": [
    "census[\"census_data\"][\"homo_sapiens\"].obs.read(\n",
    "        value_filter = \"sex == 'female' and cell_type in ['microglial cell', 'neuron']\",\n",
    "        column_names = [\"assay\", \"cell_type\", \"tissue\", \"tissue_general\", \"suspension_type\", \"disease\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1860a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
