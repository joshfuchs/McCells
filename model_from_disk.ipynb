{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf4e25ff",
   "metadata": {},
   "source": [
    "# McCell Model Data Streaming From Disk\n",
    "\n",
    "Model the CellxGene Census data by streaming the data from disk, to save on memory issues. Based on the tutorial from https://chanzuckerberg.github.io/cellxgene-census/notebooks/experimental/pytorch.html\n",
    "\n",
    "Need to run ```mccell_preprocess_from_disk.ipynb``` first, which saves some preprocessing files this program loads and uses. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b822fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellxgene_census\n",
    "import cellxgene_census.experimental.ml as census_ml\n",
    "import tiledbsoma as soma\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from torcheval.metrics.functional import multilabel_accuracy\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(style='whitegrid')\n",
    "sns.set_context(context='notebook')\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc(\n",
    "    'axes',\n",
    "    labelweight='bold',\n",
    "    labelsize='large',\n",
    "    titleweight='bold',\n",
    "    titlesize=9,\n",
    "    linewidth=4\n",
    "    )\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9355266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dba2fb",
   "metadata": {},
   "source": [
    "## Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed289f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(marginalization_dict,num_epochs,save_title=None):\n",
    "    fig, ax = plt.subplots(4,2,figsize=(9,12))\n",
    "    \n",
    "    \n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['accuracy_train_leaf_hist'], \n",
    "                    ax = ax[0,0],color='lightcoral',label='Train')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['accuracy_val_leaf_hist'], \n",
    "                    ax = ax[0,0],color='mediumslateblue',label='Validation')\n",
    "    \n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['accuracy_train_internal_hist'],\n",
    "                   ax = ax[0,1],color='lightcoral',label='Train')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['accuracy_val_internal_hist'],\n",
    "                   ax = ax[0,1],color='mediumslateblue',label='Validation')\n",
    "    \n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_train_hist'], \n",
    "                    ax = ax[1,0],color='lightcoral')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_val_hist'], \n",
    "                    ax = ax[1,0],color='mediumslateblue')\n",
    "    \n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_train_leaf_hist'], \n",
    "                    ax = ax[1,1],color='lightcoral',marker='X',label='Train Leafs')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_train_internal_hist'], \n",
    "                    ax = ax[1,1],color='lightcoral',marker='o',label='Train Internal')\n",
    "    #sns.scatterplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_train_internal_hist'], \n",
    "    #                ax = ax[1,0],color='lightcoral',marker='v',label='Train Internal')\n",
    "\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_val_leaf_hist'], \n",
    "                    ax = ax[2,0],color='mediumslateblue',marker='X',label='Val Leafs')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_val_internal_hist'], \n",
    "                    ax = ax[2,0],color='mediumslateblue',marker='o',label='Val Internal')\n",
    "    #sns.scatterplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_val_internal_hist'], \n",
    "    #                ax = ax[1,1],color='mediumslateblue',marker='v',label='Val Internal')\n",
    "\n",
    "\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['f1_score_train_leaf'], \n",
    "                    ax = ax[2,1],color='lightcoral',label='Train')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['f1_score_val_leaf'], \n",
    "                    ax = ax[2,1],color='mediumslateblue',label='Validation')\n",
    "\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['f1_score_train_internal'], \n",
    "                    ax = ax[3,0],color='lightcoral',label='Train')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['f1_score_val_internal'], \n",
    "                    ax = ax[3,0],color='mediumslateblue',label='Validation')\n",
    "\n",
    "    \n",
    "    ax[0,0].set_xlabel('Epoch')\n",
    "    ax[0,1].set_xlabel('Epoch')\n",
    "    ax[1,0].set_xlabel('Epoch')\n",
    "    ax[1,1].set_xlabel('Epoch')\n",
    "    ax[2,0].set_xlabel('Epoch')\n",
    "    ax[2,1].set_xlabel('Epoch')\n",
    "    ax[3,0].set_xlabel('Epoch')\n",
    "\n",
    "\n",
    "    ax[0,0].set_ylabel('Leaf Accuracy')\n",
    "    ax[0,1].set_ylabel('Internal Accuracy')\n",
    "    ax[1,0].set_ylabel('Total Loss')\n",
    "    ax[1,1].set_ylabel('Training Loss')\n",
    "    ax[2,0].set_ylabel('Validation Loss')\n",
    "    ax[2,1].set_ylabel('Leaf F1 Score')\n",
    "    ax[3,0].set_ylabel('Internal F1 Score')\n",
    "\n",
    "\n",
    "    # set the boundary for the accuracy plots\n",
    "    #ax[0,1].set_ylim((50,100))\n",
    "    \n",
    "    # turn off the axis for subplot 2,1\n",
    "    ax[3,1].axis('off')\n",
    "    \n",
    "    if save_title:\n",
    "        plt.savefig(save_title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e491b4",
   "metadata": {},
   "source": [
    "## Load the Saved Outputs from McCell_preprocessing\n",
    "\n",
    "The preproccessing and modeling here should be run on the **same dataset**. If not, there might be differences in the ordering of cells the would nullify this model. \n",
    "\n",
    "- cell_parent_mask\n",
    "- Mapping_dict\n",
    "- Ontology_df\n",
    "- Internal_values\n",
    "- leaf_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531a2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing outputs are normally stored on Turbo\n",
    "os.chdir('/nfs/turbo/umms-welchjd/mccell/preprocessing_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c952ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the date in yyyy-mm-dd format\n",
    "date = '2024-03-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea04d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_df_name = date + '_ontology_df.csv'\n",
    "ontology_df = pd.read_csv(ontology_df_name,index_col=0)\n",
    "\n",
    "\n",
    "mapping_dict_name = date + '_mapping_dict_df.csv'\n",
    "mapping_dict_df = pd.read_csv(mapping_dict_name,index_col=0)\n",
    "mapping_dict = mapping_dict_df.T.to_dict('list')\n",
    "# the values are stored as a list. convert to single value\n",
    "for key, value in mapping_dict.items():\n",
    "    mapping_dict[key] = value[0]\n",
    "\n",
    "leaf_values_name = date + '_leaf_values'\n",
    "internal_values_name = date + '_internal_values'\n",
    "with open(leaf_values_name,'rb') as fp:\n",
    "    leaf_values = pickle.load(fp)\n",
    "with open(internal_values_name,'rb') as fp:\n",
    "    internal_values = pickle.load(fp)\n",
    "\n",
    "\n",
    "cell_parent_mask_name = date + '_cell_parent_mask.pt'\n",
    "cell_parent_mask = torch.load(cell_parent_mask_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caceac8",
   "metadata": {},
   "source": [
    "## Build the Experiment and the DataPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5274b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene and cell type info stored on Turbo\n",
    "os.chdir('/nfs/turbo/umms-welchjd/mccell')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2d95a",
   "metadata": {},
   "source": [
    "First, let's load the gene list and cell type list that we want from the Census. Then we construct the ```var_val_filter``` and ```obs_val_filter``` for querying the census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91823465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gene list\n",
    "biomart = pd.read_csv('mart_export.txt')\n",
    "\n",
    "coding_only = biomart[biomart['Gene type'] == 'protein_coding']\n",
    "\n",
    "gene_list = coding_only['Gene stable ID'].to_list()\n",
    "\n",
    "var_val_filter = '''feature_id in {}'''.format(gene_list)\n",
    "\n",
    "# load the cell type list\n",
    "cell_type_list_name = 'cell_type_list.txt'\n",
    "with open(cell_type_list_name,'rb') as fp:\n",
    "    cell_type_list = pickle.load(fp)\n",
    "\n",
    "obs_val_filter = '''assay == \"10x 3\\' v3\" and is_primary_data == True and cell_type_ontology_term_id in {}'''.format(cell_type_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0f26d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#organism = \"Homo sapiens\"\n",
    "col_names = {\"obs\": [\"cell_type_ontology_term_id\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192a33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the Census and create the Experiment\n",
    "census = cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\")\n",
    "experiment = census[\"census_data\"][\"homo_sapiens\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "437e76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256 #128 #8192 # 4096\n",
    "soma_chunk_size = 50_000 #10_000\n",
    "\n",
    "experiment_datapipe = census_ml.ExperimentDataPipe(\n",
    "    experiment,\n",
    "    measurement_name=\"RNA\",\n",
    "    X_name=\"raw\",\n",
    "    obs_query=soma.AxisQuery(value_filter=obs_val_filter),\n",
    "    var_query=soma.AxisQuery(value_filter=var_val_filter),\n",
    "    obs_column_names=[\"cell_type_ontology_term_id\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    soma_chunk_size=soma_chunk_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54f2e94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2726029, 19966)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_datapipe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195167e",
   "metadata": {},
   "source": [
    "Split the datapipe into Train and Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1373237",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.8\n",
    "val_percent = 0.2\n",
    "extra_percent = 0.999 # use this to reduce the size of the dataset (I'm not sure this actually works...)\n",
    "\n",
    "# if you give random_split only two values, it normalizes those to the whole dataset, \n",
    "# i.e. if you give it 0.12 and 0.08 (in an attempt to train a subset of the dataset), \n",
    "# you get a 60/40 traing/validation split\n",
    "\n",
    "train_datapipe, val_datapipe = experiment_datapipe.random_split(weights={\"train\": train_percent, \"val\": val_percent},\n",
    "                                                                seed=42)\n",
    "#train_datapipe, val_datapipe, test_datapipe = experiment_datapipe.random_split(weights={\"train\": train_percent, \"test\": val_percent,'val':extra_percent},\n",
    "#                                                                seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f5e6e",
   "metadata": {},
   "source": [
    "Build the dataloaders for the train and test splits. We don't use PyTorch ```DataLoader``` directly because the ```ExperimentDataPipe``` already deals with the necessary parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b58334",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = census_ml.experiment_dataloader(train_datapipe)\n",
    "val_dataloader = census_ml.experiment_dataloader(val_datapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fca5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd854341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66c1fc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IterDataPipeSerializationWrapper"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_dataloader.size\n",
    "#print(len(train_dataloader.dataset))\n",
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "453e07d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 395.4807653427124\n"
     ]
    }
   ],
   "source": [
    "start_batch = time.time()\n",
    "for batch in train_dataloader:\n",
    "    print('running time', (time.time()-start_batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b38d1747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 353.2778468132019\n"
     ]
    }
   ],
   "source": [
    "start_batch = time.time()\n",
    "for batch in val_dataloader:\n",
    "    print('running time', (time.time()-start_batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c8c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecae61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00ada2e8",
   "metadata": {},
   "source": [
    "## Build Neural Network Classifier\n",
    "\n",
    "First, we need to select and define the input and output dimensions from the data. The number of neurons for the hidden nodes is defined manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07043911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19966 256 128 88\n"
     ]
    }
   ],
   "source": [
    "# number of features (len of X cols)\n",
    "# select the number of gene columns\n",
    "input_dim = experiment_datapipe.shape[1]#X_train.size(dim=1) #adata.X.shape[1] \n",
    "\n",
    "# number of neurons for hidden layers\n",
    "hidden_layer_1 = 256\n",
    "hidden_layer_2 = 128\n",
    "\n",
    "# number of leaf classes (unique of y that are greater than or equal to 0)\n",
    "output_dim = len(leaf_values) #torch.unique(y_train[y_train >= 0]).size(dim=0) #labels['encoded_labels'].nunique()\n",
    "\n",
    "print(input_dim,hidden_layer_1,hidden_layer_2,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d64bec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim,hidden_layer_1)\n",
    "        self.linear2 = nn.Linear(hidden_layer_1,hidden_layer_2)\n",
    "        self.linear3 = nn.Linear(hidden_layer_2,output_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_layer_1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_layer_2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "    \n",
    "    def get_last_layer(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf977d",
   "metadata": {},
   "source": [
    "## Functions for dealing with cell ontology and loss calculations\n",
    "\n",
    "We'll need a few specific functions to process the predicted values with the structure of the Cell Ontology. We'll define these here. Full details of each function are found in each space. \n",
    "\n",
    "- output_probability_tensor: convolves the predicted classification outputs with the ontology hierarchy to get predicted normalized probabilities for all parent nodes\n",
    "- target_probability_tensor: convolves the known target values with the ontology hierarchy to get target probabilities for all parent nodes\n",
    "- build_mask_tensor_for_batch : builds a masking tensor from cell_parent_mask specific to the targets for each batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a022561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(x_data):\n",
    "    '''\n",
    "    This function takes the input x_data, transforms the data with log(1+x) and \n",
    "    returns the transformed data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_data : scipy matrix\n",
    "        scipy sparse CSR matrix  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x_data : SciPy Matrix\n",
    "        scipy sparse CSR matrix\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # np.log takes the natural log\n",
    "    x_data.data = np.log(1+ x_data.data)\n",
    "\n",
    "    return x_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a3c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_probability_tensor(outputs,ontology_df):\n",
    "    '''\n",
    "    Function to convolve the predicted classification outputs with the ontology heirarchy to\n",
    "    get predicted normalized probabilities for all parents. \n",
    "    Precursur to loss calculation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    outputs : tensor\n",
    "        PyTorch tensor of shape [a,b] where a = number of cells and b = number of target leafs\n",
    "        This tensor is the result of the classification in the neural network\n",
    "                \n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where rows are parent labels and columns are leafs\n",
    "        values indicate if parent node is an ancestor of leaf node\n",
    "\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    sum_probability_tensor : tensor\n",
    "        PyTorch tensor of shape [c,a] where c = number of cell ontology IDs and a = number of cells\n",
    "        Each entry is the summed predicted probability for that cell ID\n",
    "\n",
    "    '''\n",
    "        \n",
    "    # convert the dataframe to a pytorch tensor\n",
    "    ontology_tensor = torch.FloatTensor(ontology_df.values)\n",
    "    ontology_tensor = ontology_tensor.to(device)\n",
    "        \n",
    "    # convolve the ontology tensor with the predicted outputs\n",
    "    # ontology tensor is shape ij, where i = parent IDs, j = probability for leaf IDs\n",
    "    # output tensor is shape kj, where k = number of cells classified, j = probability for leaf IDs\n",
    "    # probability tensor is shape ijk\n",
    "    \n",
    "    # if there is only a single column for the ontology, change shape to match expected value\n",
    "    if len(ontology_tensor.shape) == 1:\n",
    "        ontology_tensor = ontology_tensor.unsqueeze(1)    \n",
    "    #print(ontology_tensor.shape)\n",
    "    #print(outputs.shape)\n",
    "    probability_tensor = torch.einsum('ij,kj->ijk',ontology_tensor,outputs)\n",
    "    #print('prob_tensor', probability_tensor.shape)\n",
    "    \n",
    "    # sum across leafs to get the predicted probability, by cell, for each\n",
    "    # parent \n",
    "    # sum_probability_tensor is shape ik, where i = parent IDs, k = number of cells\n",
    "    sum_probability_tensor = torch.sum(probability_tensor,dim=1,dtype=float)\n",
    "    \n",
    "    ##sum_masked_probability_tensor = sum_probability_tensor * batch_masking_tensor\n",
    "    #print('sum masked',sum_masked_probability_tensor.shape)\n",
    "    #print('sum masked',sum_masked_probability_tensor.sum(dim=1))\n",
    "    # ensure that the max value is 1 because of floating point issues\n",
    "    # if we don't do this, we can run into errors with the binary cross entropy\n",
    "    ##sum_masked_probability_tensor = torch.where(sum_masked_probability_tensor > 1, 1.0, sum_masked_probability_tensor )\n",
    "    sum_probability_tensor = torch.where(sum_probability_tensor > 1, 1.0, sum_probability_tensor )\n",
    "\n",
    "    return sum_probability_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0e3aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mask_tensor_for_batch(cell_parent_mask,y_batch,min_encoded_value,max_encoded_value):\n",
    "    '''\n",
    "    For each batch, this function builds the correct masking tensor based on which\n",
    "    values of the cell ontology we want to include given the target. It returns aa \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cell_parent_mask : tensor\n",
    "        tensor of shape ik, where i = parent IDs and k = each cell type in the dataset\n",
    "        binary tensor where 1 means for that cell type, that parent ID will be included\n",
    "        in the internal loss calculation\n",
    "        and 0 means for that cell type, that parent ID is excluded in the internal loss\n",
    "        calculation\n",
    "                \n",
    "    y_batch : tensor\n",
    "        tensor with encoded target values for current batch of data\n",
    "        \n",
    "    min_encoded_value : int\n",
    "        the minimum encoded value from the full set of target values. Typically -9999\n",
    "        \n",
    "    max_encoded_value : int\n",
    "        the maximum encoded value from the full set of target values. Depends on number\n",
    "        of leaf targets in the dataset\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    batch_masking_tensor : tensor\n",
    "        PyTorch tensor of shape [c,a] where c = number of cell ontology IDs and a = number of cells\n",
    "        Binary tensor to zero out probabilities we do not want\n",
    "    \n",
    "    '''\n",
    "    # 1) from y_batch, we need to get the indices we'll use to select from cell_parent_mask\n",
    "    #.   all the positive values are each, but we need to convert the negative values to\n",
    "    #.   correspond with the (positive) index they would otherwise be. Then save to a tensor\n",
    "    \n",
    "    for value in y_batch:\n",
    "        if value >= 0:\n",
    "            new_value = value\n",
    "        else:\n",
    "            new_value = (value - min_encoded_value) + max_encoded_value + 1\n",
    "        try:\n",
    "            converted_y_batch = torch.cat((converted_y_batch,new_value.reshape(1)),dim=0)\n",
    "        except:\n",
    "            converted_y_batch = new_value.reshape(1)\n",
    "    \n",
    "    \n",
    "    # 2) use the y_batch converted values to build a new tensor from cell_parent_mask\n",
    "    #.    that is the mask we will use for this batch of values.\n",
    "    #.    return this tensor\n",
    "\n",
    "    cell_parent_mask = cell_parent_mask.to(device)\n",
    "    batch_masking_tensor = torch.index_select(cell_parent_mask,1,converted_y_batch)\n",
    "    #print(batch_masking_tensor.sum(dim=0))\n",
    "    \n",
    "    return(batch_masking_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47cb3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_probability_tensor(target_values,ontology_df,mapping_dict):\n",
    "    '''\n",
    "    Function to convolve the known target values with the ontology heirarchy\n",
    "    Precursur to loss calculation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    target_values : tensor\n",
    "        PyTorch tensor of shape [a] where a = number of cells\n",
    "                \n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where rows are parent labels and columns are leafs\n",
    "        values indicate if parent node is an ancestor of leaf node\n",
    "\n",
    "    mapping_dict : dictionary\n",
    "        dictionary mapping the Cell Ontology IDs (keys) to the encoded values (values)\n",
    "        Values >= 0 are leaf nodes\n",
    "        Values < 0 are internal nodes\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    target_tensor : tensor\n",
    "        PyTorch tensor of shape [c,a] where c = number of cell ontology IDs and a = number of cells\n",
    "        Each entry is the summed predicted probability for that cell ID\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # loop through target values, pick out corresponding column of ontology_df\n",
    "    # append that to a tensor\n",
    "    \n",
    "    # invert the mapping dict so that we can select columns by CELL TYPE ID\n",
    "    inv_mapping_dict = {v: k for k,v in mapping_dict.items()}\n",
    "\n",
    "    for count, target_value in enumerate(target_values):\n",
    "        # get the cell ID from the inverted mapping dictionary based on the encoded value\n",
    "        target_cell_id = inv_mapping_dict[target_value.item()]\n",
    "        \n",
    "        # look up the correct column by the Cell ID. get those column values and convert\n",
    "        # to a tensor\n",
    "        sub_target_tensor = torch.tensor(ontology_df.loc[:,target_cell_id].values,dtype=float).reshape(-1,1)\n",
    "        \n",
    "        if count == 0 :\n",
    "            target_tensor = sub_target_tensor\n",
    "        else:\n",
    "            # set requires_grad so that we can track\n",
    "            target_tensor = torch.cat((target_tensor,sub_target_tensor),1).requires_grad_()\n",
    "    #print('target tensor shape',target_tensor.shape)\n",
    "    #print('batch_masking_tensor',batch_masking_tensor.shape)\n",
    "    ###masked_target_tensor = target_tensor * batch_masking_tensor\n",
    "    ##print('masked target tensor',masked_target_tensor.shape)\n",
    "    \n",
    "    target_tensor = target_tensor.to(device)\n",
    "    ###masked_target_tensor = masked_target_tensor.to(device)\n",
    "    \n",
    "    \n",
    "    return target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf08074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e85f3a8f",
   "metadata": {},
   "source": [
    "# Marginalization Classification \n",
    "\n",
    "- Based on Dahll, et al., Hierarchical Image Classification using Entailment Cone Embeddings, CVPR 202\n",
    "- https://arxiv.org/pdf/2004.03459.pdf\n",
    "- Thesis slides: https://ankitdhall.github.io/publication/learning-representations-for-images-with-hierarchical-labels/master_thesis.pdf\n",
    "- First Author website: https://ankitdhall.github.io/project/learning-representations-for-images-with-hierarchical-labels/\n",
    "\n",
    "Important Details:\n",
    "- we use mini-batch learning, with the batch size set by the user\n",
    "- we model each batch of data at once, then split into leaf and internal nodes, based on the values in y_batch\n",
    "- we calculate the loss two different ways, then sum to get the total loss\n",
    "- we calculate and save the loss, accuracy, and F1 score for metrics to review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c1df033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "criterion_leafs = nn.CrossEntropyLoss(reduction='mean')\n",
    "testoutput = torch.empty((0,3),dtype=torch.float)\n",
    "testy = torch.empty((0,3),dtype=torch.float)\n",
    "loss_train_leafs = criterion_leafs(testoutput, testy)\n",
    "print(loss_train_leafs.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e8771ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 3), dtype=torch.int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2768c41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss_train_leafs.item() == np.nan\n",
    "torch.isnan(loss_train_leafs).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5e57bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerotensor = torch.tensor(0,dtype=torch.int64)\n",
    "zerotensor = zerotensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f596f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zerotensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9ba58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([], device='cuda:0', dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58d02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c19946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa4cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9dae7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginalization_classification_manual_batch(train_dataloader,val_dataloader,num_epochs,ontology_leaf_df, \n",
    "                                                batch_size,internal_values,mapping_dict,\n",
    "                                               ontology_df, threshold, cell_parent_mask,encoding_mapper):\n",
    "    '''\n",
    "    Performs training and validation simultaneously to allow visualization of model performance \n",
    "    per epoch. Accounts for entire tree structure of the ontology by classifying to the leaf nodes, \n",
    "    propogating the probabilities across the ontology, and calculating the loss for both the leafs \n",
    "    and parent nodes. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_dataloader : DataLoader object\n",
    "        DataLoader object for training data from census_ml.experiment_dataloader for \n",
    "        streaming data from disk from the CZI cell_census API\n",
    "        similar to PyTorach DataLoader but specific to working with Cell Census data\n",
    "    \n",
    "    val_dataloader : DataLoader object\n",
    "        DataLoader object for validation data from census_ml.experiment_dataloader for \n",
    "        streaming data from disk from the CZI cell_census API\n",
    "        similar to PyTorach DataLoader but specific to working with Cell Census \n",
    "        \n",
    "    num_epochs : int\n",
    "        integer specify the number of epochs\n",
    "        \n",
    "    ontology_leaf_df : pandas dataframe\n",
    "        pandas dataframe where indices (rows) are all leaf and parent cell IDs from the portion of \n",
    "        the ontology being queried, and columns are onlys leafs in portion of ontology being queried. \n",
    "        Differs from ontology_df in that columns do not include any internal nodes.\n",
    "        \n",
    "        Dataframe is binary. For each parent node, element = 1 if parent node is an ancestor\n",
    "        of corresponding leaf node.\n",
    "    \n",
    "    batch_size : int\n",
    "        integer specificying the number of samples processed before the model\n",
    "        is updated\n",
    "        \n",
    "    internal_values : list\n",
    "        list of Cell Ontology IDs for internal nodes included in the dataset\n",
    "        \n",
    "    mapping_dict : dict\n",
    "        dictionary mapping the Cell Ontology IDs (keys) to the encoded values (values)\n",
    "        Values >= 0 are leaf nodes\n",
    "        Values < 0 are internal nodes\n",
    "    \n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where indices (rows) are all leaf and parent cell IDs from the portion of \n",
    "        the ontology being queried, and columns are leafs and internal nodes in portion of ontology being \n",
    "        queried. \n",
    "        Differs from ontology_leaf_df in that columns include both leaf and internal node values\n",
    "        \n",
    "        Dataframe is binary. For each parent node, element = 1 if parent node is an ancestor\n",
    "        of corresponding leaf node.\n",
    "        \n",
    "    threshold : float\n",
    "        value between 0 and 1 to set for making predictions. If the predicted probability is\n",
    "        equal to or greater than threshold, we consider that a true prediction\n",
    "        \n",
    "    cell_parent_mask : tensor\n",
    "        tensor of shape ik, where i = parent IDs and k = each cell type in the dataset\n",
    "        binary tensor where 1 means for that cell type, that parent ID will be included\n",
    "        in the internal loss calculation\n",
    "        and 0 means for that cell type, that parent ID is excluded in the internal loss\n",
    "        calculation\n",
    "\n",
    "    encoding_mapper : dictionary\n",
    "        dictionary mapping from encoder_mapping_dict (keys) to mapping_dict (values)\n",
    "        used to differentiate leaf values and internal values \n",
    "        \n",
    "    Returns\n",
    "    -------    \n",
    "    marginalization_dict : dictionary\n",
    "        dictionary containing results from each epoch of the neural network\n",
    "    \n",
    "    Keys and Values include:\n",
    "    \n",
    "        accuracy_train_leaf_hist : list\n",
    "            list containing accuracy for leaf values for the training set per epoch\n",
    "            \n",
    "        accuracy_train_internal_hist : list\n",
    "            list containing accuracy for internal values for the trainig set per epoch\n",
    "        \n",
    "        loss_train_hist: list\n",
    "            list containing total loss values for the training set per epoch\n",
    "            \n",
    "        loss_train_leaf_hist : list\n",
    "            list containing loss values for leaf nodes for the training set per epoch\n",
    "            \n",
    "        loss_train_parents_hist : list\n",
    "            list containing loss values for parent nodes for the training set per epoch\n",
    "        \n",
    "        loss_train_internal_hist : list\n",
    "            list containing loss values for internal nodes for the training set per epoch\n",
    "        \n",
    "        accuracy_val_leaf_hist : list \n",
    "            list containing accuracy for leaf values for the validation set per epoch\n",
    "        \n",
    "        accuracy_val_internal_hist : list\n",
    "            list containing accuracy for internal values for the validation set per epoch\n",
    "        \n",
    "        loss_val_hist : list\n",
    "            list containing total loss values for the validation set per epoch\n",
    "            \n",
    "        loss_val_leaf_hist : list\n",
    "            list containing loss values for leaf nodes for the validation set per epoch\n",
    "            \n",
    "        loss_val_parents_hist : list\n",
    "            list containing loss values for parent nodes for the validation set per epoch\n",
    "            \n",
    "        loss_val_internal_hist : list\n",
    "            list containing loss values for internal nodes for the validation set per epoch\n",
    "        \n",
    "        f1_score_train_leaf : list\n",
    "            list containing Macro F1 score for leaf nodes for training set per epoch \n",
    "        \n",
    "        f1_score_val_leaf : list\n",
    "            list containing Macro F1 score for leaf nodes for validation set per epoch \n",
    "        \n",
    "        best_output : tensor\n",
    "            PyTorch tensor containing the predicted probabilites for the most accurate\n",
    "            epoch\n",
    "            \n",
    "        best_state_dict : dictionary\n",
    "            Pytorch state_dict that contains the parameters for the best fitting models\n",
    "    '''\n",
    "    # initialize variables for saving values\n",
    "    accuracy_train_leaf_hist = []\n",
    "    accuracy_train_internal_hist = []\n",
    "    loss_train_leaf_hist = []\n",
    "    loss_train_parents_hist = []\n",
    "    loss_train_internal_hist = []\n",
    "    loss_train_hist = []\n",
    "    \n",
    "    accuracy_val_leaf_hist = []\n",
    "    accuracy_val_internal_hist = []\n",
    "    loss_val_hist = []\n",
    "    loss_val_leaf_hist = []\n",
    "    loss_val_parents_hist = []\n",
    "    loss_val_internal_hist = []\n",
    "    \n",
    "    f1_score_train_leaf = []\n",
    "    f1_score_val_leaf = []\n",
    "    \n",
    "    f1_score_train_parent = []\n",
    "    f1_score_val_parent = []\n",
    "\n",
    "    best_accuracy = - np.inf\n",
    "    best_weights = None\n",
    "    \n",
    "    # get the list of leaf labels\n",
    "    leaf_label_list = [value for (key,value) in mapping_dict.items() if value >= 0]\n",
    "\n",
    "    # get the min and max encoded values\n",
    "    min_encoded_value = min(mapping_dict.values()) #min(y_train).item()\n",
    "    max_encoded_value = max(mapping_dict.values()) #max(y_train).item()\n",
    "\n",
    "    # initialize network\n",
    "    clf = Network()\n",
    "    clf.to(device)\n",
    "\n",
    "    # define loss and optimizer\n",
    "    # we use two different loss methods for the leafs and parents\n",
    "    # use Cross Entory Loss for leafs, because those probabilities are normalized\n",
    "    #     and it is thus a multi-class problem\n",
    "    # Use BCELoss for the parents because this is a multi-label problem\n",
    "    #     and the probabilities are normalized, so we don't need BCELossWithLogits\n",
    "    # initialize the leaf loss here\n",
    "    # because of how we weight the parent loss, we will have to initialize that\n",
    "    # loss on each iteration because the weighting will change.\n",
    "    criterion_leafs = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    #criterion_parents = nn.BCELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(clf.parameters(), lr=1e-3)#, amsgrad=True, eps=1e-5)\n",
    "    #scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.5, total_iters=5)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5,gamma=0.5)\n",
    "\n",
    "    #start_epoch = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        #print('on epoch', epoch)\n",
    "        \n",
    "        # TRAINING\n",
    "        #print('Begin Training...')\n",
    "        clf.train()\n",
    "        \n",
    "        running_train_loss = 0.0\n",
    "        #correct_train = 0\n",
    "        #y_length = 0\n",
    "                \n",
    "        # set up manual batches - from https://stackoverflow.com/questions/45113245/how-to-get-mini-batches-in-pytorch-in-a-clean-and-efficient-way\n",
    "        #permutation = torch.randperm(X_train.size()[0]).to(device)\n",
    "        #permutation_cpu = permutation.cpu() # we want the same permutations, but need one copy on the cpu\n",
    "\n",
    "        print('start train batching')\n",
    "        start_batch = time.time()\n",
    "        #for i in range(0,X_train.size()[0], batch_size):\n",
    "        for i, train_batch in enumerate(train_dataloader):\n",
    "            if (i) % 100 == 0:\n",
    "                print('on batch', i, 'running time', (time.time()-start_batch))\n",
    "            #print(i)\n",
    "            #indices = permutation[i:i+batch_size]\n",
    "            #indices_cpu = permutation_cpu[i:i+batch_size]\n",
    "            #X_batch, y_batch = X_train[indices], y_train[indices] # doesn't work for sparse tensors\n",
    "\n",
    "            #X_batch = torch.index_select(X_train,0,indices_cpu).to(device)\n",
    "\n",
    "            #y_batch = torch.index_select(y_train,0,indices)#.to(device)\n",
    "\n",
    "            X_batch, y_batch = train_batch\n",
    "            \n",
    "            # change dtype to float\n",
    "            X_batch = X_batch.float()\n",
    "            \n",
    "            # transform the data with log(1+x)\n",
    "            X_batch = transform_data(X_batch)\n",
    "            \n",
    "            # move to device\n",
    "            X_batch = X_batch.to(device)\n",
    "\n",
    "            \n",
    "            # select the encoded values from the experiment_datapipe\n",
    "            y_batch = y_batch[:,1]\n",
    "            #print(y_batch)\n",
    "\n",
    "            # then map the values from the datapipe encoded values to the\n",
    "            # encoded values from the Ontology/mapping_dict\n",
    "            \n",
    "            #encoding_mapper\n",
    "            y_batch = torch.tensor([encoding_mapper[x.item()] for x in y_batch])\n",
    "            \n",
    "            # move to device\n",
    "            y_batch = y_batch.to(device)\n",
    "            #print(y_batch)\n",
    "            \n",
    "            # check that tensors are on gpu. if on gpu, get_device returns 0, if on cpu, returns -1\n",
    "            #print(X_batch.get_device())\n",
    "            #print(y_batch.get_device())\n",
    "            \n",
    "            # set optimizer to zero grad to remove previous epoch gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # make predictions for this batch\n",
    "            #if epoch == 0:\n",
    "            #    outputs_train = clf_nosoftmax(X_batch.float()) # might need to change to X_train.float()\n",
    "            #else:\n",
    "            outputs_train = clf(X_batch) # might need to change to X_train.float()\n",
    "            \n",
    "            ######\n",
    "            # create mask to separate leaf and internal nodes\n",
    "            ######\n",
    "            output_train_leaf = outputs_train[y_batch >= 0]\n",
    "            #print(output_train_leaf.shape)\n",
    "            y_batch_leaf = y_batch[y_batch >= 0]\n",
    "            #print(y_batch_leaf.shape)\n",
    "            \n",
    "            #output_train_internal = outputs_train[y_batch < 0]\n",
    "            #y_batch_internal = y_batch[y_batch < 0]\n",
    "            \n",
    "\n",
    "            # calculate loss for just the leafs\n",
    "            loss_train_leafs = criterion_leafs(output_train_leaf, y_batch_leaf)\n",
    "            #print(y_batch_leaf)\n",
    "            #print(loss_train_leafs)\n",
    "            #print(type(loss_train_leafs))\n",
    "            #print(loss_train_leafs.item())\n",
    "            #print(type(loss_train_leafs.item()))\n",
    "            \n",
    "            # if we have no leaf values in the batch, the leaf loss evaluates to NaN.\n",
    "            # in this case, set it to 0\n",
    "            if torch.isnan(loss_train_leafs).item():\n",
    "                loss_train_leafs = torch.tensor(0,dtype=torch.int64)\n",
    "                loss_train_leafs = loss_train_leafs.to(device)\n",
    "                #print(loss_train_leafs)\n",
    "            #print('')\n",
    "\n",
    "            # get the masking tensor for this batch of cells\n",
    "            # for calculating the internal loss\n",
    "            # we initialize BCE loss every batch because the mask changes based on which cells are\n",
    "            # included and ordered for this batch\n",
    "            batch_train_masking_tensor = build_mask_tensor_for_batch(cell_parent_mask,y_batch,min_encoded_value,max_encoded_value)\n",
    "            criterion_parents = nn.BCELoss(weight=batch_train_masking_tensor,reduction='mean')\n",
    "\n",
    "            \n",
    "            # calculate the loss for the parents of the cells that are leafs\n",
    "            output_train_parent_prob = output_probability_tensor(outputs_train,ontology_leaf_df)\n",
    "            target_train_parent_prob = target_probability_tensor(y_batch,ontology_df,mapping_dict)\n",
    "\n",
    "            #print(output_train_parent_prob)\n",
    "            #print('output_train_parent_prob',output_train_parent_prob.shape)\n",
    "            #print(target_train_parent_prob)\n",
    "            #print('target_train_parent_prob',target_train_parent_prob.shape)\n",
    "            \n",
    "            loss_train_parents = criterion_parents(output_train_parent_prob,target_train_parent_prob)\n",
    "\n",
    "            #######\n",
    "            # calculate the loss for the cells that are internal nodes\n",
    "            ##### total_accuracy_cell, total_number_of_cells\n",
    "            \n",
    "            #loss_train_internal, batch_accuracy_internal, batch_numbers_internal = internal_node_loss(\n",
    "            #                                        output_train_internal,y_batch_internal,\n",
    "            #                                         internal_values,mapping_dict,ontology_df,\n",
    "            #                                        ontology_leaf_df,criterion_parents,threshold)\n",
    "            \n",
    "            # sum the loss for both leafs and parents\n",
    "            loss_train = loss_train_leafs + loss_train_parents #+ loss_train_internal\n",
    "            #print(loss_train)\n",
    "            #print('')\n",
    "\n",
    "            # backward propagation\n",
    "            loss_train.backward()\n",
    "\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "             \n",
    "            running_train_loss += loss_train.item()\n",
    "           \n",
    "            # save predictions\n",
    "            _, train_leaf_pred_per_epoch = output_train_leaf.max(dim=1)\n",
    "\n",
    "            # calculate accuracy for internal cells\n",
    "            #####\n",
    "            # need to update this with the weighting somehow!!!!\n",
    "            #####\n",
    "            train_batch_accuracy = multilabel_accuracy(output_train_parent_prob,target_train_parent_prob,\n",
    "                                                      threshold=threshold,criteria='hamming')\n",
    "            \n",
    "            # save the number of cells for batch, for use in weighting when\n",
    "            # determining the overall accuracy per epoch\n",
    "            train_batch_number_of_cells = output_train_parent_prob.shape[1]\n",
    "                        \n",
    "            # check size of internal tensors. if only 1 internal cell\n",
    "            # reshape and detach\n",
    "            # else just detach\n",
    "            \n",
    "            ##if len(batch_accuracy_internal.size()) == 0:\n",
    "            ##    batch_accuracy_internal_shaped = batch_accuracy_internal.detach().reshape(1)\n",
    "            ##    batch_numbers_internal_shaped = batch_numbers_internal.detach().reshape(1)\n",
    "            ##else:\n",
    "            ##    batch_accuracy_internal_shaped = batch_accuracy_internal.detach()\n",
    "            ##    batch_numbers_internal_shaped = batch_numbers_internal.detach()\n",
    "                \n",
    "            \n",
    "            if i == 0:\n",
    "                train_leaf_pred_total = train_leaf_pred_per_epoch.detach()\n",
    "                y_train_leaf_total = y_batch_leaf.detach()\n",
    "                train_batch_accuracy_internal = train_batch_accuracy.reshape(1)\n",
    "                train_total_number_of_cells = torch.tensor(train_batch_number_of_cells).reshape(1)\n",
    "                output_train_probabilities = output_train_leaf.detach()\n",
    "                train_parent_pred_total = output_train_parent_prob.detach()\n",
    "                train_parent_true_total = target_train_parent_prob.detach()\n",
    "            else:\n",
    "                train_leaf_pred_total = torch.cat((train_leaf_pred_total,train_leaf_pred_per_epoch.detach()),0)\n",
    "                y_train_leaf_total = torch.cat((y_train_leaf_total,y_batch_leaf.detach()),0)\n",
    "                train_batch_accuracy_internal = torch.cat((train_batch_accuracy_internal,train_batch_accuracy.reshape(1)),0)\n",
    "                train_total_number_of_cells = torch.cat((train_total_number_of_cells,torch.tensor(train_batch_number_of_cells).reshape(1)),0)\n",
    "                output_train_probabilities = torch.cat((output_train_probabilities,output_train_leaf.detach()),0)\n",
    "                train_parent_pred_total = torch.cat((train_parent_pred_total,output_train_parent_prob.detach()),1)\n",
    "                train_parent_true_total = torch.cat((train_parent_true_total,target_train_parent_prob.detach()),1)\n",
    "                #print('train parent pred',train_parent_pred_total.shape)\n",
    "                #print('train parent true',train_parent_true_total.shape)\n",
    "                \n",
    "            # exit after 1 loop so we can test validation code\n",
    "            #break\n",
    "                            \n",
    "            # calculate total epoch accuracy for internal nodes\n",
    "            #epoch_internal_accuracy = / train_numbers_internal.sum() * 100\n",
    "            \n",
    "            #correct_train += (train_pred_per_epoch == y_batch).sum().item()\n",
    "            #y_length += len(y_batch)\n",
    "            \n",
    "            # calculate F1 score\n",
    "            #f1_val_score_epoch = f1_score(train_pred_per_epoch.cpu(),y_batch.cpu(),labels=output_dim,average='weighted',zero_division=np.nan)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        print('done with training')\n",
    "        \n",
    "        # save tensors\n",
    "        #if epoch == 14:\n",
    "        #    torch.save(output_train_probabilities, 'output_good_nosoftmax_1Dec.pt')\n",
    "        #    torch.save(y_train_leaf_total, 'targets_good_nosoftmax_1Dec.pt')\n",
    "        \n",
    "        # save accuracy\n",
    "        #_, train_pred = outputs_train.max(dim=1)\n",
    "        #correct_train = (train_pred == y_train).sum().item()\n",
    "        #accuracy_train_hist.append(correct_train / y_length * 100.)\n",
    "        #print('acc train hist', accuracy_train_hist[-1])\n",
    "        \n",
    "        train_total_number_of_cells = train_total_number_of_cells.to(device)\n",
    "        \n",
    "        correct_train_leaf = (train_leaf_pred_total == y_train_leaf_total).sum().item()\n",
    "        #print(train_leaf_pred_total.shape)\n",
    "        accuracy_train_leaf_hist.append(correct_train_leaf / train_leaf_pred_total.shape[0] * 100.)\n",
    "                \n",
    "        correct_train_internal = (train_batch_accuracy_internal * train_total_number_of_cells).sum()\n",
    "        accuracy_train_internal = (correct_train_internal / train_total_number_of_cells.sum() * 100.).item()\n",
    "        accuracy_train_internal_hist.append(accuracy_train_internal)\n",
    "        \n",
    "        #print('sample acc', acc_full)\n",
    "\n",
    "        # save loss\n",
    "        loss_train_hist.append(loss_train.item())\n",
    "        loss_train_leaf_hist.append(loss_train_leafs.item())\n",
    "        loss_train_parents_hist.append(loss_train_parents.item())\n",
    "        ##loss_train_internal_hist.append(loss_train_internal.item())\n",
    "        \n",
    "        # save f1 score\n",
    "        # use average = weighted to account for label imbalance\n",
    "        # use zero_division = np.nan to exclude labels where all \n",
    "        #       predictions and labels are negative\n",
    "        f1_train_leaf_score = f1_score(y_train_leaf_total.cpu(), train_leaf_pred_total.cpu(),\n",
    "                                  labels=leaf_label_list,average='weighted',zero_division=np.nan)\n",
    "        f1_score_train_leaf.append(f1_train_leaf_score)\n",
    "        \n",
    "        # for the F1 score for the internal nodes, we need to first turn the probabilities\n",
    "        # into predictions using our threshold value\n",
    "        train_parent_pred_total_thresholded = torch.where(train_parent_pred_total > threshold,1.0,0.0)\n",
    "        \n",
    "        f1_train_parent_score = f1_score(train_parent_true_total.cpu(),train_parent_pred_total_thresholded.cpu(),\n",
    "                                        average='weighted',zero_division=np.nan)\n",
    "        f1_score_train_parent.append(f1_train_parent_score)\n",
    "        #torch.save(train_parent_true_total.cpu(),'train_parent_true_total_20Feb.pt')\n",
    "        #torch.save(train_parent_pred_total_thresholded.cpu(),'train_parent_pred_total_thresholded_20Feb.pt')\n",
    "\n",
    "        \n",
    "        # set up validation\n",
    "        correct_val = 0\n",
    "        y_val_length = 0\n",
    "        \n",
    "        print('start validation')\n",
    "        with torch.no_grad():\n",
    "            clf.eval()\n",
    "            \n",
    "            # set up manual batches\n",
    "            # we don't need to randomly permute the validation set, but\n",
    "            # this will provide consistency with the above.\n",
    "            # for simplicity, let's use the same batch size\n",
    "            #permutation_val = torch.randperm(X_val.size()[0]).to(device)\n",
    "            #start_val = time.time()\n",
    "            \n",
    "            #for i in range(0,X_val.size()[0],batch_size):\n",
    "            print('start validation batching')\n",
    "            start_batch = time.time()\n",
    "            for i, val_batch in enumerate(val_dataloader):\n",
    "                if (i) % 100 == 0:\n",
    "                    print('on batch', i, 'running time', (time.time()-start_batch))\n",
    "\n",
    "                #indices_val = permutation_val[i:i+batch_size]\n",
    "                \n",
    "                #X_val_batch = torch.index_select(X_val,0,indices_val)\n",
    "                #y_val_batch = torch.index_select(y_val,0,indices_val)\n",
    "                \n",
    "                \n",
    "                X_val_batch, y_val_batch = val_batch\n",
    "            \n",
    "                # change dtype to float\n",
    "                X_val_batch = X_val_batch.float()\n",
    "\n",
    "                # transform the data with log(1+x)\n",
    "                X_val_batch = transform_data(X_val_batch)\n",
    "                \n",
    "                # move to device\n",
    "                X_val_batch = X_val_batch.to(device)\n",
    "\n",
    "                \n",
    "                # select the encoded values from the experiment_datapipe\n",
    "                y_val_batch = y_val_batch[:,1]\n",
    "                #print(y_batch)\n",
    "\n",
    "                # then map the values from the datapipe encoded values to the\n",
    "                # encoded values from the Ontology/mapping_dict\n",
    "\n",
    "                #encoding_mapper\n",
    "                y_val_batch = torch.tensor([encoding_mapper[x.item()] for x in y_val_batch])\n",
    "                \n",
    "                # move to device\n",
    "                y_val_batch = y_val_batch.to(device)\n",
    "                \n",
    "                # calculate output by running through the network\n",
    "                outputs_val = clf(X_val_batch)\n",
    "            \n",
    "                ######\n",
    "                # create mask to separate leaf and internal nodes\n",
    "                ######\n",
    "                output_val_leaf = outputs_val[y_val_batch >= 0]\n",
    "                y_val_batch_leaf = y_val_batch[y_val_batch >= 0]\n",
    "\n",
    "                #output_val_internal = outputs_val[y_val_batch < 0]\n",
    "                #y_val_batch_internal = y_val_batch[y_val_batch < 0]\n",
    "            \n",
    "                # calculate loss for just the leafs\n",
    "                loss_val_leafs = criterion_leafs(output_val_leaf, y_val_batch_leaf)\n",
    "        \n",
    "                # if we have no leaf values in the batch, the leaf loss evaluates to NaN.\n",
    "                # in this case, set it to 0\n",
    "                if torch.isnan(loss_val_leafs).item():\n",
    "                    loss_val_leafs = torch.tensor(0,dtype=torch.int64)\n",
    "                    loss_val_leafs = loss_val_leafs.to(device)\n",
    "\n",
    "                # get the masking tensor for this batch of cells\n",
    "                # for calculating the internal loss\n",
    "                # we initialize BCE loss every batch because the mask changes based on which cells are\n",
    "                # included and ordered for this batch\n",
    "                batch_val_masking_tensor = build_mask_tensor_for_batch(cell_parent_mask,y_val_batch,min_encoded_value,max_encoded_value)\n",
    "                criterion_parents = nn.BCELoss(weight=batch_val_masking_tensor,reduction='mean')\n",
    "                \n",
    "                # calculate the loss for the parents of the leafs\n",
    "                output_val_parent_prob = output_probability_tensor(outputs_val,ontology_leaf_df)\n",
    "                target_val_parent_prob = target_probability_tensor(y_val_batch,ontology_df,mapping_dict)\n",
    "                \n",
    "                #print(output_val_parent_prob)\n",
    "                #print(target_val_parent_prob)\n",
    "                loss_val_parents = criterion_parents(output_val_parent_prob,target_val_parent_prob)\n",
    "                #print(loss_val_parents)\n",
    "                #######\n",
    "                # calculate the loss for the cells that are internal nodes\n",
    "                #####\n",
    "\n",
    "                #loss_val_internal, batch_accuracy_internal_val, batch_numbers_internal_val = internal_node_loss(output_val_internal,\n",
    "                #                                                y_val_batch_internal,\n",
    "                #                                                internal_values,mapping_dict,ontology_df,ontology_leaf_df,\n",
    "                #                                                criterion_parents,threshold)\n",
    "\n",
    "                \n",
    "                # sum the loss for both leafs and parents\n",
    "                loss_val = loss_val_leafs + loss_val_parents #+ loss_val_internal\n",
    "            \n",
    "            \n",
    "                # get the predictions\n",
    "                __, predicted_leaf_val_per_epoch = output_val_leaf.max(dim=1)            \n",
    "\n",
    "                # calculate accuracy for internal cells\n",
    "                #####\n",
    "                # need to update this with the weighting somehow!!!!\n",
    "                #####\n",
    "                val_batch_accuracy = multilabel_accuracy(output_val_parent_prob,target_val_parent_prob,\n",
    "                                                          threshold=threshold,criteria='hamming')\n",
    "\n",
    "                # save the number of cells for batch, for use in weighting when\n",
    "                # determining the overall accuracy per epoch\n",
    "                val_batch_number_of_cells = output_val_parent_prob.shape[1]\n",
    "\n",
    "                \n",
    "                # save accuracy\n",
    "                #correct_val += (predicted_val_per_epoch == y_val_batch).sum().item()\n",
    "                #y_val_length += len(y_val_batch)\n",
    "                \n",
    "                # check size of internal tensors. if only 1 internal cell\n",
    "                # reshape and detach\n",
    "                # else just detach\n",
    "                            \n",
    "                #if len(batch_accuracy_internal_val.size()) == 0:\n",
    "                #    batch_accuracy_internal_val_shaped = batch_accuracy_internal_val.detach().reshape(1)\n",
    "                #    batch_numbers_internal_val_shaped = batch_numbers_internal_val.detach().reshape(1)\n",
    "                #else:\n",
    "                #    batch_accuracy_internal_val_shaped = batch_accuracy_internal_val.detach()\n",
    "                #    batch_numbers_internal_val_shaped = batch_numbers_internal_val.detach()\n",
    "                                \n",
    "                if i == 0:\n",
    "                    val_leaf_pred_total = predicted_leaf_val_per_epoch.detach()\n",
    "                    y_leaf_val_total = y_val_batch_leaf.detach()\n",
    "                    val_batch_accuracy_internal = val_batch_accuracy.reshape(1)\n",
    "                    val_total_number_of_cells = torch.tensor(val_batch_number_of_cells).reshape(1)\n",
    "                    val_parent_pred_total = output_val_parent_prob.detach()\n",
    "                    val_parent_true_total = target_val_parent_prob.detach()\n",
    "\n",
    "                else:\n",
    "                    val_leaf_pred_total = torch.cat((val_leaf_pred_total,predicted_leaf_val_per_epoch.detach()),0)\n",
    "                    y_leaf_val_total = torch.cat((y_leaf_val_total,y_val_batch_leaf.detach()),0)\n",
    "                    val_batch_accuracy_internal = torch.cat((val_batch_accuracy_internal,val_batch_accuracy.reshape(1)),0)\n",
    "                    val_total_number_of_cells = torch.cat((val_total_number_of_cells,torch.tensor(val_batch_number_of_cells).reshape(1)),0)\n",
    "                    val_parent_pred_total = torch.cat((val_parent_pred_total,output_val_parent_prob.detach()),1)\n",
    "                    val_parent_true_total = torch.cat((val_parent_true_total,target_val_parent_prob.detach()),1)\n",
    "\n",
    "                    \n",
    "                # exit after 1 loop so we can test  code\n",
    "                #break\n",
    "\n",
    "            # save total accuracy\n",
    "            #accuracy_val_hist.append(correct_val / y_val_length * 100.)\n",
    "            print('done with validation')\n",
    "            val_total_number_of_cells = val_total_number_of_cells.to(device)\n",
    "            \n",
    "            correct_val_leaf = (val_leaf_pred_total == y_leaf_val_total).sum().item()\n",
    "            #print(val_leaf_pred_total.shape)\n",
    "            accuracy_val_leaf_hist.append(correct_val_leaf / val_leaf_pred_total.shape[0] * 100.)\n",
    "\n",
    "            correct_val_internal = (val_batch_accuracy_internal * val_total_number_of_cells).sum()\n",
    "            accuracy_val_internal = (correct_val_internal / val_total_number_of_cells.sum() * 100.).item()\n",
    "            accuracy_val_internal_hist.append(accuracy_val_internal)\n",
    "\n",
    "            \n",
    "            # save loss\n",
    "            loss_val_hist.append(loss_val.item())\n",
    "            loss_val_leaf_hist.append(loss_val_leafs.item())\n",
    "            loss_val_parents_hist.append(loss_val_parents.item())\n",
    "            #loss_val_internal_hist.append(loss_val_internal.item())\n",
    "            \n",
    "            # save f1 score\n",
    "            # use average = weighted to account for label imbalance\n",
    "            # use zero_division = np.nan to exclude labels where all \n",
    "            #       predictions and labels are negative\n",
    "            f1_val_leaf_score = f1_score(y_leaf_val_total.cpu(),val_leaf_pred_total.cpu(),\n",
    "                                    labels=leaf_label_list,average='weighted',zero_division=np.nan)\n",
    "            f1_score_val_leaf.append(f1_val_leaf_score)\n",
    "\n",
    "            \n",
    "            # for the F1 score for the internal nodes, we need to first turn the probabilities\n",
    "            # into predictions using our threshold value\n",
    "            val_parent_pred_total_thresholded = torch.where(val_parent_pred_total > threshold,1.0,0.0)\n",
    "\n",
    "            f1_val_parent_score = f1_score( val_parent_true_total.cpu(),val_parent_pred_total_thresholded.cpu(),\n",
    "                                        average='weighted',zero_division=np.nan)\n",
    "            f1_score_val_parent.append(f1_val_parent_score)\n",
    "            #torch.save(val_parent_true_total.cpu(),'val_parent_true_total_20Feb.pt')\n",
    "            #torch.save(val_parent_pred_total_thresholded.cpu(),'val_parent_pred_total_thresholded_20Feb.pt')\n",
    "\n",
    "            \n",
    "            # check if best model\n",
    "            if accuracy_val_leaf_hist[-1] > best_accuracy:\n",
    "                best_acc = accuracy_val_leaf_hist[-1]\n",
    "                best_state_dict = copy.deepcopy(clf.state_dict())\n",
    "                best_output = copy.deepcopy(outputs_val)\n",
    "            \n",
    "        if (epoch + 1) % 1 == 0 or epoch == 0:\n",
    "            print(f'[{epoch + 1}] Training Accuracy: {accuracy_train_leaf_hist[-1]:.3f} Validation Accuracy: {accuracy_val_leaf_hist[-1]:.3f}')\n",
    "            print(f'Train Loss: {loss_train.item():.4f} Validation Loss: {loss_val.item():.4f}')\n",
    "            #print(f'Internal Loss: {loss_val_internal.item():.4f}')\n",
    "            #print('learning rate:', optimizer.param_groups[0][\"lr\"])\n",
    "        #end_epoch = time.time()\n",
    "        #print('epoch timer', end_epoch-start_epoch)\n",
    "        #break\n",
    "\n",
    "    print(f'Best Validation Accuracy: {best_acc:.3f}')\n",
    "    \n",
    "    # build dictionary to return values\n",
    "    marginalization_dict = {}\n",
    "    marginalization_dict['accuracy_train_leaf_hist'] = accuracy_train_leaf_hist\n",
    "    marginalization_dict['accuracy_train_internal_hist'] = accuracy_train_internal_hist\n",
    "    \n",
    "    marginalization_dict['loss_train_hist'] = loss_train_hist\n",
    "    \n",
    "    marginalization_dict['loss_train_leaf_hist'] = loss_train_leaf_hist\n",
    "    marginalization_dict['loss_train_internal_hist'] = loss_train_parents_hist\n",
    "\n",
    "    marginalization_dict['accuracy_val_leaf_hist'] = accuracy_val_leaf_hist\n",
    "    marginalization_dict['accuracy_val_internal_hist'] = accuracy_val_internal_hist\n",
    "\n",
    "    marginalization_dict['loss_val_hist'] = loss_val_hist\n",
    "\n",
    "    marginalization_dict['loss_val_leaf_hist'] = loss_val_leaf_hist\n",
    "    marginalization_dict['loss_val_internal_hist'] = loss_val_parents_hist\n",
    "    \n",
    "    marginalization_dict['f1_score_train_leaf'] = f1_score_train_leaf\n",
    "    marginalization_dict['f1_score_val_leaf'] = f1_score_val_leaf\n",
    "    \n",
    "    marginalization_dict['f1_score_train_internal'] = f1_score_train_parent\n",
    "    marginalization_dict['f1_score_val_internal'] = f1_score_val_parent\n",
    "\n",
    "    marginalization_dict['best_output'] = best_output\n",
    "    marginalization_dict['best_state_dict'] = best_state_dict\n",
    "\n",
    "\n",
    "    return marginalization_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0768f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 88 leafs and 55 parents.\n",
      "Number of training batches is 8518.84\n",
      "Number of validation batches is 2129.71\n",
      "Prediction threshold for internal nodes is 0.5\n",
      "start train batching\n",
      "on batch 0 running time 202.0083990097046\n",
      "on batch 100 running time 381.976482629776\n",
      "on batch 200 running time 451.0890326499939\n",
      "on batch 300 running time 635.6067895889282\n",
      "on batch 400 running time 798.1238715648651\n",
      "on batch 500 running time 872.8309845924377\n",
      "on batch 600 running time 1050.8959746360779\n",
      "on batch 700 running time 1167.6235990524292\n",
      "on batch 800 running time 1349.3635840415955\n",
      "on batch 900 running time 1524.7903490066528\n",
      "on batch 1000 running time 1676.839144706726\n",
      "on batch 1100 running time 1822.2817788124084\n",
      "on batch 1200 running time 1969.8034255504608\n",
      "on batch 1300 running time 2136.367960691452\n",
      "on batch 1400 running time 2253.20850110054\n",
      "on batch 1500 running time 2372.458888053894\n",
      "on batch 1600 running time 2535.5160615444183\n",
      "on batch 1700 running time 2681.814965724945\n",
      "on batch 1800 running time 2805.586553812027\n",
      "on batch 1900 running time 3000.3583896160126\n",
      "on batch 2000 running time 3174.5193223953247\n",
      "on batch 2100 running time 3323.556310415268\n",
      "on batch 2200 running time 3401.4595341682434\n",
      "on batch 2300 running time 3569.907839536667\n",
      "on batch 2400 running time 3748.0082819461823\n",
      "on batch 2500 running time 3860.160757780075\n",
      "on batch 2600 running time 4032.259093284607\n",
      "on batch 2700 running time 4213.459141731262\n",
      "on batch 2800 running time 4285.412585020065\n",
      "on batch 2900 running time 4453.607020616531\n",
      "on batch 3000 running time 4580.4920353889465\n",
      "on batch 3100 running time 4686.521691083908\n",
      "on batch 3200 running time 4814.668521165848\n",
      "on batch 3300 running time 4957.318863868713\n",
      "on batch 3400 running time 5089.026100158691\n",
      "on batch 3500 running time 5597.786132335663\n",
      "on batch 3600 running time 5708.817826271057\n",
      "on batch 3700 running time 5882.197132110596\n",
      "on batch 3800 running time 6022.437375068665\n",
      "on batch 3900 running time 6289.151829004288\n",
      "on batch 4000 running time 6429.87001824379\n",
      "on batch 4100 running time 6519.877661943436\n",
      "on batch 4200 running time 6669.190592765808\n",
      "on batch 4300 running time 6947.45943069458\n",
      "on batch 4400 running time 7074.8651785850525\n",
      "on batch 4500 running time 7244.005796909332\n",
      "on batch 4600 running time 7447.69517326355\n",
      "on batch 4700 running time 7597.65932059288\n",
      "on batch 4800 running time 7764.668199300766\n",
      "on batch 4900 running time 7863.457050085068\n",
      "on batch 5000 running time 7994.820309877396\n",
      "on batch 5100 running time 8166.4258279800415\n",
      "on batch 5200 running time 8253.92250585556\n",
      "on batch 5300 running time 8447.968827009201\n",
      "on batch 5400 running time 8618.622753620148\n",
      "on batch 5500 running time 8699.397257566452\n",
      "on batch 5600 running time 8833.456830978394\n",
      "on batch 5700 running time 8995.407243728638\n",
      "on batch 5800 running time 9111.23413491249\n",
      "on batch 5900 running time 9239.178466558456\n",
      "on batch 6000 running time 9345.538108825684\n",
      "on batch 6100 running time 9496.953994989395\n",
      "on batch 6200 running time 9658.64952468872\n",
      "on batch 6300 running time 9775.760281562805\n",
      "on batch 6400 running time 10007.957605361938\n",
      "on batch 6500 running time 10121.93762922287\n",
      "on batch 6600 running time 10551.166859149933\n",
      "on batch 6700 running time 10737.884947776794\n",
      "on batch 6800 running time 10892.59723997116\n",
      "on batch 6900 running time 11013.281252861023\n",
      "on batch 7000 running time 11134.131103038788\n",
      "on batch 7100 running time 11318.971102952957\n",
      "on batch 7200 running time 11431.05188202858\n",
      "on batch 7300 running time 11575.631966590881\n",
      "on batch 7400 running time 11732.084338188171\n",
      "on batch 7500 running time 11843.093114852905\n",
      "on batch 7600 running time 11989.656837701797\n",
      "on batch 7700 running time 12153.705117225647\n",
      "on batch 7800 running time 12244.95249080658\n",
      "on batch 7900 running time 12399.410164117813\n",
      "on batch 8000 running time 12896.251542806625\n",
      "on batch 8100 running time 13042.674187660217\n",
      "on batch 8200 running time 13219.58397102356\n",
      "on batch 8300 running time 13368.089757680893\n",
      "on batch 8400 running time 13510.992436170578\n",
      "on batch 8500 running time 13516.850216388702\n",
      "done with training\n",
      "start validation\n",
      "start validation batching\n",
      "on batch 0 running time 186.1365945339203\n",
      "on batch 100 running time 590.7850410938263\n",
      "on batch 200 running time 1077.8253433704376\n",
      "on batch 300 running time 1624.5823867321014\n",
      "on batch 400 running time 2179.615324497223\n",
      "on batch 500 running time 2668.2279319763184\n",
      "on batch 600 running time 3361.876443386078\n",
      "on batch 700 running time 3834.412910938263\n",
      "on batch 800 running time 4898.170814037323\n",
      "on batch 900 running time 5560.628427505493\n",
      "on batch 1000 running time 6208.399557828903\n",
      "on batch 1100 running time 6878.787623167038\n",
      "on batch 1200 running time 7352.041923761368\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "number_of_leafs = len(leaf_values)\n",
    "number_of_parents = len(internal_values)\n",
    "\n",
    "print('There are', number_of_leafs, 'leafs and', number_of_parents, 'parents.')\n",
    "\n",
    "print('Number of training batches is {:.2f}'.format(experiment_datapipe.shape[0]*train_percent/batch_size))\n",
    "print('Number of validation batches is {:.2f}'.format(experiment_datapipe.shape[0]*val_percent/batch_size))\n",
    "\n",
    "# create dataframe that only includes leaf nodes\n",
    "ontology_leaf_df = ontology_df[leaf_values]\n",
    "\n",
    "# Create dictionary to map between two different types of encoded values\n",
    "# get the encoder from the datapipe\n",
    "cell_type_encoder = experiment_datapipe.obs_encoders[\"cell_type_ontology_term_id\"]\n",
    "\n",
    "# build the dictionary of encoded values from the datapipe\n",
    "encoder_mapping_dict = dict(zip(cell_type_encoder.classes_,cell_type_encoder.transform(cell_type_encoder.classes_)))\n",
    "\n",
    "# build the dictionary mapping from encoder_mapping_dict (keys) to mapping_dict (values)\n",
    "encoding_mapper = {}\n",
    "for cell_term in encoder_mapping_dict.keys():\n",
    "    encoding_mapper[encoder_mapping_dict[cell_term]] = mapping_dict[cell_term]\n",
    "\n",
    "\n",
    "# set the prediction threshold for internal nodes\n",
    "threshold = 0.5 #0.8\n",
    "print('Prediction threshold for internal nodes is', threshold)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "marginalization_dict = marginalization_classification_manual_batch(train_dataloader,val_dataloader,\n",
    "                                                                   num_epochs, ontology_leaf_df, batch_size,\n",
    "                                                                  internal_values,mapping_dict,\n",
    "                                                                  ontology_df,threshold, cell_parent_mask,encoding_mapper)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "time_minutes = (end-start)/60.\n",
    "time_hours = (end-start)/3600.\n",
    "\n",
    "print(f'Run time for {num_epochs} epochs was {time_minutes:.2f} minutes ({time_hours:.2f} hours)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb3866",
   "metadata": {},
   "source": [
    "#### Testing running times per batch\n",
    "Note that I'm only running a handful of batches, so this probbably does not account for any extra time needed to load the next batch of data from disk. That would require a longer run, so soma_chunck_size might not really matter here. And there is some variability in how long each batch takes to run. I'm not sure if this is related to disk streaming or not. This is for the full set of 2.7 million cells\n",
    "\n",
    "|batch size | soma chunk size| time per batch (s) | # of batches | time per 1 training epoch (hr) |\n",
    "| -------- | ------- |------ | ----- | ----- |\n",
    "|8192 | 10,000 | 190 | 266 | 14\n",
    "| 32768 | 10,000 | 600 | 66 | 11\n",
    "| 8192 | 20,000 | 180 | 266 | 14\n",
    "| 4096 | 20,000 | 45 | 532 | 6.7\n",
    "| 1024 | 20,000 | 15 | 2129 | 8.8\n",
    "| 512 | 20,000 |  4.5 | 4259  | 5.3\n",
    "| 256 | 20,000 | 1.4  | 8518  | 3.3\n",
    "| 256 | 30,000 |  1.8 | 8518   | 4.4\n",
    "| 128 | 30,000 | 1.06  | 17037  | 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ca2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9a904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36cf22a5",
   "metadata": {},
   "source": [
    "## Save portions of the modeling and visualize results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4945eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get today's date for saving information about this model\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model parameters to a file\n",
    "\n",
    "#marginalization_dict['best_state_dict']\n",
    "\n",
    "model_title = today + '_best_model'\n",
    "\n",
    "torch.save(marginalization_dict['best_state_dict'],model_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the loss/accuracy/f1 scores to a file\n",
    "\n",
    "cols_to_save = ['accuracy_train_leaf_hist','loss_train_hist', \n",
    "                'loss_train_leaf_hist', 'loss_train_internal_hist', \n",
    "                'accuracy_val_leaf_hist', \n",
    "                'loss_val_hist', 'loss_val_leaf_hist', 'loss_val_internal_hist', \n",
    "                'f1_score_train_leaf', 'f1_score_val_leaf',\n",
    "               'f1_score_train_internal','f1_score_val_internal']\n",
    "\n",
    "results_dict = {key: marginalization_dict[key] for key in cols_to_save}\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient='columns')\n",
    "\n",
    "results_df.insert(0,'epoch',range(1,num_epochs+1))\n",
    "\n",
    "results_title = today + '_results.csv'\n",
    "\n",
    "\n",
    "results_df.to_csv(results_title,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70b0081b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marginalization_dict['loss_val_hist']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c32fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = today + '_results.png'\n",
    "\n",
    "# if you want to save the plot\n",
    "plot_results(marginalization_dict,num_epochs,save_title=plot_title)\n",
    "\n",
    "# just display the plot\n",
    "#plot_results(marginalization_dict,num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb849b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4dcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c82cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1592e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c21039bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CL:0000037': 0,\n",
       " 'CL:0000038': 1,\n",
       " 'CL:0000049': 2,\n",
       " 'CL:0000050': 3,\n",
       " 'CL:0000051': 4,\n",
       " 'CL:0000081': 5,\n",
       " 'CL:0000084': 6,\n",
       " 'CL:0000091': 7,\n",
       " 'CL:0000092': 8,\n",
       " 'CL:0000094': 9,\n",
       " 'CL:0000097': 10,\n",
       " 'CL:0000129': 11,\n",
       " 'CL:0000232': 12,\n",
       " 'CL:0000233': 13,\n",
       " 'CL:0000235': 14,\n",
       " 'CL:0000236': 15,\n",
       " 'CL:0000451': 16,\n",
       " 'CL:0000453': 17,\n",
       " 'CL:0000492': 18,\n",
       " 'CL:0000542': 19,\n",
       " 'CL:0000547': 20,\n",
       " 'CL:0000556': 21,\n",
       " 'CL:0000557': 22,\n",
       " 'CL:0000559': 23,\n",
       " 'CL:0000576': 24,\n",
       " 'CL:0000583': 25,\n",
       " 'CL:0000595': 26,\n",
       " 'CL:0000623': 27,\n",
       " 'CL:0000624': 28,\n",
       " 'CL:0000625': 29,\n",
       " 'CL:0000738': 30,\n",
       " 'CL:0000763': 31,\n",
       " 'CL:0000764': 32,\n",
       " 'CL:0000765': 33,\n",
       " 'CL:0000766': 34,\n",
       " 'CL:0000767': 35,\n",
       " 'CL:0000771': 36,\n",
       " 'CL:0000775': 37,\n",
       " 'CL:0000776': 38,\n",
       " 'CL:0000782': 39,\n",
       " 'CL:0000784': 40,\n",
       " 'CL:0000785': 41,\n",
       " 'CL:0000786': 42,\n",
       " 'CL:0000787': 43,\n",
       " 'CL:0000788': 44,\n",
       " 'CL:0000789': 45,\n",
       " 'CL:0000791': 46,\n",
       " 'CL:0000794': 47,\n",
       " 'CL:0000798': 48,\n",
       " 'CL:0000800': 49,\n",
       " 'CL:0000807': 50,\n",
       " 'CL:0000808': 51,\n",
       " 'CL:0000809': 52,\n",
       " 'CL:0000810': 53,\n",
       " 'CL:0000811': 54,\n",
       " 'CL:0000813': 55,\n",
       " 'CL:0000814': 56,\n",
       " 'CL:0000815': 57,\n",
       " 'CL:0000816': 58,\n",
       " 'CL:0000817': 59,\n",
       " 'CL:0000818': 60,\n",
       " 'CL:0000823': 61,\n",
       " 'CL:0000826': 62,\n",
       " 'CL:0000836': 63,\n",
       " 'CL:0000837': 64,\n",
       " 'CL:0000838': 65,\n",
       " 'CL:0000839': 66,\n",
       " 'CL:0000841': 67,\n",
       " 'CL:0000844': 68,\n",
       " 'CL:0000860': 69,\n",
       " 'CL:0000861': 70,\n",
       " 'CL:0000863': 71,\n",
       " 'CL:0000875': 72,\n",
       " 'CL:0000878': 73,\n",
       " 'CL:0000890': 74,\n",
       " 'CL:0000893': 75,\n",
       " 'CL:0000894': 76,\n",
       " 'CL:0000895': 77,\n",
       " 'CL:0000896': 78,\n",
       " 'CL:0000897': 79,\n",
       " 'CL:0000898': 80,\n",
       " 'CL:0000899': 81,\n",
       " 'CL:0000900': 82,\n",
       " 'CL:0000903': 83,\n",
       " 'CL:0000904': 84,\n",
       " 'CL:0000905': 85,\n",
       " 'CL:0000906': 86,\n",
       " 'CL:0000907': 87,\n",
       " 'CL:0000908': 88,\n",
       " 'CL:0000909': 89,\n",
       " 'CL:0000910': 90,\n",
       " 'CL:0000912': 91,\n",
       " 'CL:0000913': 92,\n",
       " 'CL:0000915': 93,\n",
       " 'CL:0000921': 94,\n",
       " 'CL:0000934': 95,\n",
       " 'CL:0000936': 96,\n",
       " 'CL:0000938': 97,\n",
       " 'CL:0000939': 98,\n",
       " 'CL:0000940': 99,\n",
       " 'CL:0000970': 100,\n",
       " 'CL:0000972': 101,\n",
       " 'CL:0000979': 102,\n",
       " 'CL:0000980': 103,\n",
       " 'CL:0000985': 104,\n",
       " 'CL:0000987': 105,\n",
       " 'CL:0000990': 106,\n",
       " 'CL:0001029': 107,\n",
       " 'CL:0001043': 108,\n",
       " 'CL:0001044': 109,\n",
       " 'CL:0001049': 110,\n",
       " 'CL:0001050': 111,\n",
       " 'CL:0001054': 112,\n",
       " 'CL:0001056': 113,\n",
       " 'CL:0001057': 114,\n",
       " 'CL:0001058': 115,\n",
       " 'CL:0001062': 116,\n",
       " 'CL:0001065': 117,\n",
       " 'CL:0001071': 118,\n",
       " 'CL:0001078': 119,\n",
       " 'CL:0001082': 120,\n",
       " 'CL:0001203': 121,\n",
       " 'CL:0002038': 122,\n",
       " 'CL:0002045': 123,\n",
       " 'CL:0002046': 124,\n",
       " 'CL:0002057': 125,\n",
       " 'CL:0002117': 126,\n",
       " 'CL:0002343': 127,\n",
       " 'CL:0002355': 128,\n",
       " 'CL:0002393': 129,\n",
       " 'CL:0002394': 130,\n",
       " 'CL:0002396': 131,\n",
       " 'CL:0002397': 132,\n",
       " 'CL:0002399': 133,\n",
       " 'CL:0002419': 134,\n",
       " 'CL:0002425': 135,\n",
       " 'CL:0002489': 136,\n",
       " 'CL:0002496': 137,\n",
       " 'CL:0002677': 138,\n",
       " 'CL:0002678': 139,\n",
       " 'CL:1001603': 140,\n",
       " 'CL:2000055': 141,\n",
       " 'CL:3000001': 142}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "687a4ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CL:0000763': -9999,\n",
       " 'CL:0000542': -9998,\n",
       " 'CL:0000097': 0,\n",
       " 'CL:0002046': 1,\n",
       " 'CL:0000817': 2,\n",
       " 'CL:0000051': 3,\n",
       " 'CL:0000826': -9997,\n",
       " 'CL:0001029': 4,\n",
       " 'CL:0000990': -9996,\n",
       " 'CL:0000785': -9995,\n",
       " 'CL:0000816': 5,\n",
       " 'CL:0000786': -9994,\n",
       " 'CL:0000784': -9993,\n",
       " 'CL:0000557': 6,\n",
       " 'CL:0000084': -9992,\n",
       " 'CL:0000814': -9991,\n",
       " 'CL:0000837': -9990,\n",
       " 'CL:0000037': 7,\n",
       " 'CL:0000576': -9989,\n",
       " 'CL:0000050': 8,\n",
       " 'CL:0000129': 9,\n",
       " 'CL:0000815': -9988,\n",
       " 'CL:0000912': 10,\n",
       " 'CL:0000940': 11,\n",
       " 'CL:0000623': -9987,\n",
       " 'CL:0000899': 12,\n",
       " 'CL:0000798': -9986,\n",
       " 'CL:0000235': -9985,\n",
       " 'CL:0000775': -9984,\n",
       " 'CL:0000236': -9983,\n",
       " 'CL:0000453': 13,\n",
       " 'CL:0002343': 14,\n",
       " 'CL:0001078': 15,\n",
       " 'CL:3000001': 16,\n",
       " 'CL:0000451': -9982,\n",
       " 'CL:0000094': -9981,\n",
       " 'CL:0000738': -9980,\n",
       " 'CL:0000878': -9979,\n",
       " 'CL:0000972': -9978,\n",
       " 'CL:0000788': 17,\n",
       " 'CL:0000985': 18,\n",
       " 'CL:0000987': 19,\n",
       " 'CL:0000970': 20,\n",
       " 'CL:0000913': 21,\n",
       " 'CL:0000492': -9977,\n",
       " 'CL:0000624': -9976,\n",
       " 'CL:0000909': -9975,\n",
       " 'CL:0000896': -9974,\n",
       " 'CL:0000906': -9973,\n",
       " 'CL:0000905': 22,\n",
       " 'CL:0000890': 23,\n",
       " 'CL:0000860': -9972,\n",
       " 'CL:0000875': -9971,\n",
       " 'CL:0000782': -9970,\n",
       " 'CL:0000863': 24,\n",
       " 'CL:0000767': 25,\n",
       " 'CL:0000583': 26,\n",
       " 'CL:0000625': -9969,\n",
       " 'CL:0000861': -9968,\n",
       " 'CL:1001603': -9967,\n",
       " 'CL:0002399': 27,\n",
       " 'CL:0001071': -9966,\n",
       " 'CL:0000766': -9965,\n",
       " 'CL:0000765': 28,\n",
       " 'CL:0002496': -9964,\n",
       " 'CL:0000898': -9963,\n",
       " 'CL:0001065': -9962,\n",
       " 'CL:0000903': 29,\n",
       " 'CL:0000787': -9961,\n",
       " 'CL:0000813': -9960,\n",
       " 'CL:0000232': -9959,\n",
       " 'CL:0000910': 30,\n",
       " 'CL:0000838': -9958,\n",
       " 'CL:0000839': -9957,\n",
       " 'CL:0000038': 31,\n",
       " 'CL:0000547': 32,\n",
       " 'CL:0002355': 33,\n",
       " 'CL:0002045': 34,\n",
       " 'CL:0000559': 35,\n",
       " 'CL:0001054': -9956,\n",
       " 'CL:0000836': 36,\n",
       " 'CL:0000556': 37,\n",
       " 'CL:0000092': 38,\n",
       " 'CL:0000938': 39,\n",
       " 'CL:0000936': 40,\n",
       " 'CL:0000049': 41,\n",
       " 'CL:0000771': 42,\n",
       " 'CL:0002419': -9955,\n",
       " 'CL:0001082': -9954,\n",
       " 'CL:0002489': -9953,\n",
       " 'CL:0000809': 43,\n",
       " 'CL:0002425': 44,\n",
       " 'CL:0000915': 45,\n",
       " 'CL:0000897': -9952,\n",
       " 'CL:0000789': -9951,\n",
       " 'CL:0000904': 46,\n",
       " 'CL:0000900': 47,\n",
       " 'CL:0002396': 48,\n",
       " 'CL:0000895': 49,\n",
       " 'CL:0000934': 50,\n",
       " 'CL:0000907': 51,\n",
       " 'CL:0002677': 52,\n",
       " 'CL:0000980': 53,\n",
       " 'CL:0002678': 54,\n",
       " 'CL:0000233': 55,\n",
       " 'CL:0001057': 56,\n",
       " 'CL:0000091': 57,\n",
       " 'CL:0000939': 58,\n",
       " 'CL:0001203': -9950,\n",
       " 'CL:0002038': 59,\n",
       " 'CL:0000764': -9949,\n",
       " 'CL:0001062': 60,\n",
       " 'CL:0001056': -9948,\n",
       " 'CL:0000844': 61,\n",
       " 'CL:0001044': 62,\n",
       " 'CL:0000979': 63,\n",
       " 'CL:0001050': 64,\n",
       " 'CL:0002117': 65,\n",
       " 'CL:0002393': 66,\n",
       " 'CL:0000081': -9947,\n",
       " 'CL:0000595': 67,\n",
       " 'CL:0000810': 68,\n",
       " 'CL:0000811': 69,\n",
       " 'CL:0002394': 70,\n",
       " 'CL:2000055': 71,\n",
       " 'CL:0000908': 72,\n",
       " 'CL:0000921': 73,\n",
       " 'CL:0000841': 74,\n",
       " 'CL:0000794': 75,\n",
       " 'CL:0000807': 76,\n",
       " 'CL:0000894': 77,\n",
       " 'CL:0000808': 78,\n",
       " 'CL:0000823': 79,\n",
       " 'CL:0000893': -9946,\n",
       " 'CL:0002057': 80,\n",
       " 'CL:0000791': -9945,\n",
       " 'CL:0002397': 81,\n",
       " 'CL:0000800': 82,\n",
       " 'CL:0001058': 83,\n",
       " 'CL:0000818': 84,\n",
       " 'CL:0001043': 85,\n",
       " 'CL:0001049': 86,\n",
       " 'CL:0000776': 87}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d98802bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be27cda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-9999: 31,\n",
       " -9998: 19,\n",
       " 0: 10,\n",
       " 1: 124,\n",
       " 2: 59,\n",
       " 3: 4,\n",
       " -9997: 62,\n",
       " 4: 107,\n",
       " -9996: 106,\n",
       " -9995: 41,\n",
       " 5: 58,\n",
       " -9994: 42,\n",
       " -9993: 40,\n",
       " 6: 22,\n",
       " -9992: 6,\n",
       " -9991: 56,\n",
       " -9990: 64,\n",
       " 7: 0,\n",
       " -9989: 24,\n",
       " 8: 3,\n",
       " 9: 11,\n",
       " -9988: 57,\n",
       " 10: 91,\n",
       " 11: 99,\n",
       " -9987: 27,\n",
       " 12: 81,\n",
       " -9986: 48,\n",
       " -9985: 14,\n",
       " -9984: 37,\n",
       " -9983: 15,\n",
       " 13: 17,\n",
       " 14: 127,\n",
       " 15: 119,\n",
       " 16: 142,\n",
       " -9982: 16,\n",
       " -9981: 9,\n",
       " -9980: 30,\n",
       " -9979: 73,\n",
       " -9978: 101,\n",
       " 17: 44,\n",
       " 18: 104,\n",
       " 19: 105,\n",
       " 20: 100,\n",
       " 21: 92,\n",
       " -9977: 18,\n",
       " -9976: 28,\n",
       " -9975: 89,\n",
       " -9974: 78,\n",
       " -9973: 86,\n",
       " 22: 85,\n",
       " 23: 74,\n",
       " -9972: 69,\n",
       " -9971: 72,\n",
       " -9970: 39,\n",
       " 24: 71,\n",
       " 25: 35,\n",
       " 26: 25,\n",
       " -9969: 29,\n",
       " -9968: 70,\n",
       " -9967: 140,\n",
       " 27: 133,\n",
       " -9966: 118,\n",
       " -9965: 34,\n",
       " 28: 33,\n",
       " -9964: 137,\n",
       " -9963: 80,\n",
       " -9962: 117,\n",
       " 29: 83,\n",
       " -9961: 43,\n",
       " -9960: 55,\n",
       " -9959: 12,\n",
       " 30: 90,\n",
       " -9958: 65,\n",
       " -9957: 66,\n",
       " 31: 1,\n",
       " 32: 20,\n",
       " 33: 128,\n",
       " 34: 123,\n",
       " 35: 23,\n",
       " -9956: 112,\n",
       " 36: 63,\n",
       " 37: 21,\n",
       " 38: 8,\n",
       " 39: 97,\n",
       " 40: 96,\n",
       " 41: 2,\n",
       " 42: 36,\n",
       " -9955: 134,\n",
       " -9954: 120,\n",
       " -9953: 136,\n",
       " 43: 52,\n",
       " 44: 135,\n",
       " 45: 93,\n",
       " -9952: 79,\n",
       " -9951: 45,\n",
       " 46: 84,\n",
       " 47: 82,\n",
       " 48: 131,\n",
       " 49: 77,\n",
       " 50: 95,\n",
       " 51: 87,\n",
       " 52: 138,\n",
       " 53: 103,\n",
       " 54: 139,\n",
       " 55: 13,\n",
       " 56: 114,\n",
       " 57: 7,\n",
       " 58: 98,\n",
       " -9950: 121,\n",
       " 59: 122,\n",
       " -9949: 32,\n",
       " 60: 116,\n",
       " -9948: 113,\n",
       " 61: 68,\n",
       " 62: 109,\n",
       " 63: 102,\n",
       " 64: 111,\n",
       " 65: 126,\n",
       " 66: 129,\n",
       " -9947: 5,\n",
       " 67: 26,\n",
       " 68: 53,\n",
       " 69: 54,\n",
       " 70: 130,\n",
       " 71: 141,\n",
       " 72: 88,\n",
       " 73: 94,\n",
       " 74: 67,\n",
       " 75: 47,\n",
       " 76: 50,\n",
       " 77: 76,\n",
       " 78: 51,\n",
       " 79: 61,\n",
       " -9946: 75,\n",
       " 80: 125,\n",
       " -9945: 46,\n",
       " 81: 132,\n",
       " 82: 49,\n",
       " 83: 115,\n",
       " 84: 60,\n",
       " 85: 108,\n",
       " 86: 110,\n",
       " 87: 38}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd2142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d75f938d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CL:0000037', 'CL:0000038', 'CL:0000049', 'CL:0000050',\n",
       "       'CL:0000051', 'CL:0000081', 'CL:0000084', 'CL:0000091',\n",
       "       'CL:0000092', 'CL:0000094', 'CL:0000097', 'CL:0000129',\n",
       "       'CL:0000232', 'CL:0000233', 'CL:0000235', 'CL:0000236',\n",
       "       'CL:0000451', 'CL:0000453', 'CL:0000492', 'CL:0000542',\n",
       "       'CL:0000547', 'CL:0000556', 'CL:0000557', 'CL:0000559',\n",
       "       'CL:0000576', 'CL:0000583', 'CL:0000595', 'CL:0000623',\n",
       "       'CL:0000624', 'CL:0000625', 'CL:0000738', 'CL:0000763',\n",
       "       'CL:0000764', 'CL:0000765', 'CL:0000766', 'CL:0000767',\n",
       "       'CL:0000771', 'CL:0000775', 'CL:0000776', 'CL:0000782',\n",
       "       'CL:0000784', 'CL:0000785', 'CL:0000786', 'CL:0000787',\n",
       "       'CL:0000788', 'CL:0000789', 'CL:0000791', 'CL:0000794',\n",
       "       'CL:0000798', 'CL:0000800', 'CL:0000807', 'CL:0000808',\n",
       "       'CL:0000809', 'CL:0000810', 'CL:0000811', 'CL:0000813',\n",
       "       'CL:0000814', 'CL:0000815', 'CL:0000816', 'CL:0000817',\n",
       "       'CL:0000818', 'CL:0000823', 'CL:0000826', 'CL:0000836',\n",
       "       'CL:0000837', 'CL:0000838', 'CL:0000839', 'CL:0000841',\n",
       "       'CL:0000844', 'CL:0000860', 'CL:0000861', 'CL:0000863',\n",
       "       'CL:0000875', 'CL:0000878', 'CL:0000890', 'CL:0000893',\n",
       "       'CL:0000894', 'CL:0000895', 'CL:0000896', 'CL:0000897',\n",
       "       'CL:0000898', 'CL:0000899', 'CL:0000900', 'CL:0000903',\n",
       "       'CL:0000904', 'CL:0000905', 'CL:0000906', 'CL:0000907',\n",
       "       'CL:0000908', 'CL:0000909', 'CL:0000910', 'CL:0000912',\n",
       "       'CL:0000913', 'CL:0000915', 'CL:0000921', 'CL:0000934',\n",
       "       'CL:0000936', 'CL:0000938', 'CL:0000939', 'CL:0000940',\n",
       "       'CL:0000970', 'CL:0000972', 'CL:0000979', 'CL:0000980',\n",
       "       'CL:0000985', 'CL:0000987', 'CL:0000990', 'CL:0001029',\n",
       "       'CL:0001043', 'CL:0001044', 'CL:0001049', 'CL:0001050',\n",
       "       'CL:0001054', 'CL:0001056', 'CL:0001057', 'CL:0001058',\n",
       "       'CL:0001062', 'CL:0001065', 'CL:0001071', 'CL:0001078',\n",
       "       'CL:0001082', 'CL:0001203', 'CL:0002038', 'CL:0002045',\n",
       "       'CL:0002046', 'CL:0002057', 'CL:0002117', 'CL:0002343',\n",
       "       'CL:0002355', 'CL:0002393', 'CL:0002394', 'CL:0002396',\n",
       "       'CL:0002397', 'CL:0002399', 'CL:0002419', 'CL:0002425',\n",
       "       'CL:0002489', 'CL:0002496', 'CL:0002677', 'CL:0002678',\n",
       "       'CL:1001603', 'CL:2000055', 'CL:3000001'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13d65d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LabelEncoder in module sklearn.preprocessing._label object:\n",
      "\n",
      "class LabelEncoder(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  Encode target labels with value between 0 and n_classes-1.\n",
      " |  \n",
      " |  This transformer should be used to encode target values, *i.e.* `y`, and\n",
      " |  not the input `X`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_targets>`.\n",
      " |  \n",
      " |  .. versionadded:: 0.12\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      Holds the label for each class.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  OrdinalEncoder : Encode categorical features using an ordinal encoding\n",
      " |      scheme.\n",
      " |  OneHotEncoder : Encode categorical features as a one-hot numeric array.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  `LabelEncoder` can be used to normalize labels.\n",
      " |  \n",
      " |  >>> from sklearn import preprocessing\n",
      " |  >>> le = preprocessing.LabelEncoder()\n",
      " |  >>> le.fit([1, 2, 2, 6])\n",
      " |  LabelEncoder()\n",
      " |  >>> le.classes_\n",
      " |  array([1, 2, 6])\n",
      " |  >>> le.transform([1, 1, 2, 6])\n",
      " |  array([0, 0, 1, 2]...)\n",
      " |  >>> le.inverse_transform([0, 0, 1, 2])\n",
      " |  array([1, 1, 2, 6])\n",
      " |  \n",
      " |  It can also be used to transform non-numerical labels (as long as they are\n",
      " |  hashable and comparable) to numerical labels.\n",
      " |  \n",
      " |  >>> le = preprocessing.LabelEncoder()\n",
      " |  >>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
      " |  LabelEncoder()\n",
      " |  >>> list(le.classes_)\n",
      " |  ['amsterdam', 'paris', 'tokyo']\n",
      " |  >>> le.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
      " |  array([2, 2, 1]...)\n",
      " |  >>> list(le.inverse_transform([2, 2, 1]))\n",
      " |  ['tokyo', 'tokyo', 'paris']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LabelEncoder\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  fit(self, y)\n",
      " |      Fit label encoder.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |          Fitted label encoder.\n",
      " |  \n",
      " |  fit_transform(self, y)\n",
      " |      Fit label encoder and return encoded labels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Encoded labels.\n",
      " |  \n",
      " |  inverse_transform(self, y)\n",
      " |      Transform labels back to original encoding.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          Original encoding.\n",
      " |  \n",
      " |  transform(self, y)\n",
      " |      Transform labels to normalized encoding.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Labels as normalized encodings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |      \n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |      \n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from builtins.type\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cell_type_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47897d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f58d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1860a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
