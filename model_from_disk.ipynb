{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf4e25ff",
   "metadata": {},
   "source": [
    "Tutorial from https://chanzuckerberg.github.io/cellxgene-census/notebooks/experimental/pytorch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b822fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellxgene_census\n",
    "import cellxgene_census.experimental.ml as census_ml\n",
    "import tiledbsoma as soma\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from torcheval.metrics.functional import multilabel_accuracy\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(style='whitegrid')\n",
    "sns.set_context(context='notebook')\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc(\n",
    "    'axes',\n",
    "    labelweight='bold',\n",
    "    labelsize='large',\n",
    "    titleweight='bold',\n",
    "    titlesize=9,\n",
    "    linewidth=4\n",
    "    )\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9355266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dba2fb",
   "metadata": {},
   "source": [
    "## Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ed289f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(marginalization_dict,num_epochs,save_title=None):\n",
    "    fig, ax = plt.subplots(4,2,figsize=(9,12))\n",
    "    \n",
    "    \n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['accuracy_train_leaf_hist'], \n",
    "                    ax = ax[0,0],color='lightcoral',label='Train')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['accuracy_val_leaf_hist'], \n",
    "                    ax = ax[0,0],color='mediumslateblue',label='Validation')\n",
    "    \n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['accuracy_train_internal_hist'],\n",
    "                   ax = ax[0,1],color='lightcoral',label='Train')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['accuracy_val_internal_hist'],\n",
    "                   ax = ax[0,1],color='mediumslateblue',label='Validation')\n",
    "    \n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_train_hist'], \n",
    "                    ax = ax[1,0],color='lightcoral')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_val_hist'], \n",
    "                    ax = ax[1,0],color='mediumslateblue')\n",
    "    \n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_train_leaf_hist'], \n",
    "                    ax = ax[1,1],color='lightcoral',marker='X',label='Train Leafs')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_train_internal_hist'], \n",
    "                    ax = ax[1,1],color='lightcoral',marker='o',label='Train Internal')\n",
    "    #sns.scatterplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_train_internal_hist'], \n",
    "    #                ax = ax[1,0],color='lightcoral',marker='v',label='Train Internal')\n",
    "\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_val_leaf_hist'], \n",
    "                    ax = ax[2,0],color='mediumslateblue',marker='X',label='Val Leafs')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_val_internal_hist'], \n",
    "                    ax = ax[2,0],color='mediumslateblue',marker='o',label='Val Internal')\n",
    "    #sns.scatterplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_val_internal_hist'], \n",
    "    #                ax = ax[1,1],color='mediumslateblue',marker='v',label='Val Internal')\n",
    "\n",
    "\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['f1_score_train_leaf'], \n",
    "                    ax = ax[2,1],color='lightcoral',label='Train')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['f1_score_val_leaf'], \n",
    "                    ax = ax[2,1],color='mediumslateblue',label='Validation')\n",
    "\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['f1_score_train_internal'], \n",
    "                    ax = ax[3,0],color='lightcoral',label='Train')\n",
    "    sns.lineplot(x=range(1,num_epochs+1),y=marginalization_dict['f1_score_val_internal'], \n",
    "                    ax = ax[3,0],color='mediumslateblue',label='Validation')\n",
    "\n",
    "    \n",
    "    ax[0,0].set_xlabel('Epoch')\n",
    "    ax[0,1].set_xlabel('Epoch')\n",
    "    ax[1,0].set_xlabel('Epoch')\n",
    "    ax[1,1].set_xlabel('Epoch')\n",
    "    ax[2,0].set_xlabel('Epoch')\n",
    "    ax[2,1].set_xlabel('Epoch')\n",
    "    ax[3,0].set_xlabel('Epoch')\n",
    "\n",
    "\n",
    "    ax[0,0].set_ylabel('Leaf Accuracy')\n",
    "    ax[0,1].set_ylabel('Internal Accuracy')\n",
    "    ax[1,0].set_ylabel('Total Loss')\n",
    "    ax[1,1].set_ylabel('Training Loss')\n",
    "    ax[2,0].set_ylabel('Validation Loss')\n",
    "    ax[2,1].set_ylabel('Leaf F1 Score')\n",
    "    ax[3,0].set_ylabel('Internal F1 Score')\n",
    "\n",
    "\n",
    "    # set the boundary for the accuracy plots\n",
    "    #ax[0,1].set_ylim((50,100))\n",
    "    \n",
    "    # turn off the axis for subplot 2,1\n",
    "    ax[3,1].axis('off')\n",
    "    \n",
    "    if save_title:\n",
    "        plt.savefig(save_title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e491b4",
   "metadata": {},
   "source": [
    "## Load the Saved Outputs from McCell_preprocessing\n",
    "\n",
    "The preproccessing and modeling here should be run on the **same dataset**. If not, there might be differences in the ordering of cells the would nullify this model. \n",
    "\n",
    "- cell_parent_mask\n",
    "- Mapping_dict\n",
    "- Ontology_df\n",
    "- Internal_values\n",
    "- leaf_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531a2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing outputs are normally stored on Turbo\n",
    "os.chdir('/nfs/turbo/umms-welchjd/mccell/preprocessing_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c952ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the date in yyyy-mm-dd format\n",
    "date = '2024-03-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea04d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_df_name = date + '_ontology_df.csv'\n",
    "ontology_df = pd.read_csv(ontology_df_name,index_col=0)\n",
    "\n",
    "\n",
    "mapping_dict_name = date + '_mapping_dict_df.csv'\n",
    "mapping_dict_df = pd.read_csv(mapping_dict_name,index_col=0)\n",
    "mapping_dict = mapping_dict_df.T.to_dict('list')\n",
    "# the values are stored as a list. convert to single value\n",
    "for key, value in mapping_dict.items():\n",
    "    mapping_dict[key] = value[0]\n",
    "\n",
    "leaf_values_name = date + '_leaf_values'\n",
    "internal_values_name = date + '_internal_values'\n",
    "with open(leaf_values_name,'rb') as fp:\n",
    "    leaf_values = pickle.load(fp)\n",
    "with open(internal_values_name,'rb') as fp:\n",
    "    internal_values = pickle.load(fp)\n",
    "\n",
    "\n",
    "cell_parent_mask_name = date + '_cell_parent_mask.pt'\n",
    "cell_parent_mask = torch.load(cell_parent_mask_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caceac8",
   "metadata": {},
   "source": [
    "## Build the Experiment and the DataPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5274b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene and cell type info stored on Turbo\n",
    "os.chdir('/nfs/turbo/umms-welchjd/mccell')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2d95a",
   "metadata": {},
   "source": [
    "First, let's load the gene list and cell type list that we want from the Census. Then we construct the ```var_val_filter``` and ```obs_val_filter``` for querying the census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91823465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gene list\n",
    "biomart = pd.read_csv('mart_export.txt')\n",
    "\n",
    "coding_only = biomart[biomart['Gene type'] == 'protein_coding']\n",
    "\n",
    "gene_list = coding_only['Gene stable ID'].to_list()\n",
    "\n",
    "var_val_filter = '''feature_id in {}'''.format(gene_list)\n",
    "\n",
    "# load the cell type list\n",
    "cell_type_list_name = 'cell_type_list.txt'\n",
    "with open(cell_type_list_name,'rb') as fp:\n",
    "    cell_type_list = pickle.load(fp)\n",
    "\n",
    "obs_val_filter = '''assay == \"10x 3\\' v3\" and is_primary_data == True and cell_type_ontology_term_id in {}'''.format(cell_type_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f26d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#organism = \"Homo sapiens\"\n",
    "col_names = {\"obs\": [\"cell_type_ontology_term_id\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192a33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the Census and create the Experiment\n",
    "census = cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\")\n",
    "experiment = census[\"census_data\"][\"homo_sapiens\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "437e76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512 #128 #8192 # 4096\n",
    "soma_chunk_size = 10_000 #10_000\n",
    "\n",
    "experiment_datapipe = census_ml.ExperimentDataPipe(\n",
    "    experiment,\n",
    "    measurement_name=\"RNA\",\n",
    "    X_name=\"raw\",\n",
    "    obs_query=soma.AxisQuery(value_filter=obs_val_filter),\n",
    "    var_query=soma.AxisQuery(value_filter=var_val_filter),\n",
    "    obs_column_names=[\"cell_type_ontology_term_id\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    soma_chunk_size=soma_chunk_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54f2e94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2726029, 19966)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_datapipe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195167e",
   "metadata": {},
   "source": [
    "Split the datapipe into Train and Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1373237",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.0006\n",
    "val_percent = 0.0004\n",
    "extra_percent = 0.999 # use this to reduce the size of the dataset\n",
    "\n",
    "train_datapipe, val_datapipe = experiment_datapipe.random_split(weights={\"train\": train_percent, \"val\": val_percent},\n",
    "                                                                seed=42)\n",
    "#train_datapipe, val_datapipe, test_datapipe = experiment_datapipe.random_split(weights={\"train\": train_percent, \"test\": val_percent,'val':extra_percent},\n",
    "#                                                                seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f5e6e",
   "metadata": {},
   "source": [
    "Build the dataloaders for the train and test splits. We don't use PyTorch ```DataLoader``` directly because the ```ExperimentDataPipe``` already deals with the necessary parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15b58334",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = census_ml.experiment_dataloader(train_datapipe)\n",
    "val_dataloader = census_ml.experiment_dataloader(val_datapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fca5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd854341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66c1fc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IterDataPipeSerializationWrapper"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_dataloader.size\n",
    "#print(len(train_dataloader.dataset))\n",
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "453e07d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 395.4807653427124\n"
     ]
    }
   ],
   "source": [
    "start_batch = time.time()\n",
    "for batch in train_dataloader:\n",
    "    print('running time', (time.time()-start_batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b38d1747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 353.2778468132019\n"
     ]
    }
   ],
   "source": [
    "start_batch = time.time()\n",
    "for batch in val_dataloader:\n",
    "    print('running time', (time.time()-start_batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c8c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecae61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00ada2e8",
   "metadata": {},
   "source": [
    "## Build Neural Network Classifier\n",
    "\n",
    "First, we need to select and define the input and output dimensions from the data. The number of neurons for the hidden nodes is defined manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07043911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19966 256 128 88\n"
     ]
    }
   ],
   "source": [
    "# number of features (len of X cols)\n",
    "# select the number of gene columns\n",
    "input_dim = experiment_datapipe.shape[1]#X_train.size(dim=1) #adata.X.shape[1] \n",
    "\n",
    "# number of neurons for hidden layers\n",
    "hidden_layer_1 = 256\n",
    "hidden_layer_2 = 128\n",
    "\n",
    "# number of leaf classes (unique of y that are greater than or equal to 0)\n",
    "output_dim = len(leaf_values) #torch.unique(y_train[y_train >= 0]).size(dim=0) #labels['encoded_labels'].nunique()\n",
    "\n",
    "print(input_dim,hidden_layer_1,hidden_layer_2,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d64bec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim,hidden_layer_1)\n",
    "        self.linear2 = nn.Linear(hidden_layer_1,hidden_layer_2)\n",
    "        self.linear3 = nn.Linear(hidden_layer_2,output_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_layer_1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_layer_2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "    \n",
    "    def get_last_layer(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf977d",
   "metadata": {},
   "source": [
    "## Functions for dealing with cell ontology and loss calculations\n",
    "\n",
    "We'll need a few specific functions to process the predicted values with the structure of the Cell Ontology. We'll define these here. Full details of each function are found in each space. \n",
    "\n",
    "- output_probability_tensor: convolves the predicted classification outputs with the ontology hierarchy to get predicted normalized probabilities for all parent nodes\n",
    "- target_probability_tensor: convolves the known target values with the ontology hierarchy to get target probabilities for all parent nodes\n",
    "- build_mask_tensor_for_batch : builds a masking tensor from cell_parent_mask specific to the targets for each batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a022561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(x_data):\n",
    "    '''\n",
    "    This function takes the input x_data, transforms the data with log(1+x) and \n",
    "    returns the transformed data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_data : scipy matrix\n",
    "        scipy sparse CSR matrix  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x_data : SciPy Matrix\n",
    "        scipy sparse CSR matrix\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # np.log takes the natural log\n",
    "    x_data.data = np.log(1+ x_data.data)\n",
    "\n",
    "    return x_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83a3c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_probability_tensor(outputs,ontology_df):\n",
    "    '''\n",
    "    Function to convolve the predicted classification outputs with the ontology heirarchy to\n",
    "    get predicted normalized probabilities for all parents. \n",
    "    Precursur to loss calculation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    outputs : tensor\n",
    "        PyTorch tensor of shape [a,b] where a = number of cells and b = number of target leafs\n",
    "        This tensor is the result of the classification in the neural network\n",
    "                \n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where rows are parent labels and columns are leafs\n",
    "        values indicate if parent node is an ancestor of leaf node\n",
    "\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    sum_probability_tensor : tensor\n",
    "        PyTorch tensor of shape [c,a] where c = number of cell ontology IDs and a = number of cells\n",
    "        Each entry is the summed predicted probability for that cell ID\n",
    "\n",
    "    '''\n",
    "        \n",
    "    # convert the dataframe to a pytorch tensor\n",
    "    ontology_tensor = torch.FloatTensor(ontology_df.values)\n",
    "    ontology_tensor = ontology_tensor.to(device)\n",
    "        \n",
    "    # convolve the ontology tensor with the predicted outputs\n",
    "    # ontology tensor is shape ij, where i = parent IDs, j = probability for leaf IDs\n",
    "    # output tensor is shape kj, where k = number of cells classified, j = probability for leaf IDs\n",
    "    # probability tensor is shape ijk\n",
    "    \n",
    "    # if there is only a single column for the ontology, change shape to match expected value\n",
    "    if len(ontology_tensor.shape) == 1:\n",
    "        ontology_tensor = ontology_tensor.unsqueeze(1)    \n",
    "    #print(ontology_tensor.shape)\n",
    "    #print(outputs.shape)\n",
    "    probability_tensor = torch.einsum('ij,kj->ijk',ontology_tensor,outputs)\n",
    "    #print('prob_tensor', probability_tensor.shape)\n",
    "    \n",
    "    # sum across leafs to get the predicted probability, by cell, for each\n",
    "    # parent \n",
    "    # sum_probability_tensor is shape ik, where i = parent IDs, k = number of cells\n",
    "    sum_probability_tensor = torch.sum(probability_tensor,dim=1,dtype=float)\n",
    "    \n",
    "    ##sum_masked_probability_tensor = sum_probability_tensor * batch_masking_tensor\n",
    "    #print('sum masked',sum_masked_probability_tensor.shape)\n",
    "    #print('sum masked',sum_masked_probability_tensor.sum(dim=1))\n",
    "    # ensure that the max value is 1 because of floating point issues\n",
    "    # if we don't do this, we can run into errors with the binary cross entropy\n",
    "    ##sum_masked_probability_tensor = torch.where(sum_masked_probability_tensor > 1, 1.0, sum_masked_probability_tensor )\n",
    "    sum_probability_tensor = torch.where(sum_probability_tensor > 1, 1.0, sum_probability_tensor )\n",
    "\n",
    "    return sum_probability_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0e3aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mask_tensor_for_batch(cell_parent_mask,y_batch,min_encoded_value,max_encoded_value):\n",
    "    '''\n",
    "    For each batch, this function builds the correct masking tensor based on which\n",
    "    values of the cell ontology we want to include given the target. It returns aa \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cell_parent_mask : tensor\n",
    "        tensor of shape ik, where i = parent IDs and k = each cell type in the dataset\n",
    "        binary tensor where 1 means for that cell type, that parent ID will be included\n",
    "        in the internal loss calculation\n",
    "        and 0 means for that cell type, that parent ID is excluded in the internal loss\n",
    "        calculation\n",
    "                \n",
    "    y_batch : tensor\n",
    "        tensor with encoded target values for current batch of data\n",
    "        \n",
    "    min_encoded_value : int\n",
    "        the minimum encoded value from the full set of target values. Typically -9999\n",
    "        \n",
    "    max_encoded_value : int\n",
    "        the maximum encoded value from the full set of target values. Depends on number\n",
    "        of leaf targets in the dataset\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    batch_masking_tensor : tensor\n",
    "        PyTorch tensor of shape [c,a] where c = number of cell ontology IDs and a = number of cells\n",
    "        Binary tensor to zero out probabilities we do not want\n",
    "    \n",
    "    '''\n",
    "    # 1) from y_batch, we need to get the indices we'll use to select from cell_parent_mask\n",
    "    #.   all the positive values are each, but we need to convert the negative values to\n",
    "    #.   correspond with the (positive) index they would otherwise be. Then save to a tensor\n",
    "    \n",
    "    for value in y_batch:\n",
    "        if value >= 0:\n",
    "            new_value = value\n",
    "        else:\n",
    "            new_value = (value - min_encoded_value) + max_encoded_value + 1\n",
    "        try:\n",
    "            converted_y_batch = torch.cat((converted_y_batch,new_value.reshape(1)),dim=0)\n",
    "        except:\n",
    "            converted_y_batch = new_value.reshape(1)\n",
    "    \n",
    "    \n",
    "    # 2) use the y_batch converted values to build a new tensor from cell_parent_mask\n",
    "    #.    that is the mask we will use for this batch of values.\n",
    "    #.    return this tensor\n",
    "\n",
    "    cell_parent_mask = cell_parent_mask.to(device)\n",
    "    batch_masking_tensor = torch.index_select(cell_parent_mask,1,converted_y_batch)\n",
    "    #print(batch_masking_tensor.sum(dim=0))\n",
    "    \n",
    "    return(batch_masking_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47cb3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_probability_tensor(target_values,ontology_df,mapping_dict):\n",
    "    '''\n",
    "    Function to convolve the known target values with the ontology heirarchy\n",
    "    Precursur to loss calculation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    target_values : tensor\n",
    "        PyTorch tensor of shape [a] where a = number of cells\n",
    "                \n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where rows are parent labels and columns are leafs\n",
    "        values indicate if parent node is an ancestor of leaf node\n",
    "\n",
    "    mapping_dict : dictionary\n",
    "        dictionary mapping the Cell Ontology IDs (keys) to the encoded values (values)\n",
    "        Values >= 0 are leaf nodes\n",
    "        Values < 0 are internal nodes\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    target_tensor : tensor\n",
    "        PyTorch tensor of shape [c,a] where c = number of cell ontology IDs and a = number of cells\n",
    "        Each entry is the summed predicted probability for that cell ID\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # loop through target values, pick out corresponding column of ontology_df\n",
    "    # append that to a tensor\n",
    "    \n",
    "    # invert the mapping dict so that we can select columns by CELL TYPE ID\n",
    "    inv_mapping_dict = {v: k for k,v in mapping_dict.items()}\n",
    "\n",
    "    for count, target_value in enumerate(target_values):\n",
    "        # get the cell ID from the inverted mapping dictionary based on the encoded value\n",
    "        target_cell_id = inv_mapping_dict[target_value.item()]\n",
    "        \n",
    "        # look up the correct column by the Cell ID. get those column values and convert\n",
    "        # to a tensor\n",
    "        sub_target_tensor = torch.tensor(ontology_df.loc[:,target_cell_id].values,dtype=float).reshape(-1,1)\n",
    "        \n",
    "        if count == 0 :\n",
    "            target_tensor = sub_target_tensor\n",
    "        else:\n",
    "            # set requires_grad so that we can track\n",
    "            target_tensor = torch.cat((target_tensor,sub_target_tensor),1).requires_grad_()\n",
    "    #print('target tensor shape',target_tensor.shape)\n",
    "    #print('batch_masking_tensor',batch_masking_tensor.shape)\n",
    "    ###masked_target_tensor = target_tensor * batch_masking_tensor\n",
    "    ##print('masked target tensor',masked_target_tensor.shape)\n",
    "    \n",
    "    target_tensor = target_tensor.to(device)\n",
    "    ###masked_target_tensor = masked_target_tensor.to(device)\n",
    "    \n",
    "    \n",
    "    return target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf08074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e85f3a8f",
   "metadata": {},
   "source": [
    "# Marginalization Classification \n",
    "\n",
    "- Based on Dahll, et al., Hierarchical Image Classification using Entailment Cone Embeddings, CVPR 202\n",
    "- https://arxiv.org/pdf/2004.03459.pdf\n",
    "- Thesis slides: https://ankitdhall.github.io/publication/learning-representations-for-images-with-hierarchical-labels/master_thesis.pdf\n",
    "- First Author website: https://ankitdhall.github.io/project/learning-representations-for-images-with-hierarchical-labels/\n",
    "\n",
    "Important Details:\n",
    "- we use mini-batch learning, with the batch size set by the user\n",
    "- we model each batch of data at once, then split into leaf and internal nodes, based on the values in y_batch\n",
    "- we calculate the loss two different ways, then sum to get the total loss\n",
    "- we calculate and save the loss, accuracy, and F1 score for metrics to review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9dae7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginalization_classification_manual_batch(train_dataloader,val_dataloader,num_epochs,ontology_leaf_df, \n",
    "                                                batch_size,internal_values,mapping_dict,\n",
    "                                               ontology_df, threshold, cell_parent_mask,encoding_mapper):\n",
    "    '''\n",
    "    Performs training and validation simultaneously to allow visualization of model performance \n",
    "    per epoch. Accounts for entire tree structure of the ontology by classifying to the leaf nodes, \n",
    "    propogating the probabilities across the ontology, and calculating the loss for both the leafs \n",
    "    and parent nodes. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : Tensor\n",
    "        pytorch tensor of training values\n",
    "    \n",
    "    X_val : Tensor\n",
    "        pytorch tensor of validation values\n",
    "        \n",
    "    y_train : Tensor\n",
    "        pytorch tensor of training target values\n",
    "        \n",
    "    y_val : Tensor\n",
    "        pytorch tensor of validation target values\n",
    "    \n",
    "    num_epochs : int\n",
    "        integer specify the number of epochs\n",
    "        \n",
    "    ontology_leaf_df : pandas dataframe\n",
    "        pandas dataframe where indices (rows) are all leaf and parent cell IDs from the portion of \n",
    "        the ontology being queried, and columns are onlys leafs in portion of ontology being queried. \n",
    "        Differs from ontology_df in that columns do not include any internal nodes.\n",
    "        \n",
    "        Dataframe is binary. For each parent node, element = 1 if parent node is an ancestor\n",
    "        of corresponding leaf node.\n",
    "    \n",
    "    batch_size : int\n",
    "        integer specificying the number of samples processed before the model\n",
    "        is updated\n",
    "        \n",
    "    internal_values : list\n",
    "        list of Cell Ontology IDs for internal nodes included in the dataset\n",
    "        \n",
    "    mapping_dict : dict\n",
    "        dictionary mapping the Cell Ontology IDs (keys) to the encoded values (values)\n",
    "        Values >= 0 are leaf nodes\n",
    "        Values < 0 are internal nodes\n",
    "    \n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where indices (rows) are all leaf and parent cell IDs from the portion of \n",
    "        the ontology being queried, and columns are leafs and internal nodes in portion of ontology being \n",
    "        queried. \n",
    "        Differs from ontology_leaf_df in that columns include both leaf and internal node values\n",
    "        \n",
    "        Dataframe is binary. For each parent node, element = 1 if parent node is an ancestor\n",
    "        of corresponding leaf node.\n",
    "        \n",
    "    threshold : float\n",
    "        value between 0 and 1 to set for making predictions. If the predicted probability is\n",
    "        equal to or greater than threshold, we consider that a true prediction\n",
    "        \n",
    "    cell_parent_mask : tensor\n",
    "        tensor of shape ik, where i = parent IDs and k = each cell type in the dataset\n",
    "        binary tensor where 1 means for that cell type, that parent ID will be included\n",
    "        in the internal loss calculation\n",
    "        and 0 means for that cell type, that parent ID is excluded in the internal loss\n",
    "        calculation\n",
    "\n",
    "        \n",
    "    Returns\n",
    "    -------    \n",
    "    marginalization_dict : dictionary\n",
    "        dictionary containing results from each epoch of the neural network\n",
    "    \n",
    "    Keys and Values include:\n",
    "    \n",
    "        accuracy_train_leaf_hist : list\n",
    "            list containing accuracy for leaf values for the training set per epoch\n",
    "            \n",
    "        accuracy_train_internal_hist : list\n",
    "            list containing accuracy for internal values for the trainig set per epoch\n",
    "        \n",
    "        loss_train_hist: list\n",
    "            list containing total loss values for the training set per epoch\n",
    "            \n",
    "        loss_train_leaf_hist : list\n",
    "            list containing loss values for leaf nodes for the training set per epoch\n",
    "            \n",
    "        loss_train_parents_hist : list\n",
    "            list containing loss values for parent nodes for the training set per epoch\n",
    "        \n",
    "        loss_train_internal_hist : list\n",
    "            list containing loss values for internal nodes for the training set per epoch\n",
    "        \n",
    "        accuracy_val_leaf_hist : list \n",
    "            list containing accuracy for leaf values for the validation set per epoch\n",
    "        \n",
    "        accuracy_val_internal_hist : list\n",
    "            list containing accuracy for internal values for the validation set per epoch\n",
    "        \n",
    "        loss_val_hist : list\n",
    "            list containing total loss values for the validation set per epoch\n",
    "            \n",
    "        loss_val_leaf_hist : list\n",
    "            list containing loss values for leaf nodes for the validation set per epoch\n",
    "            \n",
    "        loss_val_parents_hist : list\n",
    "            list containing loss values for parent nodes for the validation set per epoch\n",
    "            \n",
    "        loss_val_internal_hist : list\n",
    "            list containing loss values for internal nodes for the validation set per epoch\n",
    "        \n",
    "        f1_score_train_leaf : list\n",
    "            list containing Macro F1 score for leaf nodes for training set per epoch \n",
    "        \n",
    "        f1_score_val_leaf : list\n",
    "            list containing Macro F1 score for leaf nodes for validation set per epoch \n",
    "        \n",
    "        best_output : tensor\n",
    "            PyTorch tensor containing the predicted probabilites for the most accurate\n",
    "            epoch\n",
    "            \n",
    "        best_state_dict : dictionary\n",
    "            Pytorch state_dict that contains the parameters for the best fitting models\n",
    "    '''\n",
    "    # initialize variables for saving values\n",
    "    accuracy_train_leaf_hist = []\n",
    "    accuracy_train_internal_hist = []\n",
    "    loss_train_leaf_hist = []\n",
    "    loss_train_parents_hist = []\n",
    "    loss_train_internal_hist = []\n",
    "    loss_train_hist = []\n",
    "    \n",
    "    accuracy_val_leaf_hist = []\n",
    "    accuracy_val_internal_hist = []\n",
    "    loss_val_hist = []\n",
    "    loss_val_leaf_hist = []\n",
    "    loss_val_parents_hist = []\n",
    "    loss_val_internal_hist = []\n",
    "    \n",
    "    f1_score_train_leaf = []\n",
    "    f1_score_val_leaf = []\n",
    "    \n",
    "    f1_score_train_parent = []\n",
    "    f1_score_val_parent = []\n",
    "\n",
    "    best_accuracy = - np.inf\n",
    "    best_weights = None\n",
    "    \n",
    "    # get the list of leaf labels\n",
    "    leaf_label_list = [value for (key,value) in mapping_dict.items() if value >= 0]\n",
    "\n",
    "    # get the min and max encoded values\n",
    "    min_encoded_value = min(mapping_dict.values()) #min(y_train).item()\n",
    "    max_encoded_value = max(mapping_dict.values()) #max(y_train).item()\n",
    "\n",
    "    # initialize network\n",
    "    clf = Network()\n",
    "    clf.to(device)\n",
    "\n",
    "    # define loss and optimizer\n",
    "    # we use two different loss methods for the leafs and parents\n",
    "    # use Cross Entory Loss for leafs, because those probabilities are normalized\n",
    "    #     and it is thus a multi-class problem\n",
    "    # Use BCELoss for the parents because this is a multi-label problem\n",
    "    #     and the probabilities are normalized, so we don't need BCELossWithLogits\n",
    "    # initialize the leaf loss here\n",
    "    # because of how we weight the parent loss, we will have to initialize that\n",
    "    # loss on each iteration because the weighting will change.\n",
    "    criterion_leafs = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    #criterion_parents = nn.BCELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(clf.parameters(), lr=1e-3)#, amsgrad=True, eps=1e-5)\n",
    "    #scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.5, total_iters=5)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5,gamma=0.5)\n",
    "\n",
    "    #start_epoch = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        #print('on epoch', epoch)\n",
    "        \n",
    "        # TRAINING\n",
    "        #print('Begin Training...')\n",
    "        clf.train()\n",
    "        \n",
    "        running_train_loss = 0.0\n",
    "        #correct_train = 0\n",
    "        #y_length = 0\n",
    "                \n",
    "        # set up manual batches - from https://stackoverflow.com/questions/45113245/how-to-get-mini-batches-in-pytorch-in-a-clean-and-efficient-way\n",
    "        #permutation = torch.randperm(X_train.size()[0]).to(device)\n",
    "        #permutation_cpu = permutation.cpu() # we want the same permutations, but need one copy on the cpu\n",
    "\n",
    "        print('start train batching')\n",
    "        start_batch = time.time()\n",
    "        #for i in range(0,X_train.size()[0], batch_size):\n",
    "        for i, train_batch in enumerate(train_dataloader):\n",
    "            #if (i/batch_size) % 10 == 0:\n",
    "            print('on batch', i, 'running time', (time.time()-start_batch))\n",
    "            #print(i)\n",
    "            #indices = permutation[i:i+batch_size]\n",
    "            #indices_cpu = permutation_cpu[i:i+batch_size]\n",
    "            #X_batch, y_batch = X_train[indices], y_train[indices] # doesn't work for sparse tensors\n",
    "\n",
    "            #X_batch = torch.index_select(X_train,0,indices_cpu).to(device)\n",
    "\n",
    "            #y_batch = torch.index_select(y_train,0,indices)#.to(device)\n",
    "\n",
    "            X_batch, y_batch = train_batch\n",
    "            \n",
    "            # change dtype to float\n",
    "            X_batch = X_batch.float()\n",
    "            \n",
    "            # transform the data with log(1+x)\n",
    "            X_batch = transform_data(X_batch)\n",
    "            \n",
    "            # move to device\n",
    "            X_batch = X_batch.to(device)\n",
    "\n",
    "            \n",
    "            # select the encoded values from the experiment_datapipe\n",
    "            y_batch = y_batch[:,1]\n",
    "            #print(y_batch)\n",
    "\n",
    "            # then map the values from the datapipe encoded values to the\n",
    "            # encoded values from the Ontology/mapping_dict\n",
    "            \n",
    "            #encoding_mapper\n",
    "            y_batch = torch.tensor([encoding_mapper[x.item()] for x in y_batch])\n",
    "            \n",
    "            # move to device\n",
    "            y_batch = y_batch.to(device)\n",
    "            #print(y_batch)\n",
    "            \n",
    "            # check that tensors are on gpu. if on gpu, get_device returns 0, if on cpu, returns -1\n",
    "            #print(X_batch.get_device())\n",
    "            #print(y_batch.get_device())\n",
    "            \n",
    "            # set optimizer to zero grad to remove previous epoch gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # make predictions for this batch\n",
    "            #if epoch == 0:\n",
    "            #    outputs_train = clf_nosoftmax(X_batch.float()) # might need to change to X_train.float()\n",
    "            #else:\n",
    "            outputs_train = clf(X_batch) # might need to change to X_train.float()\n",
    "            \n",
    "            ######\n",
    "            # create mask to separate leaf and internal nodes\n",
    "            ######\n",
    "            output_train_leaf = outputs_train[y_batch >= 0]\n",
    "            #print(output_train_leaf.shape)\n",
    "            y_batch_leaf = y_batch[y_batch >= 0]\n",
    "            #print(y_batch_leaf.shape)\n",
    "            \n",
    "            #output_train_internal = outputs_train[y_batch < 0]\n",
    "            #y_batch_internal = y_batch[y_batch < 0]\n",
    "            \n",
    "\n",
    "            # calculate loss for just the leafs\n",
    "            loss_train_leafs = criterion_leafs(output_train_leaf, y_batch_leaf)\n",
    "\n",
    "            # get the masking tensor for this batch of cells\n",
    "            # for calculating the internal loss\n",
    "            # we initialize BCE loss every batch because the mask changes based on which cells are\n",
    "            # included and ordered for this batch\n",
    "            batch_train_masking_tensor = build_mask_tensor_for_batch(cell_parent_mask,y_batch,min_encoded_value,max_encoded_value)\n",
    "            criterion_parents = nn.BCELoss(weight=batch_train_masking_tensor,reduction='mean')\n",
    "\n",
    "            \n",
    "            # calculate the loss for the parents of the cells that are leafs\n",
    "            output_train_parent_prob = output_probability_tensor(outputs_train,ontology_leaf_df)\n",
    "            target_train_parent_prob = target_probability_tensor(y_batch,ontology_df,mapping_dict)\n",
    "\n",
    "            #print(output_train_parent_prob)\n",
    "            #print('output_train_parent_prob',output_train_parent_prob.shape)\n",
    "            #print(target_train_parent_prob)\n",
    "            #print('target_train_parent_prob',target_train_parent_prob.shape)\n",
    "            \n",
    "            loss_train_parents = criterion_parents(output_train_parent_prob,target_train_parent_prob)\n",
    "\n",
    "            #######\n",
    "            # calculate the loss for the cells that are internal nodes\n",
    "            ##### total_accuracy_cell, total_number_of_cells\n",
    "            \n",
    "            #loss_train_internal, batch_accuracy_internal, batch_numbers_internal = internal_node_loss(\n",
    "            #                                        output_train_internal,y_batch_internal,\n",
    "            #                                         internal_values,mapping_dict,ontology_df,\n",
    "            #                                        ontology_leaf_df,criterion_parents,threshold)\n",
    "            \n",
    "            # sum the loss for both leafs and parents\n",
    "            loss_train = loss_train_leafs + loss_train_parents #+ loss_train_internal\n",
    "\n",
    "            # backward propagation\n",
    "            loss_train.backward()\n",
    "\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "             \n",
    "            running_train_loss += loss_train.item()\n",
    "           \n",
    "            # save predictions\n",
    "            _, train_leaf_pred_per_epoch = output_train_leaf.max(dim=1)\n",
    "\n",
    "            # calculate accuracy for internal cells\n",
    "            #####\n",
    "            # need to update this with the weighting somehow!!!!\n",
    "            #####\n",
    "            train_batch_accuracy = multilabel_accuracy(output_train_parent_prob,target_train_parent_prob,\n",
    "                                                      threshold=threshold,criteria='hamming')\n",
    "            \n",
    "            # save the number of cells for batch, for use in weighting when\n",
    "            # determining the overall accuracy per epoch\n",
    "            train_batch_number_of_cells = output_train_parent_prob.shape[1]\n",
    "                        \n",
    "            # check size of internal tensors. if only 1 internal cell\n",
    "            # reshape and detach\n",
    "            # else just detach\n",
    "            \n",
    "            ##if len(batch_accuracy_internal.size()) == 0:\n",
    "            ##    batch_accuracy_internal_shaped = batch_accuracy_internal.detach().reshape(1)\n",
    "            ##    batch_numbers_internal_shaped = batch_numbers_internal.detach().reshape(1)\n",
    "            ##else:\n",
    "            ##    batch_accuracy_internal_shaped = batch_accuracy_internal.detach()\n",
    "            ##    batch_numbers_internal_shaped = batch_numbers_internal.detach()\n",
    "                \n",
    "            \n",
    "            if i == 0:\n",
    "                train_leaf_pred_total = train_leaf_pred_per_epoch.detach()\n",
    "                y_train_leaf_total = y_batch_leaf.detach()\n",
    "                train_batch_accuracy_internal = train_batch_accuracy.reshape(1)\n",
    "                train_total_number_of_cells = torch.tensor(train_batch_number_of_cells).reshape(1)\n",
    "                output_train_probabilities = output_train_leaf.detach()\n",
    "                train_parent_pred_total = output_train_parent_prob.detach()\n",
    "                train_parent_true_total = target_train_parent_prob.detach()\n",
    "            else:\n",
    "                train_leaf_pred_total = torch.cat((train_leaf_pred_total,train_leaf_pred_per_epoch.detach()),0)\n",
    "                y_train_leaf_total = torch.cat((y_train_leaf_total,y_batch_leaf.detach()),0)\n",
    "                train_batch_accuracy_internal = torch.cat((train_batch_accuracy_internal,train_batch_accuracy.reshape(1)),0)\n",
    "                train_total_number_of_cells = torch.cat((train_total_number_of_cells,torch.tensor(train_batch_number_of_cells).reshape(1)),0)\n",
    "                output_train_probabilities = torch.cat((output_train_probabilities,output_train_leaf.detach()),0)\n",
    "                train_parent_pred_total = torch.cat((train_parent_pred_total,output_train_parent_prob.detach()),1)\n",
    "                train_parent_true_total = torch.cat((train_parent_true_total,target_train_parent_prob.detach()),1)\n",
    "                #print('train parent pred',train_parent_pred_total.shape)\n",
    "                #print('train parent true',train_parent_true_total.shape)\n",
    "                \n",
    "            # exit after 1 loop so we can test validation code\n",
    "            break\n",
    "                            \n",
    "            # calculate total epoch accuracy for internal nodes\n",
    "            #epoch_internal_accuracy = / train_numbers_internal.sum() * 100\n",
    "            \n",
    "            #correct_train += (train_pred_per_epoch == y_batch).sum().item()\n",
    "            #y_length += len(y_batch)\n",
    "            \n",
    "            # calculate F1 score\n",
    "            #f1_val_score_epoch = f1_score(train_pred_per_epoch.cpu(),y_batch.cpu(),labels=output_dim,average='weighted',zero_division=np.nan)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        print('done with training')\n",
    "        \n",
    "        # save tensors\n",
    "        #if epoch == 14:\n",
    "        #    torch.save(output_train_probabilities, 'output_good_nosoftmax_1Dec.pt')\n",
    "        #    torch.save(y_train_leaf_total, 'targets_good_nosoftmax_1Dec.pt')\n",
    "        \n",
    "        # save accuracy\n",
    "        #_, train_pred = outputs_train.max(dim=1)\n",
    "        #correct_train = (train_pred == y_train).sum().item()\n",
    "        #accuracy_train_hist.append(correct_train / y_length * 100.)\n",
    "        #print('acc train hist', accuracy_train_hist[-1])\n",
    "        \n",
    "        train_total_number_of_cells = train_total_number_of_cells.to(device)\n",
    "        \n",
    "        correct_train_leaf = (train_leaf_pred_total == y_train_leaf_total).sum().item()\n",
    "        print(train_leaf_pred_total.shape)\n",
    "        accuracy_train_leaf_hist.append(correct_train_leaf / train_leaf_pred_total.shape[0] * 100.)\n",
    "                \n",
    "        correct_train_internal = (train_batch_accuracy_internal * train_total_number_of_cells).sum()\n",
    "        accuracy_train_internal = (correct_train_internal / train_total_number_of_cells.sum() * 100.).item()\n",
    "        accuracy_train_internal_hist.append(accuracy_train_internal)\n",
    "        \n",
    "        #print('sample acc', acc_full)\n",
    "\n",
    "        # save loss\n",
    "        loss_train_hist.append(loss_train.item())\n",
    "        loss_train_leaf_hist.append(loss_train_leafs.item())\n",
    "        loss_train_parents_hist.append(loss_train_parents.item())\n",
    "        ##loss_train_internal_hist.append(loss_train_internal.item())\n",
    "        \n",
    "        # save f1 score\n",
    "        # use average = weighted to account for label imbalance\n",
    "        # use zero_division = np.nan to exclude labels where all \n",
    "        #       predictions and labels are negative\n",
    "        f1_train_leaf_score = f1_score(y_train_leaf_total.cpu(), train_leaf_pred_total.cpu(),\n",
    "                                  labels=leaf_label_list,average='weighted',zero_division=np.nan)\n",
    "        f1_score_train_leaf.append(f1_train_leaf_score)\n",
    "        \n",
    "        # for the F1 score for the internal nodes, we need to first turn the probabilities\n",
    "        # into predictions using our threshold value\n",
    "        train_parent_pred_total_thresholded = torch.where(train_parent_pred_total > threshold,1.0,0.0)\n",
    "        \n",
    "        f1_train_parent_score = f1_score(train_parent_true_total.cpu(),train_parent_pred_total_thresholded.cpu(),\n",
    "                                        average='weighted',zero_division=np.nan)\n",
    "        f1_score_train_parent.append(f1_train_parent_score)\n",
    "        #torch.save(train_parent_true_total.cpu(),'train_parent_true_total_20Feb.pt')\n",
    "        #torch.save(train_parent_pred_total_thresholded.cpu(),'train_parent_pred_total_thresholded_20Feb.pt')\n",
    "\n",
    "        \n",
    "        # set up validation\n",
    "        correct_val = 0\n",
    "        y_val_length = 0\n",
    "        \n",
    "        print('start validation')\n",
    "        with torch.no_grad():\n",
    "            clf.eval()\n",
    "            \n",
    "            # set up manual batches\n",
    "            # we don't need to randomly permute the validation set, but\n",
    "            # this will provide consistency with the above.\n",
    "            # for simplicity, let's use the same batch size\n",
    "            #permutation_val = torch.randperm(X_val.size()[0]).to(device)\n",
    "            #start_val = time.time()\n",
    "            \n",
    "            #for i in range(0,X_val.size()[0],batch_size):\n",
    "            print('start validation batching')\n",
    "            start_batch = time.time()\n",
    "            for i, val_batch in enumerate(val_dataloader):\n",
    "                print('on batch', i, 'running time', (time.time()-start_batch))\n",
    "\n",
    "                #indices_val = permutation_val[i:i+batch_size]\n",
    "                \n",
    "                #X_val_batch = torch.index_select(X_val,0,indices_val)\n",
    "                #y_val_batch = torch.index_select(y_val,0,indices_val)\n",
    "                \n",
    "                \n",
    "                X_val_batch, y_val_batch = val_batch\n",
    "            \n",
    "                # change dtype to float\n",
    "                X_val_batch = X_val_batch.float()\n",
    "\n",
    "                # transform the data with log(1+x)\n",
    "                X_val_batch = transform_data(X_val_batch)\n",
    "                \n",
    "                # move to device\n",
    "                X_val_batch = X_val_batch.to(device)\n",
    "\n",
    "                \n",
    "                # select the encoded values from the experiment_datapipe\n",
    "                y_val_batch = y_val_batch[:,1]\n",
    "                #print(y_batch)\n",
    "\n",
    "                # then map the values from the datapipe encoded values to the\n",
    "                # encoded values from the Ontology/mapping_dict\n",
    "\n",
    "                #encoding_mapper\n",
    "                y_val_batch = torch.tensor([encoding_mapper[x.item()] for x in y_val_batch])\n",
    "                \n",
    "                # move to device\n",
    "                y_val_batch = y_val_batch.to(device)\n",
    "                \n",
    "                # calculate output by running through the network\n",
    "                outputs_val = clf(X_val_batch)\n",
    "            \n",
    "                ######\n",
    "                # create mask to separate leaf and internal nodes\n",
    "                ######\n",
    "                output_val_leaf = outputs_val[y_val_batch >= 0]\n",
    "                y_val_batch_leaf = y_val_batch[y_val_batch >= 0]\n",
    "\n",
    "                #output_val_internal = outputs_val[y_val_batch < 0]\n",
    "                #y_val_batch_internal = y_val_batch[y_val_batch < 0]\n",
    "            \n",
    "                # calculate loss for just the leafs\n",
    "                loss_val_leafs = criterion_leafs(output_val_leaf, y_val_batch_leaf)\n",
    "        \n",
    "                # get the masking tensor for this batch of cells\n",
    "                # for calculating the internal loss\n",
    "                # we initialize BCE loss every batch because the mask changes based on which cells are\n",
    "                # included and ordered for this batch\n",
    "                batch_val_masking_tensor = build_mask_tensor_for_batch(cell_parent_mask,y_val_batch,min_encoded_value,max_encoded_value)\n",
    "                criterion_parents = nn.BCELoss(weight=batch_val_masking_tensor,reduction='mean')\n",
    "                \n",
    "                # calculate the loss for the parents of the leafs\n",
    "                output_val_parent_prob = output_probability_tensor(outputs_val,ontology_leaf_df)\n",
    "                target_val_parent_prob = target_probability_tensor(y_val_batch,ontology_df,mapping_dict)\n",
    "                \n",
    "                loss_val_parents = criterion_parents(output_val_parent_prob,target_val_parent_prob)\n",
    "\n",
    "                #######\n",
    "                # calculate the loss for the cells that are internal nodes\n",
    "                #####\n",
    "\n",
    "                #loss_val_internal, batch_accuracy_internal_val, batch_numbers_internal_val = internal_node_loss(output_val_internal,\n",
    "                #                                                y_val_batch_internal,\n",
    "                #                                                internal_values,mapping_dict,ontology_df,ontology_leaf_df,\n",
    "                #                                                criterion_parents,threshold)\n",
    "\n",
    "                \n",
    "                # sum the loss for both leafs and parents\n",
    "                loss_val = loss_val_leafs + loss_val_parents #+ loss_val_internal\n",
    "            \n",
    "            \n",
    "                # get the predictions\n",
    "                __, predicted_leaf_val_per_epoch = output_val_leaf.max(dim=1)            \n",
    "\n",
    "                # calculate accuracy for internal cells\n",
    "                #####\n",
    "                # need to update this with the weighting somehow!!!!\n",
    "                #####\n",
    "                val_batch_accuracy = multilabel_accuracy(output_val_parent_prob,target_val_parent_prob,\n",
    "                                                          threshold=threshold,criteria='hamming')\n",
    "\n",
    "                # save the number of cells for batch, for use in weighting when\n",
    "                # determining the overall accuracy per epoch\n",
    "                val_batch_number_of_cells = output_val_parent_prob.shape[1]\n",
    "\n",
    "                \n",
    "                # save accuracy\n",
    "                #correct_val += (predicted_val_per_epoch == y_val_batch).sum().item()\n",
    "                #y_val_length += len(y_val_batch)\n",
    "                \n",
    "                # check size of internal tensors. if only 1 internal cell\n",
    "                # reshape and detach\n",
    "                # else just detach\n",
    "                            \n",
    "                #if len(batch_accuracy_internal_val.size()) == 0:\n",
    "                #    batch_accuracy_internal_val_shaped = batch_accuracy_internal_val.detach().reshape(1)\n",
    "                #    batch_numbers_internal_val_shaped = batch_numbers_internal_val.detach().reshape(1)\n",
    "                #else:\n",
    "                #    batch_accuracy_internal_val_shaped = batch_accuracy_internal_val.detach()\n",
    "                #    batch_numbers_internal_val_shaped = batch_numbers_internal_val.detach()\n",
    "                                \n",
    "                if i == 0:\n",
    "                    val_leaf_pred_total = predicted_leaf_val_per_epoch.detach()\n",
    "                    y_leaf_val_total = y_val_batch_leaf.detach()\n",
    "                    val_batch_accuracy_internal = val_batch_accuracy.reshape(1)\n",
    "                    val_total_number_of_cells = torch.tensor(val_batch_number_of_cells).reshape(1)\n",
    "                    val_parent_pred_total = output_val_parent_prob.detach()\n",
    "                    val_parent_true_total = target_val_parent_prob.detach()\n",
    "\n",
    "                else:\n",
    "                    val_leaf_pred_total = torch.cat((val_leaf_pred_total,predicted_leaf_val_per_epoch.detach()),0)\n",
    "                    y_leaf_val_total = torch.cat((y_leaf_val_total,y_val_batch_leaf.detach()),0)\n",
    "                    val_batch_accuracy_internal = torch.cat((val_batch_accuracy_internal,val_batch_accuracy.reshape(1)),0)\n",
    "                    val_total_number_of_cells = torch.cat((val_total_number_of_cells,torch.tensor(val_batch_number_of_cells).reshape(1)),0)\n",
    "                    val_parent_pred_total = torch.cat((val_parent_pred_total,output_val_parent_prob.detach()),1)\n",
    "                    val_parent_true_total = torch.cat((val_parent_true_total,target_val_parent_prob.detach()),1)\n",
    "\n",
    "                    \n",
    "                # exit after 1 loop so we can test  code\n",
    "                break\n",
    "\n",
    "            # save total accuracy\n",
    "            #accuracy_val_hist.append(correct_val / y_val_length * 100.)\n",
    "            print('done with validation')\n",
    "            val_total_number_of_cells = val_total_number_of_cells.to(device)\n",
    "            \n",
    "            correct_val_leaf = (val_leaf_pred_total == y_leaf_val_total).sum().item()\n",
    "            accuracy_val_leaf_hist.append(correct_val_leaf / val_leaf_pred_total.shape[0] * 100.)\n",
    "\n",
    "            correct_val_internal = (val_batch_accuracy_internal * val_total_number_of_cells).sum()\n",
    "            accuracy_val_internal = (correct_val_internal / val_total_number_of_cells.sum() * 100.).item()\n",
    "            accuracy_val_internal_hist.append(accuracy_val_internal)\n",
    "\n",
    "            \n",
    "            # save loss\n",
    "            loss_val_hist.append(loss_val.item())\n",
    "            loss_val_leaf_hist.append(loss_val_leafs.item())\n",
    "            loss_val_parents_hist.append(loss_val_parents.item())\n",
    "            #loss_val_internal_hist.append(loss_val_internal.item())\n",
    "            \n",
    "            # save f1 score\n",
    "            # use average = weighted to account for label imbalance\n",
    "            # use zero_division = np.nan to exclude labels where all \n",
    "            #       predictions and labels are negative\n",
    "            f1_val_leaf_score = f1_score(y_leaf_val_total.cpu(),val_leaf_pred_total.cpu(),\n",
    "                                    labels=leaf_label_list,average='weighted',zero_division=np.nan)\n",
    "            f1_score_val_leaf.append(f1_val_leaf_score)\n",
    "\n",
    "            \n",
    "            # for the F1 score for the internal nodes, we need to first turn the probabilities\n",
    "            # into predictions using our threshold value\n",
    "            val_parent_pred_total_thresholded = torch.where(val_parent_pred_total > threshold,1.0,0.0)\n",
    "\n",
    "            f1_val_parent_score = f1_score( val_parent_true_total.cpu(),val_parent_pred_total_thresholded.cpu(),\n",
    "                                        average='weighted',zero_division=np.nan)\n",
    "            f1_score_val_parent.append(f1_val_parent_score)\n",
    "            #torch.save(val_parent_true_total.cpu(),'val_parent_true_total_20Feb.pt')\n",
    "            #torch.save(val_parent_pred_total_thresholded.cpu(),'val_parent_pred_total_thresholded_20Feb.pt')\n",
    "\n",
    "            \n",
    "            # check if best model\n",
    "            if accuracy_val_leaf_hist[-1] > best_accuracy:\n",
    "                best_acc = accuracy_val_leaf_hist[-1]\n",
    "                best_state_dict = copy.deepcopy(clf.state_dict())\n",
    "                best_output = copy.deepcopy(outputs_val)\n",
    "            \n",
    "        if (epoch + 1) % 1 == 0 or epoch == 0:\n",
    "            print(f'[{epoch + 1}] Training Accuracy: {accuracy_train_leaf_hist[-1]:.3f} Validation Accuracy: {accuracy_val_leaf_hist[-1]:.3f}')\n",
    "            print(f'Train Loss: {loss_train.item():.4f} Validation Loss: {loss_val.item():.4f}')\n",
    "            #print(f'Internal Loss: {loss_val_internal.item():.4f}')\n",
    "            #print('learning rate:', optimizer.param_groups[0][\"lr\"])\n",
    "        #end_epoch = time.time()\n",
    "        #print('epoch timer', end_epoch-start_epoch)\n",
    "        break\n",
    "\n",
    "    print(f'Best Validation Accuracy: {best_acc:.3f}')\n",
    "    \n",
    "    # build dictionary to return values\n",
    "    marginalization_dict = {}\n",
    "    marginalization_dict['accuracy_train_leaf_hist'] = accuracy_train_leaf_hist\n",
    "    marginalization_dict['accuracy_train_internal_hist'] = accuracy_train_internal_hist\n",
    "    \n",
    "    marginalization_dict['loss_train_hist'] = loss_train_hist\n",
    "    \n",
    "    marginalization_dict['loss_train_leaf_hist'] = loss_train_leaf_hist\n",
    "    marginalization_dict['loss_train_internal_hist'] = loss_train_parents_hist\n",
    "\n",
    "    marginalization_dict['accuracy_val_leaf_hist'] = accuracy_val_leaf_hist\n",
    "    marginalization_dict['accuracy_val_internal_hist'] = accuracy_val_internal_hist\n",
    "\n",
    "    marginalization_dict['loss_val_hist'] = loss_val_hist\n",
    "\n",
    "    marginalization_dict['loss_val_leaf_hist'] = loss_val_leaf_hist\n",
    "    marginalization_dict['loss_val_internal_hist'] = loss_val_parents_hist\n",
    "    \n",
    "    marginalization_dict['f1_score_train_leaf'] = f1_score_train_leaf\n",
    "    marginalization_dict['f1_score_val_leaf'] = f1_score_val_leaf\n",
    "    \n",
    "    marginalization_dict['f1_score_train_internal'] = f1_score_train_parent\n",
    "    marginalization_dict['f1_score_val_internal'] = f1_score_val_parent\n",
    "\n",
    "    marginalization_dict['best_output'] = best_output\n",
    "    marginalization_dict['best_state_dict'] = best_state_dict\n",
    "\n",
    "\n",
    "    return marginalization_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0768f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 88 leafs and 55 parents.\n",
      "Number of training batches is 3.19\n",
      "Number of validation batches is 2.13\n",
      "Prediction threshold for internal nodes is 1e-05\n",
      "start train batching\n",
      "on batch 0 running time 300.35732340812683\n",
      "done with training\n",
      "torch.Size([7])\n",
      "start validation\n",
      "start validation batching\n",
      "on batch 0 running time 410.9476718902588\n",
      "done with validation\n",
      "[1] Training Accuracy: 0.000 Validation Accuracy: 0.000\n",
      "Train Loss: 4.6160 Validation Loss: 4.7743\n",
      "Best Validation Accuracy: 0.000\n",
      "Run time for 1 epochs was 11.89 minutes (0.20 hours)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "number_of_leafs = len(leaf_values)\n",
    "number_of_parents = len(internal_values)\n",
    "\n",
    "print('There are', number_of_leafs, 'leafs and', number_of_parents, 'parents.')\n",
    "\n",
    "print('Number of training batches is {:.2f}'.format(experiment_datapipe.shape[0]*train_percent/batch_size))\n",
    "print('Number of validation batches is {:.2f}'.format(experiment_datapipe.shape[0]*val_percent/batch_size))\n",
    "\n",
    "# create dataframe that only includes leaf nodes\n",
    "ontology_leaf_df = ontology_df[leaf_values]\n",
    "\n",
    "# Create dictionary to map between two different types of encoded values\n",
    "# get the encoder from the datapipe\n",
    "cell_type_encoder = experiment_datapipe.obs_encoders[\"cell_type_ontology_term_id\"]\n",
    "\n",
    "# build the dictionary of encoded values from the datapipe\n",
    "encoder_mapping_dict = dict(zip(cell_type_encoder.classes_,cell_type_encoder.transform(cell_type_encoder.classes_)))\n",
    "\n",
    "# build the dictionary mapping from encoder_mapping_dict (keys) to mapping_dict (values)\n",
    "encoding_mapper = {}\n",
    "for cell_term in encoder_mapping_dict.keys():\n",
    "    encoding_mapper[encoder_mapping_dict[cell_term]] = mapping_dict[cell_term]\n",
    "\n",
    "\n",
    "# set the prediction threshold for internal nodes\n",
    "threshold = 0.00001 #0.8\n",
    "print('Prediction threshold for internal nodes is', threshold)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "marginalization_dict = marginalization_classification_manual_batch(train_dataloader,val_dataloader,\n",
    "                                                                   num_epochs, ontology_leaf_df, batch_size,\n",
    "                                                                  internal_values,mapping_dict,\n",
    "                                                                  ontology_df,threshold, cell_parent_mask,encoding_mapper)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "time_minutes = (end-start)/60.\n",
    "time_hours = (end-start)/3600.\n",
    "\n",
    "print(f'Run time for {num_epochs} epochs was {time_minutes:.2f} minutes ({time_hours:.2f} hours)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb3866",
   "metadata": {},
   "source": [
    "#### Testing running times per batch\n",
    "Note that I'm only running a handful of batches, so this probbably does not account for any extra time needed to load the next batch of data from disk. That would require a longer run, so soma_chunck_size might not really matter here. And there is some variability in how long each batch takes to run. I'm not sure if this is related to disk streaming or not. This is for the full set of 2.7 million cells\n",
    "\n",
    "|batch size | soma chunk size| time per batch (s) | # of batches | time per 1 training epoch (hr) |\n",
    "| -------- | ------- |------ | ----- | ----- |\n",
    "|8192 | 10,000 | 190 | 266 | 14\n",
    "| 32768 | 10,000 | 600 | 66 | 11\n",
    "| 8192 | 20,000 | 180 | 266 | 14\n",
    "| 4096 | 20,000 | 45 | 532 | 6.7\n",
    "| 1024 | 20,000 | 15 | 2129 | 8.8\n",
    "| 512 | 20,000 |  4.5 | 4259  | 5.3\n",
    "| 256 | 20,000 | 1.4  | 8518  | 3.3\n",
    "| 256 | 30,000 |  1.8 | 8518   | 4.4\n",
    "| 128 | 30,000 | 1.06  | 17037  | 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ca2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9a904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36cf22a5",
   "metadata": {},
   "source": [
    "## Save portions of the modeling and visualize results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd4945eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get today's date for saving information about this model\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model parameters to a file\n",
    "\n",
    "#marginalization_dict['best_state_dict']\n",
    "\n",
    "model_title = today + '_best_model'\n",
    "\n",
    "torch.save(marginalization_dict['best_state_dict'],model_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the loss/accuracy/f1 scores to a file\n",
    "\n",
    "cols_to_save = ['accuracy_train_leaf_hist','loss_train_hist', \n",
    "                'loss_train_leaf_hist', 'loss_train_internal_hist', \n",
    "                'accuracy_val_leaf_hist', \n",
    "                'loss_val_hist', 'loss_val_leaf_hist', 'loss_val_internal_hist', \n",
    "                'f1_score_train_leaf', 'f1_score_val_leaf',\n",
    "               'f1_score_train_internal','f1_score_val_internal']\n",
    "\n",
    "results_dict = {key: marginalization_dict[key] for key in cols_to_save}\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient='columns')\n",
    "\n",
    "results_df.insert(0,'epoch',range(1,num_epochs+1))\n",
    "\n",
    "results_title = today + '_results.csv'\n",
    "\n",
    "\n",
    "results_df.to_csv(results_title,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70b0081b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marginalization_dict['f1_score_train_leaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c32fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5b9afce",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m plot_title \u001b[38;5;241m=\u001b[39m today \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_results.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# if you want to save the plot\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#plot_results(marginalization_dict,num_epochs,save_title=plot_title)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# just display the plot\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mplot_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarginalization_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 35\u001b[0m, in \u001b[0;36mplot_results\u001b[0;34m(marginalization_dict, num_epochs, save_title)\u001b[0m\n\u001b[1;32m     29\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),y\u001b[38;5;241m=\u001b[39mmarginalization_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_val_internal_hist\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     30\u001b[0m                 ax \u001b[38;5;241m=\u001b[39m ax[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m],color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmediumslateblue\u001b[39m\u001b[38;5;124m'\u001b[39m,marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Internal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#sns.scatterplot(x=range(1,num_epochs+1),y=marginalization_dict['loss_val_internal_hist'], \u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#                ax = ax[1,1],color='mediumslateblue',marker='v',label='Val Internal')\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarginalization_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1_score_train_leaf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[43max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlightcoral\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),y\u001b[38;5;241m=\u001b[39mmarginalization_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score_val_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     38\u001b[0m                 ax \u001b[38;5;241m=\u001b[39m ax[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m],color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmediumslateblue\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),y\u001b[38;5;241m=\u001b[39mmarginalization_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score_train_internal\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     41\u001b[0m                 ax \u001b[38;5;241m=\u001b[39m ax[\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m0\u001b[39m],color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightcoral\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/seaborn/relational.py:645\u001b[0m, in \u001b[0;36mlineplot\u001b[0;34m(data, x, y, hue, size, style, units, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, estimator, errorbar, n_boot, seed, orient, sort, err_style, err_kws, legend, ci, ax, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m color \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    643\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _default_color(ax\u001b[38;5;241m.\u001b[39mplot, hue, color, kwargs)\n\u001b[0;32m--> 645\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ax\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/seaborn/relational.py:459\u001b[0m, in \u001b[0;36m_LinePlotter.plot\u001b[0;34m(self, ax, kws)\u001b[0m\n\u001b[1;32m    457\u001b[0m         lines\u001b[38;5;241m.\u001b[39mextend(ax\u001b[38;5;241m.\u001b[39mplot(unit_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], unit_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws))\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m     lines \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mplot(sub_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43msub_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws)\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sub_vars:\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'y'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x1200 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_title = today + '_results.png'\n",
    "\n",
    "# if you want to save the plot\n",
    "#plot_results(marginalization_dict,num_epochs,save_title=plot_title)\n",
    "\n",
    "# just display the plot\n",
    "plot_results(marginalization_dict,num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb849b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4dcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c82cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1592e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c21039bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CL:0000037': 0,\n",
       " 'CL:0000038': 1,\n",
       " 'CL:0000049': 2,\n",
       " 'CL:0000050': 3,\n",
       " 'CL:0000051': 4,\n",
       " 'CL:0000081': 5,\n",
       " 'CL:0000084': 6,\n",
       " 'CL:0000091': 7,\n",
       " 'CL:0000092': 8,\n",
       " 'CL:0000094': 9,\n",
       " 'CL:0000097': 10,\n",
       " 'CL:0000129': 11,\n",
       " 'CL:0000232': 12,\n",
       " 'CL:0000233': 13,\n",
       " 'CL:0000235': 14,\n",
       " 'CL:0000236': 15,\n",
       " 'CL:0000451': 16,\n",
       " 'CL:0000453': 17,\n",
       " 'CL:0000492': 18,\n",
       " 'CL:0000542': 19,\n",
       " 'CL:0000547': 20,\n",
       " 'CL:0000556': 21,\n",
       " 'CL:0000557': 22,\n",
       " 'CL:0000559': 23,\n",
       " 'CL:0000576': 24,\n",
       " 'CL:0000583': 25,\n",
       " 'CL:0000595': 26,\n",
       " 'CL:0000623': 27,\n",
       " 'CL:0000624': 28,\n",
       " 'CL:0000625': 29,\n",
       " 'CL:0000738': 30,\n",
       " 'CL:0000763': 31,\n",
       " 'CL:0000764': 32,\n",
       " 'CL:0000765': 33,\n",
       " 'CL:0000766': 34,\n",
       " 'CL:0000767': 35,\n",
       " 'CL:0000771': 36,\n",
       " 'CL:0000775': 37,\n",
       " 'CL:0000776': 38,\n",
       " 'CL:0000782': 39,\n",
       " 'CL:0000784': 40,\n",
       " 'CL:0000785': 41,\n",
       " 'CL:0000786': 42,\n",
       " 'CL:0000787': 43,\n",
       " 'CL:0000788': 44,\n",
       " 'CL:0000789': 45,\n",
       " 'CL:0000791': 46,\n",
       " 'CL:0000794': 47,\n",
       " 'CL:0000798': 48,\n",
       " 'CL:0000800': 49,\n",
       " 'CL:0000807': 50,\n",
       " 'CL:0000808': 51,\n",
       " 'CL:0000809': 52,\n",
       " 'CL:0000810': 53,\n",
       " 'CL:0000811': 54,\n",
       " 'CL:0000813': 55,\n",
       " 'CL:0000814': 56,\n",
       " 'CL:0000815': 57,\n",
       " 'CL:0000816': 58,\n",
       " 'CL:0000817': 59,\n",
       " 'CL:0000818': 60,\n",
       " 'CL:0000823': 61,\n",
       " 'CL:0000826': 62,\n",
       " 'CL:0000836': 63,\n",
       " 'CL:0000837': 64,\n",
       " 'CL:0000838': 65,\n",
       " 'CL:0000839': 66,\n",
       " 'CL:0000841': 67,\n",
       " 'CL:0000844': 68,\n",
       " 'CL:0000860': 69,\n",
       " 'CL:0000861': 70,\n",
       " 'CL:0000863': 71,\n",
       " 'CL:0000875': 72,\n",
       " 'CL:0000878': 73,\n",
       " 'CL:0000890': 74,\n",
       " 'CL:0000893': 75,\n",
       " 'CL:0000894': 76,\n",
       " 'CL:0000895': 77,\n",
       " 'CL:0000896': 78,\n",
       " 'CL:0000897': 79,\n",
       " 'CL:0000898': 80,\n",
       " 'CL:0000899': 81,\n",
       " 'CL:0000900': 82,\n",
       " 'CL:0000903': 83,\n",
       " 'CL:0000904': 84,\n",
       " 'CL:0000905': 85,\n",
       " 'CL:0000906': 86,\n",
       " 'CL:0000907': 87,\n",
       " 'CL:0000908': 88,\n",
       " 'CL:0000909': 89,\n",
       " 'CL:0000910': 90,\n",
       " 'CL:0000912': 91,\n",
       " 'CL:0000913': 92,\n",
       " 'CL:0000915': 93,\n",
       " 'CL:0000921': 94,\n",
       " 'CL:0000934': 95,\n",
       " 'CL:0000936': 96,\n",
       " 'CL:0000938': 97,\n",
       " 'CL:0000939': 98,\n",
       " 'CL:0000940': 99,\n",
       " 'CL:0000970': 100,\n",
       " 'CL:0000972': 101,\n",
       " 'CL:0000979': 102,\n",
       " 'CL:0000980': 103,\n",
       " 'CL:0000985': 104,\n",
       " 'CL:0000987': 105,\n",
       " 'CL:0000990': 106,\n",
       " 'CL:0001029': 107,\n",
       " 'CL:0001043': 108,\n",
       " 'CL:0001044': 109,\n",
       " 'CL:0001049': 110,\n",
       " 'CL:0001050': 111,\n",
       " 'CL:0001054': 112,\n",
       " 'CL:0001056': 113,\n",
       " 'CL:0001057': 114,\n",
       " 'CL:0001058': 115,\n",
       " 'CL:0001062': 116,\n",
       " 'CL:0001065': 117,\n",
       " 'CL:0001071': 118,\n",
       " 'CL:0001078': 119,\n",
       " 'CL:0001082': 120,\n",
       " 'CL:0001203': 121,\n",
       " 'CL:0002038': 122,\n",
       " 'CL:0002045': 123,\n",
       " 'CL:0002046': 124,\n",
       " 'CL:0002057': 125,\n",
       " 'CL:0002117': 126,\n",
       " 'CL:0002343': 127,\n",
       " 'CL:0002355': 128,\n",
       " 'CL:0002393': 129,\n",
       " 'CL:0002394': 130,\n",
       " 'CL:0002396': 131,\n",
       " 'CL:0002397': 132,\n",
       " 'CL:0002399': 133,\n",
       " 'CL:0002419': 134,\n",
       " 'CL:0002425': 135,\n",
       " 'CL:0002489': 136,\n",
       " 'CL:0002496': 137,\n",
       " 'CL:0002677': 138,\n",
       " 'CL:0002678': 139,\n",
       " 'CL:1001603': 140,\n",
       " 'CL:2000055': 141,\n",
       " 'CL:3000001': 142}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "687a4ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CL:0000763': -9999,\n",
       " 'CL:0000542': -9998,\n",
       " 'CL:0000097': 0,\n",
       " 'CL:0002046': 1,\n",
       " 'CL:0000817': 2,\n",
       " 'CL:0000051': 3,\n",
       " 'CL:0000826': -9997,\n",
       " 'CL:0001029': 4,\n",
       " 'CL:0000990': -9996,\n",
       " 'CL:0000785': -9995,\n",
       " 'CL:0000816': 5,\n",
       " 'CL:0000786': -9994,\n",
       " 'CL:0000784': -9993,\n",
       " 'CL:0000557': 6,\n",
       " 'CL:0000084': -9992,\n",
       " 'CL:0000814': -9991,\n",
       " 'CL:0000837': -9990,\n",
       " 'CL:0000037': 7,\n",
       " 'CL:0000576': -9989,\n",
       " 'CL:0000050': 8,\n",
       " 'CL:0000129': 9,\n",
       " 'CL:0000815': -9988,\n",
       " 'CL:0000912': 10,\n",
       " 'CL:0000940': 11,\n",
       " 'CL:0000623': -9987,\n",
       " 'CL:0000899': 12,\n",
       " 'CL:0000798': -9986,\n",
       " 'CL:0000235': -9985,\n",
       " 'CL:0000775': -9984,\n",
       " 'CL:0000236': -9983,\n",
       " 'CL:0000453': 13,\n",
       " 'CL:0002343': 14,\n",
       " 'CL:0001078': 15,\n",
       " 'CL:3000001': 16,\n",
       " 'CL:0000451': -9982,\n",
       " 'CL:0000094': -9981,\n",
       " 'CL:0000738': -9980,\n",
       " 'CL:0000878': -9979,\n",
       " 'CL:0000972': -9978,\n",
       " 'CL:0000788': 17,\n",
       " 'CL:0000985': 18,\n",
       " 'CL:0000987': 19,\n",
       " 'CL:0000970': 20,\n",
       " 'CL:0000913': 21,\n",
       " 'CL:0000492': -9977,\n",
       " 'CL:0000624': -9976,\n",
       " 'CL:0000909': -9975,\n",
       " 'CL:0000896': -9974,\n",
       " 'CL:0000906': -9973,\n",
       " 'CL:0000905': 22,\n",
       " 'CL:0000890': 23,\n",
       " 'CL:0000860': -9972,\n",
       " 'CL:0000875': -9971,\n",
       " 'CL:0000782': -9970,\n",
       " 'CL:0000863': 24,\n",
       " 'CL:0000767': 25,\n",
       " 'CL:0000583': 26,\n",
       " 'CL:0000625': -9969,\n",
       " 'CL:0000861': -9968,\n",
       " 'CL:1001603': -9967,\n",
       " 'CL:0002399': 27,\n",
       " 'CL:0001071': -9966,\n",
       " 'CL:0000766': -9965,\n",
       " 'CL:0000765': 28,\n",
       " 'CL:0002496': -9964,\n",
       " 'CL:0000898': -9963,\n",
       " 'CL:0001065': -9962,\n",
       " 'CL:0000903': 29,\n",
       " 'CL:0000787': -9961,\n",
       " 'CL:0000813': -9960,\n",
       " 'CL:0000232': -9959,\n",
       " 'CL:0000910': 30,\n",
       " 'CL:0000838': -9958,\n",
       " 'CL:0000839': -9957,\n",
       " 'CL:0000038': 31,\n",
       " 'CL:0000547': 32,\n",
       " 'CL:0002355': 33,\n",
       " 'CL:0002045': 34,\n",
       " 'CL:0000559': 35,\n",
       " 'CL:0001054': -9956,\n",
       " 'CL:0000836': 36,\n",
       " 'CL:0000556': 37,\n",
       " 'CL:0000092': 38,\n",
       " 'CL:0000938': 39,\n",
       " 'CL:0000936': 40,\n",
       " 'CL:0000049': 41,\n",
       " 'CL:0000771': 42,\n",
       " 'CL:0002419': -9955,\n",
       " 'CL:0001082': -9954,\n",
       " 'CL:0002489': -9953,\n",
       " 'CL:0000809': 43,\n",
       " 'CL:0002425': 44,\n",
       " 'CL:0000915': 45,\n",
       " 'CL:0000897': -9952,\n",
       " 'CL:0000789': -9951,\n",
       " 'CL:0000904': 46,\n",
       " 'CL:0000900': 47,\n",
       " 'CL:0002396': 48,\n",
       " 'CL:0000895': 49,\n",
       " 'CL:0000934': 50,\n",
       " 'CL:0000907': 51,\n",
       " 'CL:0002677': 52,\n",
       " 'CL:0000980': 53,\n",
       " 'CL:0002678': 54,\n",
       " 'CL:0000233': 55,\n",
       " 'CL:0001057': 56,\n",
       " 'CL:0000091': 57,\n",
       " 'CL:0000939': 58,\n",
       " 'CL:0001203': -9950,\n",
       " 'CL:0002038': 59,\n",
       " 'CL:0000764': -9949,\n",
       " 'CL:0001062': 60,\n",
       " 'CL:0001056': -9948,\n",
       " 'CL:0000844': 61,\n",
       " 'CL:0001044': 62,\n",
       " 'CL:0000979': 63,\n",
       " 'CL:0001050': 64,\n",
       " 'CL:0002117': 65,\n",
       " 'CL:0002393': 66,\n",
       " 'CL:0000081': -9947,\n",
       " 'CL:0000595': 67,\n",
       " 'CL:0000810': 68,\n",
       " 'CL:0000811': 69,\n",
       " 'CL:0002394': 70,\n",
       " 'CL:2000055': 71,\n",
       " 'CL:0000908': 72,\n",
       " 'CL:0000921': 73,\n",
       " 'CL:0000841': 74,\n",
       " 'CL:0000794': 75,\n",
       " 'CL:0000807': 76,\n",
       " 'CL:0000894': 77,\n",
       " 'CL:0000808': 78,\n",
       " 'CL:0000823': 79,\n",
       " 'CL:0000893': -9946,\n",
       " 'CL:0002057': 80,\n",
       " 'CL:0000791': -9945,\n",
       " 'CL:0002397': 81,\n",
       " 'CL:0000800': 82,\n",
       " 'CL:0001058': 83,\n",
       " 'CL:0000818': 84,\n",
       " 'CL:0001043': 85,\n",
       " 'CL:0001049': 86,\n",
       " 'CL:0000776': 87}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d98802bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be27cda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-9999: 31,\n",
       " -9998: 19,\n",
       " 0: 10,\n",
       " 1: 124,\n",
       " 2: 59,\n",
       " 3: 4,\n",
       " -9997: 62,\n",
       " 4: 107,\n",
       " -9996: 106,\n",
       " -9995: 41,\n",
       " 5: 58,\n",
       " -9994: 42,\n",
       " -9993: 40,\n",
       " 6: 22,\n",
       " -9992: 6,\n",
       " -9991: 56,\n",
       " -9990: 64,\n",
       " 7: 0,\n",
       " -9989: 24,\n",
       " 8: 3,\n",
       " 9: 11,\n",
       " -9988: 57,\n",
       " 10: 91,\n",
       " 11: 99,\n",
       " -9987: 27,\n",
       " 12: 81,\n",
       " -9986: 48,\n",
       " -9985: 14,\n",
       " -9984: 37,\n",
       " -9983: 15,\n",
       " 13: 17,\n",
       " 14: 127,\n",
       " 15: 119,\n",
       " 16: 142,\n",
       " -9982: 16,\n",
       " -9981: 9,\n",
       " -9980: 30,\n",
       " -9979: 73,\n",
       " -9978: 101,\n",
       " 17: 44,\n",
       " 18: 104,\n",
       " 19: 105,\n",
       " 20: 100,\n",
       " 21: 92,\n",
       " -9977: 18,\n",
       " -9976: 28,\n",
       " -9975: 89,\n",
       " -9974: 78,\n",
       " -9973: 86,\n",
       " 22: 85,\n",
       " 23: 74,\n",
       " -9972: 69,\n",
       " -9971: 72,\n",
       " -9970: 39,\n",
       " 24: 71,\n",
       " 25: 35,\n",
       " 26: 25,\n",
       " -9969: 29,\n",
       " -9968: 70,\n",
       " -9967: 140,\n",
       " 27: 133,\n",
       " -9966: 118,\n",
       " -9965: 34,\n",
       " 28: 33,\n",
       " -9964: 137,\n",
       " -9963: 80,\n",
       " -9962: 117,\n",
       " 29: 83,\n",
       " -9961: 43,\n",
       " -9960: 55,\n",
       " -9959: 12,\n",
       " 30: 90,\n",
       " -9958: 65,\n",
       " -9957: 66,\n",
       " 31: 1,\n",
       " 32: 20,\n",
       " 33: 128,\n",
       " 34: 123,\n",
       " 35: 23,\n",
       " -9956: 112,\n",
       " 36: 63,\n",
       " 37: 21,\n",
       " 38: 8,\n",
       " 39: 97,\n",
       " 40: 96,\n",
       " 41: 2,\n",
       " 42: 36,\n",
       " -9955: 134,\n",
       " -9954: 120,\n",
       " -9953: 136,\n",
       " 43: 52,\n",
       " 44: 135,\n",
       " 45: 93,\n",
       " -9952: 79,\n",
       " -9951: 45,\n",
       " 46: 84,\n",
       " 47: 82,\n",
       " 48: 131,\n",
       " 49: 77,\n",
       " 50: 95,\n",
       " 51: 87,\n",
       " 52: 138,\n",
       " 53: 103,\n",
       " 54: 139,\n",
       " 55: 13,\n",
       " 56: 114,\n",
       " 57: 7,\n",
       " 58: 98,\n",
       " -9950: 121,\n",
       " 59: 122,\n",
       " -9949: 32,\n",
       " 60: 116,\n",
       " -9948: 113,\n",
       " 61: 68,\n",
       " 62: 109,\n",
       " 63: 102,\n",
       " 64: 111,\n",
       " 65: 126,\n",
       " 66: 129,\n",
       " -9947: 5,\n",
       " 67: 26,\n",
       " 68: 53,\n",
       " 69: 54,\n",
       " 70: 130,\n",
       " 71: 141,\n",
       " 72: 88,\n",
       " 73: 94,\n",
       " 74: 67,\n",
       " 75: 47,\n",
       " 76: 50,\n",
       " 77: 76,\n",
       " 78: 51,\n",
       " 79: 61,\n",
       " -9946: 75,\n",
       " 80: 125,\n",
       " -9945: 46,\n",
       " 81: 132,\n",
       " 82: 49,\n",
       " 83: 115,\n",
       " 84: 60,\n",
       " 85: 108,\n",
       " 86: 110,\n",
       " 87: 38}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd2142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d75f938d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CL:0000037', 'CL:0000038', 'CL:0000049', 'CL:0000050',\n",
       "       'CL:0000051', 'CL:0000081', 'CL:0000084', 'CL:0000091',\n",
       "       'CL:0000092', 'CL:0000094', 'CL:0000097', 'CL:0000129',\n",
       "       'CL:0000232', 'CL:0000233', 'CL:0000235', 'CL:0000236',\n",
       "       'CL:0000451', 'CL:0000453', 'CL:0000492', 'CL:0000542',\n",
       "       'CL:0000547', 'CL:0000556', 'CL:0000557', 'CL:0000559',\n",
       "       'CL:0000576', 'CL:0000583', 'CL:0000595', 'CL:0000623',\n",
       "       'CL:0000624', 'CL:0000625', 'CL:0000738', 'CL:0000763',\n",
       "       'CL:0000764', 'CL:0000765', 'CL:0000766', 'CL:0000767',\n",
       "       'CL:0000771', 'CL:0000775', 'CL:0000776', 'CL:0000782',\n",
       "       'CL:0000784', 'CL:0000785', 'CL:0000786', 'CL:0000787',\n",
       "       'CL:0000788', 'CL:0000789', 'CL:0000791', 'CL:0000794',\n",
       "       'CL:0000798', 'CL:0000800', 'CL:0000807', 'CL:0000808',\n",
       "       'CL:0000809', 'CL:0000810', 'CL:0000811', 'CL:0000813',\n",
       "       'CL:0000814', 'CL:0000815', 'CL:0000816', 'CL:0000817',\n",
       "       'CL:0000818', 'CL:0000823', 'CL:0000826', 'CL:0000836',\n",
       "       'CL:0000837', 'CL:0000838', 'CL:0000839', 'CL:0000841',\n",
       "       'CL:0000844', 'CL:0000860', 'CL:0000861', 'CL:0000863',\n",
       "       'CL:0000875', 'CL:0000878', 'CL:0000890', 'CL:0000893',\n",
       "       'CL:0000894', 'CL:0000895', 'CL:0000896', 'CL:0000897',\n",
       "       'CL:0000898', 'CL:0000899', 'CL:0000900', 'CL:0000903',\n",
       "       'CL:0000904', 'CL:0000905', 'CL:0000906', 'CL:0000907',\n",
       "       'CL:0000908', 'CL:0000909', 'CL:0000910', 'CL:0000912',\n",
       "       'CL:0000913', 'CL:0000915', 'CL:0000921', 'CL:0000934',\n",
       "       'CL:0000936', 'CL:0000938', 'CL:0000939', 'CL:0000940',\n",
       "       'CL:0000970', 'CL:0000972', 'CL:0000979', 'CL:0000980',\n",
       "       'CL:0000985', 'CL:0000987', 'CL:0000990', 'CL:0001029',\n",
       "       'CL:0001043', 'CL:0001044', 'CL:0001049', 'CL:0001050',\n",
       "       'CL:0001054', 'CL:0001056', 'CL:0001057', 'CL:0001058',\n",
       "       'CL:0001062', 'CL:0001065', 'CL:0001071', 'CL:0001078',\n",
       "       'CL:0001082', 'CL:0001203', 'CL:0002038', 'CL:0002045',\n",
       "       'CL:0002046', 'CL:0002057', 'CL:0002117', 'CL:0002343',\n",
       "       'CL:0002355', 'CL:0002393', 'CL:0002394', 'CL:0002396',\n",
       "       'CL:0002397', 'CL:0002399', 'CL:0002419', 'CL:0002425',\n",
       "       'CL:0002489', 'CL:0002496', 'CL:0002677', 'CL:0002678',\n",
       "       'CL:1001603', 'CL:2000055', 'CL:3000001'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13d65d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LabelEncoder in module sklearn.preprocessing._label object:\n",
      "\n",
      "class LabelEncoder(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  Encode target labels with value between 0 and n_classes-1.\n",
      " |  \n",
      " |  This transformer should be used to encode target values, *i.e.* `y`, and\n",
      " |  not the input `X`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_targets>`.\n",
      " |  \n",
      " |  .. versionadded:: 0.12\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      Holds the label for each class.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  OrdinalEncoder : Encode categorical features using an ordinal encoding\n",
      " |      scheme.\n",
      " |  OneHotEncoder : Encode categorical features as a one-hot numeric array.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  `LabelEncoder` can be used to normalize labels.\n",
      " |  \n",
      " |  >>> from sklearn import preprocessing\n",
      " |  >>> le = preprocessing.LabelEncoder()\n",
      " |  >>> le.fit([1, 2, 2, 6])\n",
      " |  LabelEncoder()\n",
      " |  >>> le.classes_\n",
      " |  array([1, 2, 6])\n",
      " |  >>> le.transform([1, 1, 2, 6])\n",
      " |  array([0, 0, 1, 2]...)\n",
      " |  >>> le.inverse_transform([0, 0, 1, 2])\n",
      " |  array([1, 1, 2, 6])\n",
      " |  \n",
      " |  It can also be used to transform non-numerical labels (as long as they are\n",
      " |  hashable and comparable) to numerical labels.\n",
      " |  \n",
      " |  >>> le = preprocessing.LabelEncoder()\n",
      " |  >>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
      " |  LabelEncoder()\n",
      " |  >>> list(le.classes_)\n",
      " |  ['amsterdam', 'paris', 'tokyo']\n",
      " |  >>> le.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
      " |  array([2, 2, 1]...)\n",
      " |  >>> list(le.inverse_transform([2, 2, 1]))\n",
      " |  ['tokyo', 'tokyo', 'paris']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LabelEncoder\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  fit(self, y)\n",
      " |      Fit label encoder.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |          Fitted label encoder.\n",
      " |  \n",
      " |  fit_transform(self, y)\n",
      " |      Fit label encoder and return encoded labels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Encoded labels.\n",
      " |  \n",
      " |  inverse_transform(self, y)\n",
      " |      Transform labels back to original encoding.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          Original encoding.\n",
      " |  \n",
      " |  transform(self, y)\n",
      " |      Transform labels to normalized encoding.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Labels as normalized encodings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |      \n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |      \n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from builtins.type\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cell_type_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47897d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f58d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e500d1da",
   "metadata": {},
   "source": [
    "## From The CZI tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483cfde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = census[\"census_data\"][\"homo_sapiens\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ff18319",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_datapipe = census_ml.ExperimentDataPipe(\n",
    "    experiment,\n",
    "    measurement_name=\"RNA\",\n",
    "    X_name=\"raw\",\n",
    "    obs_query=soma.AxisQuery(value_filter=\"tissue_general == 'tongue' and is_primary_data == True\"),\n",
    "    obs_column_names=[\"cell_type\"],\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    soma_chunk_size=10_000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8414ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15020, 60664)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_datapipe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27802bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapipe, test_datapipe = experiment_datapipe.random_split(weights={\"train\": 0.8, \"test\": 0.2}, seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c03005b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dataloader = census_ml.experiment_dataloader(train_datapipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "591f903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()  # noqa: UP008\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09072f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch = batch\n",
    "\n",
    "        X_batch = X_batch.float().to(device)\n",
    "\n",
    "        # Perform prediction\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # Determine the predicted label\n",
    "        probabilities = torch.nn.functional.softmax(outputs, 1)\n",
    "        predictions = torch.argmax(probabilities, axis=1)\n",
    "\n",
    "        # Compute the loss and perform back propagation\n",
    "\n",
    "        # Exclude the cell_type labels, which are in the second column\n",
    "        y_batch = y_batch[:, 1]\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        train_correct += (predictions == y_batch).sum().item()\n",
    "        train_total += len(predictions)\n",
    "\n",
    "        loss = loss_fn(outputs, y_batch.long())\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= train_total\n",
    "    train_accuracy = train_correct / train_total\n",
    "    return train_loss, train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dac0b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0185056 Accuracy 0.2145\n",
      "Epoch 2: Train Loss: 0.0162072 Accuracy 0.2665\n",
      "Epoch 3: Train Loss: 0.0149051 Accuracy 0.3136\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# The size of the input dimension is the number of genes\n",
    "input_dim = experiment_datapipe.shape[1]\n",
    "\n",
    "# The size of the output dimension is the number of distinct cell_type values\n",
    "cell_type_encoder = experiment_datapipe.obs_encoders[\"cell_type\"]\n",
    "output_dim = len(cell_type_encoder.classes_)\n",
    "\n",
    "model = LogisticRegression(input_dim, output_dim).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-05)\n",
    "\n",
    "for epoch in range(3):\n",
    "    train_loss, train_accuracy = train_epoch(model, experiment_dataloader, loss_fn, optimizer, device)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.7f} Accuracy {train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9d6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dataloader = census_ml.experiment_dataloader(test_datapipe)\n",
    "X_batch, y_batch = next(iter(experiment_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f0a8a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1,\n",
       "        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 7, 1, 1, 1, 1, 1, 7,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 7, 7, 1, 1, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "model.to(device)\n",
    "outputs = model(X_batch.to(device))\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(outputs, 1)\n",
    "predictions = torch.argmax(probabilities, axis=1)\n",
    "\n",
    "display(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82ac91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e3a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a857404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cae82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8bc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f489a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ddfd0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "census = cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f4df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\") as census:\n",
    "    cell_metadata = census[\"census_data\"][\"homo_sapiens\"].obs.read(\n",
    "        value_filter = \"sex == 'female' and cell_type in ['microglial cell', 'neuron']\",\n",
    "        column_names = [\"assay\", \"cell_type\", \"tissue\", \"tissue_general\", \"suspension_type\", \"disease\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1309ae24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tiledbsoma._read_iters.TableReadIter at 0x152b7f2edff0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302a947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf15d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment 'file:///scratch/welchjd_root/welchjd99/fujoshua/soma/census_data/homo_sapiens' (CLOSED for 'r')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census[\"census_data\"][\"homo_sapiens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce8ff43",
   "metadata": {},
   "outputs": [
    {
     "ename": "TileDBError",
     "evalue": "[TileDB::Array] Error: Cannot get array schema; Array is not open",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTileDBError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcensus\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcensus_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhomo_sapiens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_filter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex == \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfemale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m and cell_type in [\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmicroglial cell\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneuron\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcell_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtissue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtissue_general\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuspension_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisease\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/tiledbsoma/_dataframe.py:359\u001b[0m, in \u001b[0;36mDataFrame.read\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    349\u001b[0m sr \u001b[38;5;241m=\u001b[39m clib\u001b[38;5;241m.\u001b[39mSOMADataFrame\u001b[38;5;241m.\u001b[39mopen(\n\u001b[1;32m    350\u001b[0m     uri\u001b[38;5;241m=\u001b[39mhandle\u001b[38;5;241m.\u001b[39muri,\n\u001b[1;32m    351\u001b[0m     mode\u001b[38;5;241m=\u001b[39mclib\u001b[38;5;241m.\u001b[39mOpenMode\u001b[38;5;241m.\u001b[39mread,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     timestamp\u001b[38;5;241m=\u001b[39mhandle\u001b[38;5;241m.\u001b[39mtimestamp \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, handle\u001b[38;5;241m.\u001b[39mtimestamp),\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value_filter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     sr\u001b[38;5;241m.\u001b[39mset_condition(QueryCondition(value_filter), \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_reader_coords(sr, coords)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# # TODO: batch_size\u001b[39;00m\n",
      "\u001b[0;31mTileDBError\u001b[0m: [TileDB::Array] Error: Cannot get array schema; Array is not open"
     ]
    }
   ],
   "source": [
    "census[\"census_data\"][\"homo_sapiens\"].obs.read(\n",
    "        value_filter = \"sex == 'female' and cell_type in ['microglial cell', 'neuron']\",\n",
    "        column_names = [\"assay\", \"cell_type\", \"tissue\", \"tissue_general\", \"suspension_type\", \"disease\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1860a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
