{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf4e25ff",
   "metadata": {},
   "source": [
    "Tutorial from https://chanzuckerberg.github.io/cellxgene-census/notebooks/experimental/pytorch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b822fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellxgene_census\n",
    "import cellxgene_census.experimental.ml as census_ml\n",
    "import tiledbsoma as soma\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from torcheval.metrics.functional import multilabel_accuracy\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9355266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e491b4",
   "metadata": {},
   "source": [
    "## Load the Saved Outputs from McCell_preprocessing\n",
    "\n",
    "The preproccessing and modeling here should be run on the **same dataset**. If not, there might be differences in the ordering of cells the would nullify this model. \n",
    "\n",
    "- cell_parent_mask\n",
    "- Mapping_dict\n",
    "- Ontology_df\n",
    "- Internal_values\n",
    "- leaf_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531a2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing outputs are normally stored on Turbo\n",
    "os.chdir('/nfs/turbo/umms-welchjd/mccell/preprocessing_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c952ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the date in yyyy-mm-dd format\n",
    "date = '2024-03-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea04d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_df_name = date + '_ontology_df.csv'\n",
    "ontology_df = pd.read_csv(ontology_df_name,index_col=0)\n",
    "\n",
    "\n",
    "mapping_dict_name = date + '_mapping_dict_df.csv'\n",
    "mapping_dict_df = pd.read_csv(mapping_dict_name,index_col=0)\n",
    "mapping_dict = mapping_dict_df.T.to_dict('list')\n",
    "# the values are stored as a list. convert to single value\n",
    "for key, value in mapping_dict.items():\n",
    "    mapping_dict[key] = value[0]\n",
    "\n",
    "leaf_values_name = date + '_leaf_values'\n",
    "internal_values_name = date + '_internal_values'\n",
    "with open(leaf_values_name,'rb') as fp:\n",
    "    leaf_values = pickle.load(fp)\n",
    "with open(internal_values_name,'rb') as fp:\n",
    "    internal_values = pickle.load(fp)\n",
    "\n",
    "\n",
    "cell_parent_mask_name = date + '_cell_parent_mask.pt'\n",
    "cell_parent_mask = torch.load(cell_parent_mask_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caceac8",
   "metadata": {},
   "source": [
    "## Build the Experiment and the DataPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5274b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene and cell type info stored on Turbo\n",
    "os.chdir('/nfs/turbo/umms-welchjd/mccell')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2d95a",
   "metadata": {},
   "source": [
    "First, let's load the gene list and cell type list that we want from the Census. Then we construct the ```var_val_filter``` and ```obs_val_filter``` for querying the census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91823465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gene list\n",
    "biomart = pd.read_csv('mart_export.txt')\n",
    "\n",
    "coding_only = biomart[biomart['Gene type'] == 'protein_coding']\n",
    "\n",
    "gene_list = coding_only['Gene stable ID'].to_list()\n",
    "\n",
    "var_val_filter = '''feature_id in {}'''.format(gene_list)\n",
    "\n",
    "# load the cell type list\n",
    "cell_type_list_name = 'cell_type_list.txt'\n",
    "with open(cell_type_list_name,'rb') as fp:\n",
    "    cell_type_list = pickle.load(fp)\n",
    "\n",
    "obs_val_filter = '''assay == \"10x 3\\' v3\" and is_primary_data == True and cell_type_ontology_term_id in {}'''.format(cell_type_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f26d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#organism = \"Homo sapiens\"\n",
    "col_names = {\"obs\": [\"cell_type_ontology_term_id\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192a33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the Census and create the Experiment\n",
    "census = cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\")\n",
    "experiment = census[\"census_data\"][\"homo_sapiens\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437e76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8192 #8192 # 4096\n",
    "\n",
    "\n",
    "experiment_datapipe = census_ml.ExperimentDataPipe(\n",
    "    experiment,\n",
    "    measurement_name=\"RNA\",\n",
    "    X_name=\"raw\",\n",
    "    obs_query=soma.AxisQuery(value_filter=obs_val_filter),\n",
    "    var_query=soma.AxisQuery(value_filter=var_val_filter),\n",
    "    obs_column_names=[\"cell_type_ontology_term_id\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    soma_chunk_size=10_000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f2e94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2726029, 19966)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_datapipe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195167e",
   "metadata": {},
   "source": [
    "Split the datapipe into Train and Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1373237",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.8\n",
    "val_percent = 0.2\n",
    "\n",
    "train_datapipe, val_datapipe = experiment_datapipe.random_split(weights={\"train\": train_percent, \"test\": val_percent},\n",
    "                                                                seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f5e6e",
   "metadata": {},
   "source": [
    "Build the dataloaders for the train and test splits. We don't use PyTorch ```DataLoader``` directly because the ```ExperimentDataPipe``` already deals with the necessary parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b58334",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = census_ml.experiment_dataloader(train_datapipe)\n",
    "val_dataloader = census_ml.experiment_dataloader(val_datapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1062363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00ada2e8",
   "metadata": {},
   "source": [
    "## Build Neural Network Classifier\n",
    "\n",
    "First, we need to select and define the input and output dimensions from the data. The number of neurons for the hidden nodes is defined manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07043911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19966 256 128 88\n"
     ]
    }
   ],
   "source": [
    "# number of features (len of X cols)\n",
    "# select the number of gene columns\n",
    "input_dim = experiment_datapipe.shape[1]#X_train.size(dim=1) #adata.X.shape[1] \n",
    "\n",
    "# number of neurons for hidden layers\n",
    "hidden_layer_1 = 256\n",
    "hidden_layer_2 = 128\n",
    "\n",
    "# number of leaf classes (unique of y that are greater than or equal to 0)\n",
    "output_dim = len(leaf_values) #torch.unique(y_train[y_train >= 0]).size(dim=0) #labels['encoded_labels'].nunique()\n",
    "\n",
    "print(input_dim,hidden_layer_1,hidden_layer_2,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d64bec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim,hidden_layer_1)\n",
    "        self.linear2 = nn.Linear(hidden_layer_1,hidden_layer_2)\n",
    "        self.linear3 = nn.Linear(hidden_layer_2,output_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_layer_1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_layer_2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "    \n",
    "    def get_last_layer(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf977d",
   "metadata": {},
   "source": [
    "## Functions for dealing with cell ontology and loss calculations\n",
    "\n",
    "We'll need a few specific functions to process the predicted values with the structure of the Cell Ontology. We'll define these here. Full details of each function are found in each space. \n",
    "\n",
    "- output_probability_tensor: convolves the predicted classification outputs with the ontology hierarchy to get predicted normalized probabilities for all parent nodes\n",
    "- target_probability_tensor: convolves the known target values with the ontology hierarchy to get target probabilities for all parent nodes\n",
    "- build_mask_tensor_for_batch : builds a masking tensor from cell_parent_mask specific to the targets for each batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a022561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(x_data):\n",
    "    '''\n",
    "    This function takes the input x_data, transforms the data with log(1+x) and \n",
    "    returns the transformed data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_data : scipy matrix\n",
    "        scipy sparse CSR matrix  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x_data : SciPy Matrix\n",
    "        scipy sparse CSR matrix\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # np.log takes the natural log\n",
    "    x_data.data = np.log(1+ x_data.data)\n",
    "\n",
    "    return x_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83a3c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_probability_tensor(outputs,ontology_df):\n",
    "    '''\n",
    "    Function to convolve the predicted classification outputs with the ontology heirarchy to\n",
    "    get predicted normalized probabilities for all parents. \n",
    "    Precursur to loss calculation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    outputs : tensor\n",
    "        PyTorch tensor of shape [a,b] where a = number of cells and b = number of target leafs\n",
    "        This tensor is the result of the classification in the neural network\n",
    "                \n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where rows are parent labels and columns are leafs\n",
    "        values indicate if parent node is an ancestor of leaf node\n",
    "\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    sum_probability_tensor : tensor\n",
    "        PyTorch tensor of shape [c,a] where c = number of cell ontology IDs and a = number of cells\n",
    "        Each entry is the summed predicted probability for that cell ID\n",
    "\n",
    "    '''\n",
    "        \n",
    "    # convert the dataframe to a pytorch tensor\n",
    "    ontology_tensor = torch.FloatTensor(ontology_df.values)\n",
    "    ontology_tensor = ontology_tensor.to(device)\n",
    "        \n",
    "    # convolve the ontology tensor with the predicted outputs\n",
    "    # ontology tensor is shape ij, where i = parent IDs, j = probability for leaf IDs\n",
    "    # output tensor is shape kj, where k = number of cells classified, j = probability for leaf IDs\n",
    "    # probability tensor is shape ijk\n",
    "    \n",
    "    # if there is only a single column for the ontology, change shape to match expected value\n",
    "    if len(ontology_tensor.shape) == 1:\n",
    "        ontology_tensor = ontology_tensor.unsqueeze(1)    \n",
    "    #print(ontology_tensor.shape)\n",
    "    #print(outputs.shape)\n",
    "    probability_tensor = torch.einsum('ij,kj->ijk',ontology_tensor,outputs)\n",
    "    #print('prob_tensor', probability_tensor.shape)\n",
    "    \n",
    "    # sum across leafs to get the predicted probability, by cell, for each\n",
    "    # parent \n",
    "    # sum_probability_tensor is shape ik, where i = parent IDs, k = number of cells\n",
    "    sum_probability_tensor = torch.sum(probability_tensor,dim=1,dtype=float)\n",
    "    \n",
    "    ##sum_masked_probability_tensor = sum_probability_tensor * batch_masking_tensor\n",
    "    #print('sum masked',sum_masked_probability_tensor.shape)\n",
    "    #print('sum masked',sum_masked_probability_tensor.sum(dim=1))\n",
    "    # ensure that the max value is 1 because of floating point issues\n",
    "    # if we don't do this, we can run into errors with the binary cross entropy\n",
    "    ##sum_masked_probability_tensor = torch.where(sum_masked_probability_tensor > 1, 1.0, sum_masked_probability_tensor )\n",
    "    sum_probability_tensor = torch.where(sum_probability_tensor > 1, 1.0, sum_probability_tensor )\n",
    "\n",
    "    return sum_probability_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0e3aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mask_tensor_for_batch(cell_parent_mask,y_batch,min_encoded_value,max_encoded_value):\n",
    "    '''\n",
    "    For each batch, this function builds the correct masking tensor based on which\n",
    "    values of the cell ontology we want to include given the target. It returns aa \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cell_parent_mask : tensor\n",
    "        tensor of shape ik, where i = parent IDs and k = each cell type in the dataset\n",
    "        binary tensor where 1 means for that cell type, that parent ID will be included\n",
    "        in the internal loss calculation\n",
    "        and 0 means for that cell type, that parent ID is excluded in the internal loss\n",
    "        calculation\n",
    "                \n",
    "    y_batch : tensor\n",
    "        tensor with encoded target values for current batch of data\n",
    "        \n",
    "    min_encoded_value : int\n",
    "        the minimum encoded value from the full set of target values. Typically -9999\n",
    "        \n",
    "    max_encoded_value : int\n",
    "        the maximum encoded value from the full set of target values. Depends on number\n",
    "        of leaf targets in the dataset\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    batch_masking_tensor : tensor\n",
    "        PyTorch tensor of shape [c,a] where c = number of cell ontology IDs and a = number of cells\n",
    "        Binary tensor to zero out probabilities we do not want\n",
    "    \n",
    "    '''\n",
    "    # 1) from y_batch, we need to get the indices we'll use to select from cell_parent_mask\n",
    "    #.   all the positive values are each, but we need to convert the negative values to\n",
    "    #.   correspond with the (positive) index they would otherwise be. Then save to a tensor\n",
    "    \n",
    "    for value in y_batch:\n",
    "        if value >= 0:\n",
    "            new_value = value\n",
    "        else:\n",
    "            new_value = (value - min_encoded_value) + max_encoded_value + 1\n",
    "        try:\n",
    "            converted_y_batch = torch.cat((converted_y_batch,new_value.reshape(1)),dim=0)\n",
    "        except:\n",
    "            converted_y_batch = new_value.reshape(1)\n",
    "    \n",
    "    \n",
    "    # 2) use the y_batch converted values to build a new tensor from cell_parent_mask\n",
    "    #.    that is the mask we will use for this batch of values.\n",
    "    #.    return this tensor\n",
    "\n",
    "    cell_parent_mask = cell_parent_mask.to(device)\n",
    "    batch_masking_tensor = torch.index_select(cell_parent_mask,1,converted_y_batch)\n",
    "    #print(batch_masking_tensor.sum(dim=0))\n",
    "    \n",
    "    return(batch_masking_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47cb3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_probability_tensor(target_values,ontology_df,mapping_dict):\n",
    "    '''\n",
    "    Function to convolve the known target values with the ontology heirarchy\n",
    "    Precursur to loss calculation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    target_values : tensor\n",
    "        PyTorch tensor of shape [a] where a = number of cells\n",
    "                \n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where rows are parent labels and columns are leafs\n",
    "        values indicate if parent node is an ancestor of leaf node\n",
    "\n",
    "    mapping_dict : dictionary\n",
    "        dictionary mapping the Cell Ontology IDs (keys) to the encoded values (values)\n",
    "        Values >= 0 are leaf nodes\n",
    "        Values < 0 are internal nodes\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    target_tensor : tensor\n",
    "        PyTorch tensor of shape [c,a] where c = number of cell ontology IDs and a = number of cells\n",
    "        Each entry is the summed predicted probability for that cell ID\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # loop through target values, pick out corresponding column of ontology_df\n",
    "    # append that to a tensor\n",
    "    \n",
    "    # invert the mapping dict so that we can select columns by CELL TYPE ID\n",
    "    inv_mapping_dict = {v: k for k,v in mapping_dict.items()}\n",
    "\n",
    "    for count, target_value in enumerate(target_values):\n",
    "        # get the cell ID from the inverted mapping dictionary based on the encoded value\n",
    "        target_cell_id = inv_mapping_dict[target_value.item()]\n",
    "        \n",
    "        # look up the correct column by the Cell ID. get those column values and convert\n",
    "        # to a tensor\n",
    "        sub_target_tensor = torch.tensor(ontology_df.loc[:,target_cell_id].values,dtype=float).reshape(-1,1)\n",
    "        \n",
    "        if count == 0 :\n",
    "            target_tensor = sub_target_tensor\n",
    "        else:\n",
    "            # set requires_grad so that we can track\n",
    "            target_tensor = torch.cat((target_tensor,sub_target_tensor),1).requires_grad_()\n",
    "    #print('target tensor shape',target_tensor.shape)\n",
    "    #print('batch_masking_tensor',batch_masking_tensor.shape)\n",
    "    ###masked_target_tensor = target_tensor * batch_masking_tensor\n",
    "    ##print('masked target tensor',masked_target_tensor.shape)\n",
    "    \n",
    "    target_tensor = target_tensor.to(device)\n",
    "    ###masked_target_tensor = masked_target_tensor.to(device)\n",
    "    \n",
    "    \n",
    "    return target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8669d06",
   "metadata": {},
   "source": [
    "## Define Train and Test Models\n",
    "\n",
    "Next, we define functions to train/test the models for a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb6703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf08074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e85f3a8f",
   "metadata": {},
   "source": [
    "# Marginalization Classification \n",
    "\n",
    "- Based on Dahll, et al., Hierarchical Image Classification using Entailment Cone Embeddings, CVPR 202\n",
    "- https://arxiv.org/pdf/2004.03459.pdf\n",
    "- Thesis slides: https://ankitdhall.github.io/publication/learning-representations-for-images-with-hierarchical-labels/master_thesis.pdf\n",
    "- First Author website: https://ankitdhall.github.io/project/learning-representations-for-images-with-hierarchical-labels/\n",
    "\n",
    "Important Details:\n",
    "- we use mini-batch learning, with the batch size set by the user\n",
    "- we model each batch of data at once, then split into leaf and internal nodes, based on the values in y_batch\n",
    "- we calculate the loss two different ways, then sum to get the total loss\n",
    "- we calculate and save the loss, accuracy, and F1 score for metrics to review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9dae7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginalization_classification_manual_batch(train_dataloader,val_dataloader,num_epochs,ontology_leaf_df, \n",
    "                                                batch_size,internal_values,mapping_dict,\n",
    "                                               ontology_df, threshold, cell_parent_mask,encoding_mapper):\n",
    "    '''\n",
    "    Performs training and validation simultaneously to allow visualization of model performance \n",
    "    per epoch. Accounts for entire tree structure of the ontology by classifying to the leaf nodes, \n",
    "    propogating the probabilities across the ontology, and calculating the loss for both the leafs \n",
    "    and parent nodes. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : Tensor\n",
    "        pytorch tensor of training values\n",
    "    \n",
    "    X_val : Tensor\n",
    "        pytorch tensor of validation values\n",
    "        \n",
    "    y_train : Tensor\n",
    "        pytorch tensor of training target values\n",
    "        \n",
    "    y_val : Tensor\n",
    "        pytorch tensor of validation target values\n",
    "    \n",
    "    num_epochs : int\n",
    "        integer specify the number of epochs\n",
    "        \n",
    "    ontology_leaf_df : pandas dataframe\n",
    "        pandas dataframe where indices (rows) are all leaf and parent cell IDs from the portion of \n",
    "        the ontology being queried, and columns are onlys leafs in portion of ontology being queried. \n",
    "        Differs from ontology_df in that columns do not include any internal nodes.\n",
    "        \n",
    "        Dataframe is binary. For each parent node, element = 1 if parent node is an ancestor\n",
    "        of corresponding leaf node.\n",
    "    \n",
    "    batch_size : int\n",
    "        integer specificying the number of samples processed before the model\n",
    "        is updated\n",
    "        \n",
    "    internal_values : list\n",
    "        list of Cell Ontology IDs for internal nodes included in the dataset\n",
    "        \n",
    "    mapping_dict : dict\n",
    "        dictionary mapping the Cell Ontology IDs (keys) to the encoded values (values)\n",
    "        Values >= 0 are leaf nodes\n",
    "        Values < 0 are internal nodes\n",
    "    \n",
    "    ontology_df : pandas dataframe\n",
    "        pandas dataframe where indices (rows) are all leaf and parent cell IDs from the portion of \n",
    "        the ontology being queried, and columns are leafs and internal nodes in portion of ontology being \n",
    "        queried. \n",
    "        Differs from ontology_leaf_df in that columns include both leaf and internal node values\n",
    "        \n",
    "        Dataframe is binary. For each parent node, element = 1 if parent node is an ancestor\n",
    "        of corresponding leaf node.\n",
    "        \n",
    "    threshold : float\n",
    "        value between 0 and 1 to set for making predictions. If the predicted probability is\n",
    "        equal to or greater than threshold, we consider that a true prediction\n",
    "        \n",
    "    cell_parent_mask : tensor\n",
    "        tensor of shape ik, where i = parent IDs and k = each cell type in the dataset\n",
    "        binary tensor where 1 means for that cell type, that parent ID will be included\n",
    "        in the internal loss calculation\n",
    "        and 0 means for that cell type, that parent ID is excluded in the internal loss\n",
    "        calculation\n",
    "\n",
    "        \n",
    "    Returns\n",
    "    -------    \n",
    "    marginalization_dict : dictionary\n",
    "        dictionary containing results from each epoch of the neural network\n",
    "    \n",
    "    Keys and Values include:\n",
    "    \n",
    "        accuracy_train_leaf_hist : list\n",
    "            list containing accuracy for leaf values for the training set per epoch\n",
    "            \n",
    "        accuracy_train_internal_hist : list\n",
    "            list containing accuracy for internal values for the trainig set per epoch\n",
    "        \n",
    "        loss_train_hist: list\n",
    "            list containing total loss values for the training set per epoch\n",
    "            \n",
    "        loss_train_leaf_hist : list\n",
    "            list containing loss values for leaf nodes for the training set per epoch\n",
    "            \n",
    "        loss_train_parents_hist : list\n",
    "            list containing loss values for parent nodes for the training set per epoch\n",
    "        \n",
    "        loss_train_internal_hist : list\n",
    "            list containing loss values for internal nodes for the training set per epoch\n",
    "        \n",
    "        accuracy_val_leaf_hist : list \n",
    "            list containing accuracy for leaf values for the validation set per epoch\n",
    "        \n",
    "        accuracy_val_internal_hist : list\n",
    "            list containing accuracy for internal values for the validation set per epoch\n",
    "        \n",
    "        loss_val_hist : list\n",
    "            list containing total loss values for the validation set per epoch\n",
    "            \n",
    "        loss_val_leaf_hist : list\n",
    "            list containing loss values for leaf nodes for the validation set per epoch\n",
    "            \n",
    "        loss_val_parents_hist : list\n",
    "            list containing loss values for parent nodes for the validation set per epoch\n",
    "            \n",
    "        loss_val_internal_hist : list\n",
    "            list containing loss values for internal nodes for the validation set per epoch\n",
    "        \n",
    "        f1_score_train_leaf : list\n",
    "            list containing Macro F1 score for leaf nodes for training set per epoch \n",
    "        \n",
    "        f1_score_val_leaf : list\n",
    "            list containing Macro F1 score for leaf nodes for validation set per epoch \n",
    "        \n",
    "        best_output : tensor\n",
    "            PyTorch tensor containing the predicted probabilites for the most accurate\n",
    "            epoch\n",
    "            \n",
    "        best_state_dict : dictionary\n",
    "            Pytorch state_dict that contains the parameters for the best fitting models\n",
    "    '''\n",
    "    # initialize variables for saving values\n",
    "    accuracy_train_leaf_hist = []\n",
    "    accuracy_train_internal_hist = []\n",
    "    loss_train_leaf_hist = []\n",
    "    loss_train_parents_hist = []\n",
    "    loss_train_internal_hist = []\n",
    "    loss_train_hist = []\n",
    "    \n",
    "    accuracy_val_leaf_hist = []\n",
    "    accuracy_val_internal_hist = []\n",
    "    loss_val_hist = []\n",
    "    loss_val_leaf_hist = []\n",
    "    loss_val_parents_hist = []\n",
    "    loss_val_internal_hist = []\n",
    "    \n",
    "    f1_score_train_leaf = []\n",
    "    f1_score_val_leaf = []\n",
    "    \n",
    "    f1_score_train_parent = []\n",
    "    f1_score_val_parent = []\n",
    "\n",
    "    best_accuracy = - np.inf\n",
    "    best_weights = None\n",
    "    \n",
    "    # get the list of leaf labels\n",
    "    leaf_label_list = [value for (key,value) in mapping_dict.items() if value >= 0]\n",
    "\n",
    "    # get the min and max encoded values\n",
    "    min_encoded_value = min(mapping_dict.values()) #min(y_train).item()\n",
    "    max_encoded_value = max(mapping_dict.values()) #max(y_train).item()\n",
    "\n",
    "    # initialize network\n",
    "    clf = Network()\n",
    "    clf.to(device)\n",
    "\n",
    "    # define loss and optimizer\n",
    "    # we use two different loss methods for the leafs and parents\n",
    "    # use Cross Entory Loss for leafs, because those probabilities are normalized\n",
    "    #     and it is thus a multi-class problem\n",
    "    # Use BCELoss for the parents because this is a multi-label problem\n",
    "    #     and the probabilities are normalized, so we don't need BCELossWithLogits\n",
    "    # initialize the leaf loss here\n",
    "    # because of how we weight the parent loss, we will have to initialize that\n",
    "    # loss on each iteration because the weighting will change.\n",
    "    criterion_leafs = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    #criterion_parents = nn.BCELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(clf.parameters(), lr=1e-3)#, amsgrad=True, eps=1e-5)\n",
    "    #scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.5, total_iters=5)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5,gamma=0.5)\n",
    "\n",
    "    #start_epoch = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        #print('on epoch', epoch)\n",
    "        \n",
    "        # TRAINING\n",
    "        #print('Begin Training...')\n",
    "        clf.train()\n",
    "        \n",
    "        running_train_loss = 0.0\n",
    "        #correct_train = 0\n",
    "        #y_length = 0\n",
    "                \n",
    "        # set up manual batches - from https://stackoverflow.com/questions/45113245/how-to-get-mini-batches-in-pytorch-in-a-clean-and-efficient-way\n",
    "        #permutation = torch.randperm(X_train.size()[0]).to(device)\n",
    "        #permutation_cpu = permutation.cpu() # we want the same permutations, but need one copy on the cpu\n",
    "\n",
    "        #start = time.time()\n",
    "        #for i in range(0,X_train.size()[0], batch_size):\n",
    "        for i, train_batch in enumerate(train_dataloader):\n",
    "            #if (i/batch_size) % 10 == 0:\n",
    "            #print('on batch', i/batch_size, 'running time', (time.time()-start))\n",
    "\n",
    "            #indices = permutation[i:i+batch_size]\n",
    "            #indices_cpu = permutation_cpu[i:i+batch_size]\n",
    "            #X_batch, y_batch = X_train[indices], y_train[indices] # doesn't work for sparse tensors\n",
    "\n",
    "            #X_batch = torch.index_select(X_train,0,indices_cpu).to(device)\n",
    "\n",
    "            #y_batch = torch.index_select(y_train,0,indices)#.to(device)\n",
    "\n",
    "            X_batch, y_batch = train_batch\n",
    "            \n",
    "            # move batch to GPU\n",
    "            X_batch = X_batch.float().to(device)\n",
    "            \n",
    "            # transform the data with log(1+x)\n",
    "            X_batch = transform_data(X_batch)\n",
    "            \n",
    "            # select the encoded values from the experiment_datapipe\n",
    "            y_batch = y_batch[:,1]\n",
    "            #print(y_batch)\n",
    "\n",
    "            # then map the values from the datapipe encoded values to the\n",
    "            # encoded values from the Ontology/mapping_dict\n",
    "            \n",
    "            #encoding_mapper\n",
    "            y_batch = torch.tensor([encoding_mapper[x.item()] for x in y_batch])\n",
    "            \n",
    "            #print(y_batch)\n",
    "            \n",
    "            # check that tensors are on gpu. if on gpu, get_device returns 0, if on cpu, returns -1\n",
    "            #print(X_batch.get_device())\n",
    "            #print(y_batch.get_device())\n",
    "            \n",
    "            # set optimizer to zero grad to remove previous epoch gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # make predictions for this batch\n",
    "            #if epoch == 0:\n",
    "            #    outputs_train = clf_nosoftmax(X_batch.float()) # might need to change to X_train.float()\n",
    "            #else:\n",
    "            outputs_train = clf(X_batch) # might need to change to X_train.float()\n",
    "            \n",
    "            ######\n",
    "            # create mask to separate leaf and internal nodes\n",
    "            ######\n",
    "            output_train_leaf = outputs_train[y_batch >= 0]\n",
    "            #print(output_train_leaf.shape)\n",
    "            y_batch_leaf = y_batch[y_batch >= 0]\n",
    "            #print(y_batch_leaf.shape)\n",
    "            \n",
    "            #output_train_internal = outputs_train[y_batch < 0]\n",
    "            #y_batch_internal = y_batch[y_batch < 0]\n",
    "            \n",
    "\n",
    "            # calculate loss for just the leafs\n",
    "            loss_train_leafs = criterion_leafs(output_train_leaf, y_batch_leaf)\n",
    "\n",
    "            # get the masking tensor for this batch of cells\n",
    "            # for calculating the internal loss\n",
    "            # we initialize BCE loss every batch because the mask changes based on which cells are\n",
    "            # included and ordered for this batch\n",
    "            batch_train_masking_tensor = build_mask_tensor_for_batch(cell_parent_mask,y_batch,min_encoded_value,max_encoded_value)\n",
    "            criterion_parents = nn.BCELoss(weight=batch_train_masking_tensor,reduction='mean')\n",
    "\n",
    "            \n",
    "            # calculate the loss for the parents of the cells that are leafs\n",
    "            output_train_parent_prob = output_probability_tensor(outputs_train,ontology_leaf_df)\n",
    "            target_train_parent_prob = target_probability_tensor(y_batch,ontology_df,mapping_dict)\n",
    "\n",
    "            #print(output_train_parent_prob)\n",
    "            #print('output_train_parent_prob',output_train_parent_prob.shape)\n",
    "            #print(target_train_parent_prob)\n",
    "            #print('target_train_parent_prob',target_train_parent_prob.shape)\n",
    "            \n",
    "            loss_train_parents = criterion_parents(output_train_parent_prob,target_train_parent_prob)\n",
    "\n",
    "            #######\n",
    "            # calculate the loss for the cells that are internal nodes\n",
    "            ##### total_accuracy_cell, total_number_of_cells\n",
    "            \n",
    "            #loss_train_internal, batch_accuracy_internal, batch_numbers_internal = internal_node_loss(\n",
    "            #                                        output_train_internal,y_batch_internal,\n",
    "            #                                         internal_values,mapping_dict,ontology_df,\n",
    "            #                                        ontology_leaf_df,criterion_parents,threshold)\n",
    "            \n",
    "            # sum the loss for both leafs and parents\n",
    "            loss_train = loss_train_leafs + loss_train_parents #+ loss_train_internal\n",
    "\n",
    "            # backward propagation\n",
    "            loss_train.backward()\n",
    "\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "             \n",
    "            running_train_loss += loss_train.item()\n",
    "           \n",
    "            # save predictions\n",
    "            _, train_leaf_pred_per_epoch = output_train_leaf.max(dim=1)\n",
    "\n",
    "            # calculate accuracy for internal cells\n",
    "            #####\n",
    "            # need to update this with the weighting somehow!!!!\n",
    "            #####\n",
    "            train_batch_accuracy = multilabel_accuracy(output_train_parent_prob,target_train_parent_prob,\n",
    "                                                      threshold=threshold,criteria='hamming')\n",
    "            \n",
    "            # save the number of cells for batch, for use in weighting when\n",
    "            # determining the overall accuracy per epoch\n",
    "            train_batch_number_of_cells = output_train_parent_prob.shape[1]\n",
    "                        \n",
    "            # check size of internal tensors. if only 1 internal cell\n",
    "            # reshape and detach\n",
    "            # else just detach\n",
    "            \n",
    "            ##if len(batch_accuracy_internal.size()) == 0:\n",
    "            ##    batch_accuracy_internal_shaped = batch_accuracy_internal.detach().reshape(1)\n",
    "            ##    batch_numbers_internal_shaped = batch_numbers_internal.detach().reshape(1)\n",
    "            ##else:\n",
    "            ##    batch_accuracy_internal_shaped = batch_accuracy_internal.detach()\n",
    "            ##    batch_numbers_internal_shaped = batch_numbers_internal.detach()\n",
    "                \n",
    "            \n",
    "            if i == 0:\n",
    "                train_leaf_pred_total = train_leaf_pred_per_epoch.detach()\n",
    "                y_train_leaf_total = y_batch_leaf.detach()\n",
    "                train_batch_accuracy_internal = train_batch_accuracy.reshape(1)\n",
    "                train_total_number_of_cells = torch.tensor(train_batch_number_of_cells).reshape(1)\n",
    "                output_train_probabilities = output_train_leaf.detach()\n",
    "                train_parent_pred_total = output_train_parent_prob.detach()\n",
    "                train_parent_true_total = target_train_parent_prob.detach()\n",
    "            else:\n",
    "                train_leaf_pred_total = torch.cat((train_leaf_pred_total,train_leaf_pred_per_epoch.detach()),0)\n",
    "                y_train_leaf_total = torch.cat((y_train_leaf_total,y_batch_leaf.detach()),0)\n",
    "                train_batch_accuracy_internal = torch.cat((train_batch_accuracy_internal,train_batch_accuracy.reshape(1)),0)\n",
    "                train_total_number_of_cells = torch.cat((train_total_number_of_cells,torch.tensor(train_batch_number_of_cells).reshape(1)),0)\n",
    "                output_train_probabilities = torch.cat((output_train_probabilities,output_train_leaf.detach()),0)\n",
    "                train_parent_pred_total = torch.cat((train_parent_pred_total,output_train_parent_prob.detach()),1)\n",
    "                train_parent_true_total = torch.cat((train_parent_true_total,target_train_parent_prob.detach()),1)\n",
    "                #print('train parent pred',train_parent_pred_total.shape)\n",
    "                #print('train parent true',train_parent_true_total.shape)\n",
    "                            \n",
    "            # calculate total epoch accuracy for internal nodes\n",
    "            #epoch_internal_accuracy = / train_numbers_internal.sum() * 100\n",
    "            \n",
    "            #correct_train += (train_pred_per_epoch == y_batch).sum().item()\n",
    "            #y_length += len(y_batch)\n",
    "            \n",
    "            # calculate F1 score\n",
    "            #f1_val_score_epoch = f1_score(train_pred_per_epoch.cpu(),y_batch.cpu(),labels=output_dim,average='weighted',zero_division=np.nan)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        # save tensors\n",
    "        #if epoch == 14:\n",
    "        #    torch.save(output_train_probabilities, 'output_good_nosoftmax_1Dec.pt')\n",
    "        #    torch.save(y_train_leaf_total, 'targets_good_nosoftmax_1Dec.pt')\n",
    "        \n",
    "        # save accuracy\n",
    "        #_, train_pred = outputs_train.max(dim=1)\n",
    "        #correct_train = (train_pred == y_train).sum().item()\n",
    "        #accuracy_train_hist.append(correct_train / y_length * 100.)\n",
    "        #print('acc train hist', accuracy_train_hist[-1])\n",
    "        \n",
    "        train_total_number_of_cells = train_total_number_of_cells.to(device)\n",
    "        \n",
    "        correct_train_leaf = (train_leaf_pred_total == y_train_leaf_total).sum().item()\n",
    "        accuracy_train_leaf_hist.append(correct_train_leaf / train_leaf_pred_total.shape[0] * 100.)\n",
    "                \n",
    "        correct_train_internal = (train_batch_accuracy_internal * train_total_number_of_cells).sum()\n",
    "        accuracy_train_internal = (correct_train_internal / train_total_number_of_cells.sum() * 100.).item()\n",
    "        accuracy_train_internal_hist.append(accuracy_train_internal)\n",
    "        \n",
    "        #print('sample acc', acc_full)\n",
    "\n",
    "        # save loss\n",
    "        loss_train_hist.append(loss_train.item())\n",
    "        loss_train_leaf_hist.append(loss_train_leafs.item())\n",
    "        loss_train_parents_hist.append(loss_train_parents.item())\n",
    "        ##loss_train_internal_hist.append(loss_train_internal.item())\n",
    "        \n",
    "        # save f1 score\n",
    "        # use average = weighted to account for label imbalance\n",
    "        # use zero_division = np.nan to exclude labels where all \n",
    "        #       predictions and labels are negative\n",
    "        f1_train_leaf_score = f1_score(y_train_leaf_total.cpu(), train_leaf_pred_total.cpu(),\n",
    "                                  labels=leaf_label_list,average='weighted',zero_division=np.nan)\n",
    "        f1_score_train_leaf.append(f1_train_leaf_score)\n",
    "        \n",
    "        # for the F1 score for the internal nodes, we need to first turn the probabilities\n",
    "        # into predictions using our threshold value\n",
    "        train_parent_pred_total_thresholded = torch.where(train_parent_pred_total > threshold,1.0,0.0)\n",
    "        \n",
    "        f1_train_parent_score = f1_score(train_parent_true_total.cpu(),train_parent_pred_total_thresholded.cpu(),\n",
    "                                        average='weighted',zero_division=np.nan)\n",
    "        f1_score_train_parent.append(f1_train_parent_score)\n",
    "        #torch.save(train_parent_true_total.cpu(),'train_parent_true_total_20Feb.pt')\n",
    "        #torch.save(train_parent_pred_total_thresholded.cpu(),'train_parent_pred_total_thresholded_20Feb.pt')\n",
    "\n",
    "        \n",
    "        # set up validation\n",
    "        correct_val = 0\n",
    "        y_val_length = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            clf.eval()\n",
    "            \n",
    "            # set up manual batches\n",
    "            # we don't need to randomly permute the validation set, but\n",
    "            # this will provide consistency with the above.\n",
    "            # for simplicity, let's use the same batch size\n",
    "            #permutation_val = torch.randperm(X_val.size()[0]).to(device)\n",
    "            #start_val = time.time()\n",
    "            \n",
    "            #for i in range(0,X_val.size()[0],batch_size):\n",
    "            for i, val_batch in enumerate(val_dataloader):\n",
    "\n",
    "                #indices_val = permutation_val[i:i+batch_size]\n",
    "                \n",
    "                #X_val_batch = torch.index_select(X_val,0,indices_val)\n",
    "                #y_val_batch = torch.index_select(y_val,0,indices_val)\n",
    "                \n",
    "                \n",
    "                \n",
    "                X_val_batch, y_val_batch = val_batch\n",
    "            \n",
    "                # move batch to device\n",
    "                X_val_batch = X_val_batch.float().to(device)\n",
    "\n",
    "                # transform the data with log(1+x)\n",
    "                X_val_batch = transform_data(X_val_batch)\n",
    "\n",
    "                # select the encoded values from the experiment_datapipe\n",
    "                y_val_batch = y_val_batch[:,1]\n",
    "                #print(y_batch)\n",
    "\n",
    "                # then map the values from the datapipe encoded values to the\n",
    "                # encoded values from the Ontology/mapping_dict\n",
    "\n",
    "                #encoding_mapper\n",
    "                y_val_batch = torch.tensor([encoding_mapper[x.item()] for x in y_val_batch])\n",
    "                \n",
    "                \n",
    "                # calculate output by running through the network\n",
    "                outputs_val = clf(X_val_batch\n",
    "            \n",
    "                ######\n",
    "                # create mask to separate leaf and internal nodes\n",
    "                ######\n",
    "                output_val_leaf = outputs_val[y_val_batch >= 0]\n",
    "                y_val_batch_leaf = y_val_batch[y_val_batch >= 0]\n",
    "\n",
    "                #output_val_internal = outputs_val[y_val_batch < 0]\n",
    "                #y_val_batch_internal = y_val_batch[y_val_batch < 0]\n",
    "            \n",
    "                # calculate loss for just the leafs\n",
    "                loss_val_leafs = criterion_leafs(output_val_leaf, y_val_batch_leaf)\n",
    "        \n",
    "                # get the masking tensor for this batch of cells\n",
    "                # for calculating the internal loss\n",
    "                # we initialize BCE loss every batch because the mask changes based on which cells are\n",
    "                # included and ordered for this batch\n",
    "                batch_val_masking_tensor = build_mask_tensor_for_batch(cell_parent_mask,y_val_batch,min_encoded_value,max_encoded_value)\n",
    "                criterion_parents = nn.BCELoss(weight=batch_val_masking_tensor,reduction='mean')\n",
    "                \n",
    "                # calculate the loss for the parents of the leafs\n",
    "                output_val_parent_prob = output_probability_tensor(outputs_val,ontology_leaf_df)\n",
    "                target_val_parent_prob = target_probability_tensor(y_val_batch,ontology_df,mapping_dict)\n",
    "                \n",
    "                loss_val_parents = criterion_parents(output_val_parent_prob,target_val_parent_prob)\n",
    "\n",
    "                #######\n",
    "                # calculate the loss for the cells that are internal nodes\n",
    "                #####\n",
    "\n",
    "                #loss_val_internal, batch_accuracy_internal_val, batch_numbers_internal_val = internal_node_loss(output_val_internal,\n",
    "                #                                                y_val_batch_internal,\n",
    "                #                                                internal_values,mapping_dict,ontology_df,ontology_leaf_df,\n",
    "                #                                                criterion_parents,threshold)\n",
    "\n",
    "                \n",
    "                # sum the loss for both leafs and parents\n",
    "                loss_val = loss_val_leafs + loss_val_parents #+ loss_val_internal\n",
    "            \n",
    "            \n",
    "                # get the predictions\n",
    "                __, predicted_leaf_val_per_epoch = output_val_leaf.max(dim=1)            \n",
    "\n",
    "                # calculate accuracy for internal cells\n",
    "                #####\n",
    "                # need to update this with the weighting somehow!!!!\n",
    "                #####\n",
    "                val_batch_accuracy = multilabel_accuracy(output_val_parent_prob,target_val_parent_prob,\n",
    "                                                          threshold=threshold,criteria='hamming')\n",
    "\n",
    "                # save the number of cells for batch, for use in weighting when\n",
    "                # determining the overall accuracy per epoch\n",
    "                val_batch_number_of_cells = output_val_parent_prob.shape[1]\n",
    "\n",
    "                \n",
    "                # save accuracy\n",
    "                #correct_val += (predicted_val_per_epoch == y_val_batch).sum().item()\n",
    "                #y_val_length += len(y_val_batch)\n",
    "                \n",
    "                # check size of internal tensors. if only 1 internal cell\n",
    "                # reshape and detach\n",
    "                # else just detach\n",
    "                            \n",
    "                #if len(batch_accuracy_internal_val.size()) == 0:\n",
    "                #    batch_accuracy_internal_val_shaped = batch_accuracy_internal_val.detach().reshape(1)\n",
    "                #    batch_numbers_internal_val_shaped = batch_numbers_internal_val.detach().reshape(1)\n",
    "                #else:\n",
    "                #    batch_accuracy_internal_val_shaped = batch_accuracy_internal_val.detach()\n",
    "                #    batch_numbers_internal_val_shaped = batch_numbers_internal_val.detach()\n",
    "                                \n",
    "                if i == 0:\n",
    "                    val_leaf_pred_total = predicted_leaf_val_per_epoch.detach()\n",
    "                    y_leaf_val_total = y_val_batch_leaf.detach()\n",
    "                    val_batch_accuracy_internal = val_batch_accuracy.reshape(1)\n",
    "                    val_total_number_of_cells = torch.tensor(val_batch_number_of_cells).reshape(1)\n",
    "                    val_parent_pred_total = output_val_parent_prob.detach()\n",
    "                    val_parent_true_total = target_val_parent_prob.detach()\n",
    "\n",
    "                else:\n",
    "                    val_leaf_pred_total = torch.cat((val_leaf_pred_total,predicted_leaf_val_per_epoch.detach()),0)\n",
    "                    y_leaf_val_total = torch.cat((y_leaf_val_total,y_val_batch_leaf.detach()),0)\n",
    "                    val_batch_accuracy_internal = torch.cat((val_batch_accuracy_internal,val_batch_accuracy.reshape(1)),0)\n",
    "                    val_total_number_of_cells = torch.cat((val_total_number_of_cells,torch.tensor(val_batch_number_of_cells).reshape(1)),0)\n",
    "                    val_parent_pred_total = torch.cat((val_parent_pred_total,output_val_parent_prob.detach()),1)\n",
    "                    val_parent_true_total = torch.cat((val_parent_true_total,target_val_parent_prob.detach()),1)\n",
    "\n",
    "            # save total accuracy\n",
    "            #accuracy_val_hist.append(correct_val / y_val_length * 100.)\n",
    "            \n",
    "            val_total_number_of_cells = val_total_number_of_cells.to(device)\n",
    "            \n",
    "            correct_val_leaf = (val_leaf_pred_total == y_leaf_val_total).sum().item()\n",
    "            accuracy_val_leaf_hist.append(correct_val_leaf / val_leaf_pred_total.shape[0] * 100.)\n",
    "\n",
    "            correct_val_internal = (val_batch_accuracy_internal * val_total_number_of_cells).sum()\n",
    "            accuracy_val_internal = (correct_val_internal / val_total_number_of_cells.sum() * 100.).item()\n",
    "            accuracy_val_internal_hist.append(accuracy_val_internal)\n",
    "\n",
    "            \n",
    "            # save loss\n",
    "            loss_val_hist.append(loss_val.item())\n",
    "            loss_val_leaf_hist.append(loss_val_leafs.item())\n",
    "            loss_val_parents_hist.append(loss_val_parents.item())\n",
    "            #loss_val_internal_hist.append(loss_val_internal.item())\n",
    "            \n",
    "            # save f1 score\n",
    "            # use average = weighted to account for label imbalance\n",
    "            # use zero_division = np.nan to exclude labels where all \n",
    "            #       predictions and labels are negative\n",
    "            f1_val_leaf_score = f1_score(y_leaf_val_total.cpu(),val_leaf_pred_total.cpu(),\n",
    "                                    labels=leaf_label_list,average='weighted',zero_division=np.nan)\n",
    "            f1_score_val_leaf.append(f1_val_leaf_score)\n",
    "\n",
    "            \n",
    "            # for the F1 score for the internal nodes, we need to first turn the probabilities\n",
    "            # into predictions using our threshold value\n",
    "            val_parent_pred_total_thresholded = torch.where(val_parent_pred_total > threshold,1.0,0.0)\n",
    "\n",
    "            f1_val_parent_score = f1_score( val_parent_true_total.cpu(),val_parent_pred_total_thresholded.cpu(),\n",
    "                                        average='weighted',zero_division=np.nan)\n",
    "            f1_score_val_parent.append(f1_val_parent_score)\n",
    "            #torch.save(val_parent_true_total.cpu(),'val_parent_true_total_20Feb.pt')\n",
    "            #torch.save(val_parent_pred_total_thresholded.cpu(),'val_parent_pred_total_thresholded_20Feb.pt')\n",
    "\n",
    "            \n",
    "            # check if best model\n",
    "            if accuracy_val_leaf_hist[-1] > best_accuracy:\n",
    "                best_acc = accuracy_val_leaf_hist[-1]\n",
    "                best_state_dict = copy.deepcopy(clf.state_dict())\n",
    "                best_output = copy.deepcopy(outputs_val)\n",
    "            \n",
    "        if (epoch + 1) % 1 == 0 or epoch == 0:\n",
    "            print(f'[{epoch + 1}] Training Accuracy: {accuracy_train_leaf_hist[-1]:.3f} Validation Accuracy: {accuracy_val_leaf_hist[-1]:.3f}')\n",
    "            print(f'Train Loss: {loss_train.item():.4f} Validation Loss: {loss_val.item():.4f}')\n",
    "            #print(f'Internal Loss: {loss_val_internal.item():.4f}')\n",
    "            #print('learning rate:', optimizer.param_groups[0][\"lr\"])\n",
    "        #end_epoch = time.time()\n",
    "        #print('epoch timer', end_epoch-start_epoch)\n",
    "\n",
    "    print(f'Best Validation Accuracy: {best_acc:.3f}')\n",
    "    \n",
    "    # build dictionary to return values\n",
    "    marginalization_dict = {}\n",
    "    marginalization_dict['accuracy_train_leaf_hist'] = accuracy_train_leaf_hist\n",
    "    marginalization_dict['accuracy_train_internal_hist'] = accuracy_train_internal_hist\n",
    "    \n",
    "    marginalization_dict['loss_train_hist'] = loss_train_hist\n",
    "    \n",
    "    marginalization_dict['loss_train_leaf_hist'] = loss_train_leaf_hist\n",
    "    marginalization_dict['loss_train_internal_hist'] = loss_train_parents_hist\n",
    "\n",
    "    marginalization_dict['accuracy_val_leaf_hist'] = accuracy_val_leaf_hist\n",
    "    marginalization_dict['accuracy_val_internal_hist'] = accuracy_val_internal_hist\n",
    "\n",
    "    marginalization_dict['loss_val_hist'] = loss_val_hist\n",
    "\n",
    "    marginalization_dict['loss_val_leaf_hist'] = loss_val_leaf_hist\n",
    "    marginalization_dict['loss_val_internal_hist'] = loss_val_parents_hist\n",
    "    \n",
    "    marginalization_dict['f1_score_train_leaf'] = f1_score_train_leaf\n",
    "    marginalization_dict['f1_score_val_leaf'] = f1_score_val_leaf\n",
    "    \n",
    "    marginalization_dict['f1_score_train_internal'] = f1_score_train_parent\n",
    "    marginalization_dict['f1_score_val_internal'] = f1_score_val_parent\n",
    "\n",
    "    marginalization_dict['best_output'] = best_output\n",
    "    marginalization_dict['best_state_dict'] = best_state_dict\n",
    "\n",
    "\n",
    "    return marginalization_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0768f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 88 leafs and 55 parents.\n",
      "Number of training batches is 266.21\n",
      "Number of validation batches is 66.55\n",
      "Prediction threshold for internal nodes is 0.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction threshold for internal nodes is\u001b[39m\u001b[38;5;124m'\u001b[39m, threshold)\n\u001b[1;32m     31\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 33\u001b[0m marginalization_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmarginalization_classification_manual_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                                                   \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43montology_leaf_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43minternal_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmapping_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43montology_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_parent_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoding_mapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     40\u001b[0m time_minutes \u001b[38;5;241m=\u001b[39m (end\u001b[38;5;241m-\u001b[39mstart)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60.\u001b[39m\n",
      "Cell \u001b[0;32mIn[68], line 236\u001b[0m, in \u001b[0;36mmarginalization_classification_manual_batch\u001b[0;34m(train_dataloader, val_dataloader, num_epochs, ontology_leaf_df, batch_size, internal_values, mapping_dict, ontology_df, threshold, cell_parent_mask, encoding_mapper)\u001b[0m\n\u001b[1;32m    230\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# make predictions for this batch\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m#if epoch == 0:\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m#    outputs_train = clf_nosoftmax(X_batch.float()) # might need to change to X_train.float()\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m#else:\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m outputs_train \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# might need to change to X_train.float()\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m######\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# create mask to separate leaf and internal nodes\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m######\u001b[39;00m\n\u001b[1;32m    241\u001b[0m output_train_leaf \u001b[38;5;241m=\u001b[39m outputs_train[y_batch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[67], line 11\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "number_of_leafs = len(leaf_values)\n",
    "number_of_parents = len(internal_values)\n",
    "\n",
    "print('There are', number_of_leafs, 'leafs and', number_of_parents, 'parents.')\n",
    "\n",
    "print('Number of training batches is {:.2f}'.format(experiment_datapipe.shape[0]*train_percent/batch_size))\n",
    "print('Number of validation batches is {:.2f}'.format(experiment_datapipe.shape[0]*val_percent/batch_size))\n",
    "\n",
    "# create dataframe that only includes leaf nodes\n",
    "ontology_leaf_df = ontology_df[leaf_values]\n",
    "\n",
    "# Create dictionary to map between two different types of encoded values\n",
    "# get the encoder from the datapipe\n",
    "cell_type_encoder = experiment_datapipe.obs_encoders[\"cell_type_ontology_term_id\"]\n",
    "\n",
    "# build the dictionary of encoded values from the datapipe\n",
    "encoder_mapping_dict = dict(zip(cell_type_encoder.classes_,cell_type_encoder.transform(cell_type_encoder.classes_)))\n",
    "\n",
    "# build the dictionary mapping from encoder_mapping_dict (keys) to mapping_dict (values)\n",
    "encoding_mapper = {}\n",
    "for cell_term in encoder_mapping_dict.keys():\n",
    "    encoding_mapper[encoder_mapping_dict[cell_term]] = mapping_dict[cell_term]\n",
    "\n",
    "\n",
    "# set the prediction threshold for internal nodes\n",
    "threshold = 0.8\n",
    "print('Prediction threshold for internal nodes is', threshold)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "marginalization_dict = marginalization_classification_manual_batch(train_dataloader,val_dataloader,\n",
    "                                                                   num_epochs, ontology_leaf_df, batch_size,\n",
    "                                                                  internal_values,mapping_dict,\n",
    "                                                                  ontology_df,threshold, cell_parent_mask,encoding_mapper)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "time_minutes = (end-start)/60.\n",
    "time_hours = (end-start)/3600.\n",
    "\n",
    "print(f'Run time for {num_epochs} epochs was {time_minutes:.2f} minutes ({time_hours:.2f} hours)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f85b891f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "568ca2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c21039bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CL:0000037': 0,\n",
       " 'CL:0000038': 1,\n",
       " 'CL:0000049': 2,\n",
       " 'CL:0000050': 3,\n",
       " 'CL:0000051': 4,\n",
       " 'CL:0000081': 5,\n",
       " 'CL:0000084': 6,\n",
       " 'CL:0000091': 7,\n",
       " 'CL:0000092': 8,\n",
       " 'CL:0000094': 9,\n",
       " 'CL:0000097': 10,\n",
       " 'CL:0000129': 11,\n",
       " 'CL:0000232': 12,\n",
       " 'CL:0000233': 13,\n",
       " 'CL:0000235': 14,\n",
       " 'CL:0000236': 15,\n",
       " 'CL:0000451': 16,\n",
       " 'CL:0000453': 17,\n",
       " 'CL:0000492': 18,\n",
       " 'CL:0000542': 19,\n",
       " 'CL:0000547': 20,\n",
       " 'CL:0000556': 21,\n",
       " 'CL:0000557': 22,\n",
       " 'CL:0000559': 23,\n",
       " 'CL:0000576': 24,\n",
       " 'CL:0000583': 25,\n",
       " 'CL:0000595': 26,\n",
       " 'CL:0000623': 27,\n",
       " 'CL:0000624': 28,\n",
       " 'CL:0000625': 29,\n",
       " 'CL:0000738': 30,\n",
       " 'CL:0000763': 31,\n",
       " 'CL:0000764': 32,\n",
       " 'CL:0000765': 33,\n",
       " 'CL:0000766': 34,\n",
       " 'CL:0000767': 35,\n",
       " 'CL:0000771': 36,\n",
       " 'CL:0000775': 37,\n",
       " 'CL:0000776': 38,\n",
       " 'CL:0000782': 39,\n",
       " 'CL:0000784': 40,\n",
       " 'CL:0000785': 41,\n",
       " 'CL:0000786': 42,\n",
       " 'CL:0000787': 43,\n",
       " 'CL:0000788': 44,\n",
       " 'CL:0000789': 45,\n",
       " 'CL:0000791': 46,\n",
       " 'CL:0000794': 47,\n",
       " 'CL:0000798': 48,\n",
       " 'CL:0000800': 49,\n",
       " 'CL:0000807': 50,\n",
       " 'CL:0000808': 51,\n",
       " 'CL:0000809': 52,\n",
       " 'CL:0000810': 53,\n",
       " 'CL:0000811': 54,\n",
       " 'CL:0000813': 55,\n",
       " 'CL:0000814': 56,\n",
       " 'CL:0000815': 57,\n",
       " 'CL:0000816': 58,\n",
       " 'CL:0000817': 59,\n",
       " 'CL:0000818': 60,\n",
       " 'CL:0000823': 61,\n",
       " 'CL:0000826': 62,\n",
       " 'CL:0000836': 63,\n",
       " 'CL:0000837': 64,\n",
       " 'CL:0000838': 65,\n",
       " 'CL:0000839': 66,\n",
       " 'CL:0000841': 67,\n",
       " 'CL:0000844': 68,\n",
       " 'CL:0000860': 69,\n",
       " 'CL:0000861': 70,\n",
       " 'CL:0000863': 71,\n",
       " 'CL:0000875': 72,\n",
       " 'CL:0000878': 73,\n",
       " 'CL:0000890': 74,\n",
       " 'CL:0000893': 75,\n",
       " 'CL:0000894': 76,\n",
       " 'CL:0000895': 77,\n",
       " 'CL:0000896': 78,\n",
       " 'CL:0000897': 79,\n",
       " 'CL:0000898': 80,\n",
       " 'CL:0000899': 81,\n",
       " 'CL:0000900': 82,\n",
       " 'CL:0000903': 83,\n",
       " 'CL:0000904': 84,\n",
       " 'CL:0000905': 85,\n",
       " 'CL:0000906': 86,\n",
       " 'CL:0000907': 87,\n",
       " 'CL:0000908': 88,\n",
       " 'CL:0000909': 89,\n",
       " 'CL:0000910': 90,\n",
       " 'CL:0000912': 91,\n",
       " 'CL:0000913': 92,\n",
       " 'CL:0000915': 93,\n",
       " 'CL:0000921': 94,\n",
       " 'CL:0000934': 95,\n",
       " 'CL:0000936': 96,\n",
       " 'CL:0000938': 97,\n",
       " 'CL:0000939': 98,\n",
       " 'CL:0000940': 99,\n",
       " 'CL:0000970': 100,\n",
       " 'CL:0000972': 101,\n",
       " 'CL:0000979': 102,\n",
       " 'CL:0000980': 103,\n",
       " 'CL:0000985': 104,\n",
       " 'CL:0000987': 105,\n",
       " 'CL:0000990': 106,\n",
       " 'CL:0001029': 107,\n",
       " 'CL:0001043': 108,\n",
       " 'CL:0001044': 109,\n",
       " 'CL:0001049': 110,\n",
       " 'CL:0001050': 111,\n",
       " 'CL:0001054': 112,\n",
       " 'CL:0001056': 113,\n",
       " 'CL:0001057': 114,\n",
       " 'CL:0001058': 115,\n",
       " 'CL:0001062': 116,\n",
       " 'CL:0001065': 117,\n",
       " 'CL:0001071': 118,\n",
       " 'CL:0001078': 119,\n",
       " 'CL:0001082': 120,\n",
       " 'CL:0001203': 121,\n",
       " 'CL:0002038': 122,\n",
       " 'CL:0002045': 123,\n",
       " 'CL:0002046': 124,\n",
       " 'CL:0002057': 125,\n",
       " 'CL:0002117': 126,\n",
       " 'CL:0002343': 127,\n",
       " 'CL:0002355': 128,\n",
       " 'CL:0002393': 129,\n",
       " 'CL:0002394': 130,\n",
       " 'CL:0002396': 131,\n",
       " 'CL:0002397': 132,\n",
       " 'CL:0002399': 133,\n",
       " 'CL:0002419': 134,\n",
       " 'CL:0002425': 135,\n",
       " 'CL:0002489': 136,\n",
       " 'CL:0002496': 137,\n",
       " 'CL:0002677': 138,\n",
       " 'CL:0002678': 139,\n",
       " 'CL:1001603': 140,\n",
       " 'CL:2000055': 141,\n",
       " 'CL:3000001': 142}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "687a4ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CL:0000763': -9999,\n",
       " 'CL:0000542': -9998,\n",
       " 'CL:0000097': 0,\n",
       " 'CL:0002046': 1,\n",
       " 'CL:0000817': 2,\n",
       " 'CL:0000051': 3,\n",
       " 'CL:0000826': -9997,\n",
       " 'CL:0001029': 4,\n",
       " 'CL:0000990': -9996,\n",
       " 'CL:0000785': -9995,\n",
       " 'CL:0000816': 5,\n",
       " 'CL:0000786': -9994,\n",
       " 'CL:0000784': -9993,\n",
       " 'CL:0000557': 6,\n",
       " 'CL:0000084': -9992,\n",
       " 'CL:0000814': -9991,\n",
       " 'CL:0000837': -9990,\n",
       " 'CL:0000037': 7,\n",
       " 'CL:0000576': -9989,\n",
       " 'CL:0000050': 8,\n",
       " 'CL:0000129': 9,\n",
       " 'CL:0000815': -9988,\n",
       " 'CL:0000912': 10,\n",
       " 'CL:0000940': 11,\n",
       " 'CL:0000623': -9987,\n",
       " 'CL:0000899': 12,\n",
       " 'CL:0000798': -9986,\n",
       " 'CL:0000235': -9985,\n",
       " 'CL:0000775': -9984,\n",
       " 'CL:0000236': -9983,\n",
       " 'CL:0000453': 13,\n",
       " 'CL:0002343': 14,\n",
       " 'CL:0001078': 15,\n",
       " 'CL:3000001': 16,\n",
       " 'CL:0000451': -9982,\n",
       " 'CL:0000094': -9981,\n",
       " 'CL:0000738': -9980,\n",
       " 'CL:0000878': -9979,\n",
       " 'CL:0000972': -9978,\n",
       " 'CL:0000788': 17,\n",
       " 'CL:0000985': 18,\n",
       " 'CL:0000987': 19,\n",
       " 'CL:0000970': 20,\n",
       " 'CL:0000913': 21,\n",
       " 'CL:0000492': -9977,\n",
       " 'CL:0000624': -9976,\n",
       " 'CL:0000909': -9975,\n",
       " 'CL:0000896': -9974,\n",
       " 'CL:0000906': -9973,\n",
       " 'CL:0000905': 22,\n",
       " 'CL:0000890': 23,\n",
       " 'CL:0000860': -9972,\n",
       " 'CL:0000875': -9971,\n",
       " 'CL:0000782': -9970,\n",
       " 'CL:0000863': 24,\n",
       " 'CL:0000767': 25,\n",
       " 'CL:0000583': 26,\n",
       " 'CL:0000625': -9969,\n",
       " 'CL:0000861': -9968,\n",
       " 'CL:1001603': -9967,\n",
       " 'CL:0002399': 27,\n",
       " 'CL:0001071': -9966,\n",
       " 'CL:0000766': -9965,\n",
       " 'CL:0000765': 28,\n",
       " 'CL:0002496': -9964,\n",
       " 'CL:0000898': -9963,\n",
       " 'CL:0001065': -9962,\n",
       " 'CL:0000903': 29,\n",
       " 'CL:0000787': -9961,\n",
       " 'CL:0000813': -9960,\n",
       " 'CL:0000232': -9959,\n",
       " 'CL:0000910': 30,\n",
       " 'CL:0000838': -9958,\n",
       " 'CL:0000839': -9957,\n",
       " 'CL:0000038': 31,\n",
       " 'CL:0000547': 32,\n",
       " 'CL:0002355': 33,\n",
       " 'CL:0002045': 34,\n",
       " 'CL:0000559': 35,\n",
       " 'CL:0001054': -9956,\n",
       " 'CL:0000836': 36,\n",
       " 'CL:0000556': 37,\n",
       " 'CL:0000092': 38,\n",
       " 'CL:0000938': 39,\n",
       " 'CL:0000936': 40,\n",
       " 'CL:0000049': 41,\n",
       " 'CL:0000771': 42,\n",
       " 'CL:0002419': -9955,\n",
       " 'CL:0001082': -9954,\n",
       " 'CL:0002489': -9953,\n",
       " 'CL:0000809': 43,\n",
       " 'CL:0002425': 44,\n",
       " 'CL:0000915': 45,\n",
       " 'CL:0000897': -9952,\n",
       " 'CL:0000789': -9951,\n",
       " 'CL:0000904': 46,\n",
       " 'CL:0000900': 47,\n",
       " 'CL:0002396': 48,\n",
       " 'CL:0000895': 49,\n",
       " 'CL:0000934': 50,\n",
       " 'CL:0000907': 51,\n",
       " 'CL:0002677': 52,\n",
       " 'CL:0000980': 53,\n",
       " 'CL:0002678': 54,\n",
       " 'CL:0000233': 55,\n",
       " 'CL:0001057': 56,\n",
       " 'CL:0000091': 57,\n",
       " 'CL:0000939': 58,\n",
       " 'CL:0001203': -9950,\n",
       " 'CL:0002038': 59,\n",
       " 'CL:0000764': -9949,\n",
       " 'CL:0001062': 60,\n",
       " 'CL:0001056': -9948,\n",
       " 'CL:0000844': 61,\n",
       " 'CL:0001044': 62,\n",
       " 'CL:0000979': 63,\n",
       " 'CL:0001050': 64,\n",
       " 'CL:0002117': 65,\n",
       " 'CL:0002393': 66,\n",
       " 'CL:0000081': -9947,\n",
       " 'CL:0000595': 67,\n",
       " 'CL:0000810': 68,\n",
       " 'CL:0000811': 69,\n",
       " 'CL:0002394': 70,\n",
       " 'CL:2000055': 71,\n",
       " 'CL:0000908': 72,\n",
       " 'CL:0000921': 73,\n",
       " 'CL:0000841': 74,\n",
       " 'CL:0000794': 75,\n",
       " 'CL:0000807': 76,\n",
       " 'CL:0000894': 77,\n",
       " 'CL:0000808': 78,\n",
       " 'CL:0000823': 79,\n",
       " 'CL:0000893': -9946,\n",
       " 'CL:0002057': 80,\n",
       " 'CL:0000791': -9945,\n",
       " 'CL:0002397': 81,\n",
       " 'CL:0000800': 82,\n",
       " 'CL:0001058': 83,\n",
       " 'CL:0000818': 84,\n",
       " 'CL:0001043': 85,\n",
       " 'CL:0001049': 86,\n",
       " 'CL:0000776': 87}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d98802bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be27cda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-9999: 31,\n",
       " -9998: 19,\n",
       " 0: 10,\n",
       " 1: 124,\n",
       " 2: 59,\n",
       " 3: 4,\n",
       " -9997: 62,\n",
       " 4: 107,\n",
       " -9996: 106,\n",
       " -9995: 41,\n",
       " 5: 58,\n",
       " -9994: 42,\n",
       " -9993: 40,\n",
       " 6: 22,\n",
       " -9992: 6,\n",
       " -9991: 56,\n",
       " -9990: 64,\n",
       " 7: 0,\n",
       " -9989: 24,\n",
       " 8: 3,\n",
       " 9: 11,\n",
       " -9988: 57,\n",
       " 10: 91,\n",
       " 11: 99,\n",
       " -9987: 27,\n",
       " 12: 81,\n",
       " -9986: 48,\n",
       " -9985: 14,\n",
       " -9984: 37,\n",
       " -9983: 15,\n",
       " 13: 17,\n",
       " 14: 127,\n",
       " 15: 119,\n",
       " 16: 142,\n",
       " -9982: 16,\n",
       " -9981: 9,\n",
       " -9980: 30,\n",
       " -9979: 73,\n",
       " -9978: 101,\n",
       " 17: 44,\n",
       " 18: 104,\n",
       " 19: 105,\n",
       " 20: 100,\n",
       " 21: 92,\n",
       " -9977: 18,\n",
       " -9976: 28,\n",
       " -9975: 89,\n",
       " -9974: 78,\n",
       " -9973: 86,\n",
       " 22: 85,\n",
       " 23: 74,\n",
       " -9972: 69,\n",
       " -9971: 72,\n",
       " -9970: 39,\n",
       " 24: 71,\n",
       " 25: 35,\n",
       " 26: 25,\n",
       " -9969: 29,\n",
       " -9968: 70,\n",
       " -9967: 140,\n",
       " 27: 133,\n",
       " -9966: 118,\n",
       " -9965: 34,\n",
       " 28: 33,\n",
       " -9964: 137,\n",
       " -9963: 80,\n",
       " -9962: 117,\n",
       " 29: 83,\n",
       " -9961: 43,\n",
       " -9960: 55,\n",
       " -9959: 12,\n",
       " 30: 90,\n",
       " -9958: 65,\n",
       " -9957: 66,\n",
       " 31: 1,\n",
       " 32: 20,\n",
       " 33: 128,\n",
       " 34: 123,\n",
       " 35: 23,\n",
       " -9956: 112,\n",
       " 36: 63,\n",
       " 37: 21,\n",
       " 38: 8,\n",
       " 39: 97,\n",
       " 40: 96,\n",
       " 41: 2,\n",
       " 42: 36,\n",
       " -9955: 134,\n",
       " -9954: 120,\n",
       " -9953: 136,\n",
       " 43: 52,\n",
       " 44: 135,\n",
       " 45: 93,\n",
       " -9952: 79,\n",
       " -9951: 45,\n",
       " 46: 84,\n",
       " 47: 82,\n",
       " 48: 131,\n",
       " 49: 77,\n",
       " 50: 95,\n",
       " 51: 87,\n",
       " 52: 138,\n",
       " 53: 103,\n",
       " 54: 139,\n",
       " 55: 13,\n",
       " 56: 114,\n",
       " 57: 7,\n",
       " 58: 98,\n",
       " -9950: 121,\n",
       " 59: 122,\n",
       " -9949: 32,\n",
       " 60: 116,\n",
       " -9948: 113,\n",
       " 61: 68,\n",
       " 62: 109,\n",
       " 63: 102,\n",
       " 64: 111,\n",
       " 65: 126,\n",
       " 66: 129,\n",
       " -9947: 5,\n",
       " 67: 26,\n",
       " 68: 53,\n",
       " 69: 54,\n",
       " 70: 130,\n",
       " 71: 141,\n",
       " 72: 88,\n",
       " 73: 94,\n",
       " 74: 67,\n",
       " 75: 47,\n",
       " 76: 50,\n",
       " 77: 76,\n",
       " 78: 51,\n",
       " 79: 61,\n",
       " -9946: 75,\n",
       " 80: 125,\n",
       " -9945: 46,\n",
       " 81: 132,\n",
       " 82: 49,\n",
       " 83: 115,\n",
       " 84: 60,\n",
       " 85: 108,\n",
       " 86: 110,\n",
       " 87: 38}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd2142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d75f938d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CL:0000037', 'CL:0000038', 'CL:0000049', 'CL:0000050',\n",
       "       'CL:0000051', 'CL:0000081', 'CL:0000084', 'CL:0000091',\n",
       "       'CL:0000092', 'CL:0000094', 'CL:0000097', 'CL:0000129',\n",
       "       'CL:0000232', 'CL:0000233', 'CL:0000235', 'CL:0000236',\n",
       "       'CL:0000451', 'CL:0000453', 'CL:0000492', 'CL:0000542',\n",
       "       'CL:0000547', 'CL:0000556', 'CL:0000557', 'CL:0000559',\n",
       "       'CL:0000576', 'CL:0000583', 'CL:0000595', 'CL:0000623',\n",
       "       'CL:0000624', 'CL:0000625', 'CL:0000738', 'CL:0000763',\n",
       "       'CL:0000764', 'CL:0000765', 'CL:0000766', 'CL:0000767',\n",
       "       'CL:0000771', 'CL:0000775', 'CL:0000776', 'CL:0000782',\n",
       "       'CL:0000784', 'CL:0000785', 'CL:0000786', 'CL:0000787',\n",
       "       'CL:0000788', 'CL:0000789', 'CL:0000791', 'CL:0000794',\n",
       "       'CL:0000798', 'CL:0000800', 'CL:0000807', 'CL:0000808',\n",
       "       'CL:0000809', 'CL:0000810', 'CL:0000811', 'CL:0000813',\n",
       "       'CL:0000814', 'CL:0000815', 'CL:0000816', 'CL:0000817',\n",
       "       'CL:0000818', 'CL:0000823', 'CL:0000826', 'CL:0000836',\n",
       "       'CL:0000837', 'CL:0000838', 'CL:0000839', 'CL:0000841',\n",
       "       'CL:0000844', 'CL:0000860', 'CL:0000861', 'CL:0000863',\n",
       "       'CL:0000875', 'CL:0000878', 'CL:0000890', 'CL:0000893',\n",
       "       'CL:0000894', 'CL:0000895', 'CL:0000896', 'CL:0000897',\n",
       "       'CL:0000898', 'CL:0000899', 'CL:0000900', 'CL:0000903',\n",
       "       'CL:0000904', 'CL:0000905', 'CL:0000906', 'CL:0000907',\n",
       "       'CL:0000908', 'CL:0000909', 'CL:0000910', 'CL:0000912',\n",
       "       'CL:0000913', 'CL:0000915', 'CL:0000921', 'CL:0000934',\n",
       "       'CL:0000936', 'CL:0000938', 'CL:0000939', 'CL:0000940',\n",
       "       'CL:0000970', 'CL:0000972', 'CL:0000979', 'CL:0000980',\n",
       "       'CL:0000985', 'CL:0000987', 'CL:0000990', 'CL:0001029',\n",
       "       'CL:0001043', 'CL:0001044', 'CL:0001049', 'CL:0001050',\n",
       "       'CL:0001054', 'CL:0001056', 'CL:0001057', 'CL:0001058',\n",
       "       'CL:0001062', 'CL:0001065', 'CL:0001071', 'CL:0001078',\n",
       "       'CL:0001082', 'CL:0001203', 'CL:0002038', 'CL:0002045',\n",
       "       'CL:0002046', 'CL:0002057', 'CL:0002117', 'CL:0002343',\n",
       "       'CL:0002355', 'CL:0002393', 'CL:0002394', 'CL:0002396',\n",
       "       'CL:0002397', 'CL:0002399', 'CL:0002419', 'CL:0002425',\n",
       "       'CL:0002489', 'CL:0002496', 'CL:0002677', 'CL:0002678',\n",
       "       'CL:1001603', 'CL:2000055', 'CL:3000001'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13d65d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LabelEncoder in module sklearn.preprocessing._label object:\n",
      "\n",
      "class LabelEncoder(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  Encode target labels with value between 0 and n_classes-1.\n",
      " |  \n",
      " |  This transformer should be used to encode target values, *i.e.* `y`, and\n",
      " |  not the input `X`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_targets>`.\n",
      " |  \n",
      " |  .. versionadded:: 0.12\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      Holds the label for each class.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  OrdinalEncoder : Encode categorical features using an ordinal encoding\n",
      " |      scheme.\n",
      " |  OneHotEncoder : Encode categorical features as a one-hot numeric array.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  `LabelEncoder` can be used to normalize labels.\n",
      " |  \n",
      " |  >>> from sklearn import preprocessing\n",
      " |  >>> le = preprocessing.LabelEncoder()\n",
      " |  >>> le.fit([1, 2, 2, 6])\n",
      " |  LabelEncoder()\n",
      " |  >>> le.classes_\n",
      " |  array([1, 2, 6])\n",
      " |  >>> le.transform([1, 1, 2, 6])\n",
      " |  array([0, 0, 1, 2]...)\n",
      " |  >>> le.inverse_transform([0, 0, 1, 2])\n",
      " |  array([1, 1, 2, 6])\n",
      " |  \n",
      " |  It can also be used to transform non-numerical labels (as long as they are\n",
      " |  hashable and comparable) to numerical labels.\n",
      " |  \n",
      " |  >>> le = preprocessing.LabelEncoder()\n",
      " |  >>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
      " |  LabelEncoder()\n",
      " |  >>> list(le.classes_)\n",
      " |  ['amsterdam', 'paris', 'tokyo']\n",
      " |  >>> le.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
      " |  array([2, 2, 1]...)\n",
      " |  >>> list(le.inverse_transform([2, 2, 1]))\n",
      " |  ['tokyo', 'tokyo', 'paris']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LabelEncoder\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  fit(self, y)\n",
      " |      Fit label encoder.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |          Fitted label encoder.\n",
      " |  \n",
      " |  fit_transform(self, y)\n",
      " |      Fit label encoder and return encoded labels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Encoded labels.\n",
      " |  \n",
      " |  inverse_transform(self, y)\n",
      " |      Transform labels back to original encoding.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          Original encoding.\n",
      " |  \n",
      " |  transform(self, y)\n",
      " |      Transform labels to normalized encoding.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Labels as normalized encodings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |      \n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |      \n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from builtins.type\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cell_type_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47897d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f58d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e500d1da",
   "metadata": {},
   "source": [
    "## From The CZI tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483cfde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = census[\"census_data\"][\"homo_sapiens\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ff18319",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_datapipe = census_ml.ExperimentDataPipe(\n",
    "    experiment,\n",
    "    measurement_name=\"RNA\",\n",
    "    X_name=\"raw\",\n",
    "    obs_query=soma.AxisQuery(value_filter=\"tissue_general == 'tongue' and is_primary_data == True\"),\n",
    "    obs_column_names=[\"cell_type\"],\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    soma_chunk_size=10_000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8414ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15020, 60664)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_datapipe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27802bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapipe, test_datapipe = experiment_datapipe.random_split(weights={\"train\": 0.8, \"test\": 0.2}, seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c03005b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dataloader = census_ml.experiment_dataloader(train_datapipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "591f903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()  # noqa: UP008\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09072f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch = batch\n",
    "\n",
    "        X_batch = X_batch.float().to(device)\n",
    "\n",
    "        # Perform prediction\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # Determine the predicted label\n",
    "        probabilities = torch.nn.functional.softmax(outputs, 1)\n",
    "        predictions = torch.argmax(probabilities, axis=1)\n",
    "\n",
    "        # Compute the loss and perform back propagation\n",
    "\n",
    "        # Exclude the cell_type labels, which are in the second column\n",
    "        y_batch = y_batch[:, 1]\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        train_correct += (predictions == y_batch).sum().item()\n",
    "        train_total += len(predictions)\n",
    "\n",
    "        loss = loss_fn(outputs, y_batch.long())\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= train_total\n",
    "    train_accuracy = train_correct / train_total\n",
    "    return train_loss, train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dac0b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0185056 Accuracy 0.2145\n",
      "Epoch 2: Train Loss: 0.0162072 Accuracy 0.2665\n",
      "Epoch 3: Train Loss: 0.0149051 Accuracy 0.3136\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# The size of the input dimension is the number of genes\n",
    "input_dim = experiment_datapipe.shape[1]\n",
    "\n",
    "# The size of the output dimension is the number of distinct cell_type values\n",
    "cell_type_encoder = experiment_datapipe.obs_encoders[\"cell_type\"]\n",
    "output_dim = len(cell_type_encoder.classes_)\n",
    "\n",
    "model = LogisticRegression(input_dim, output_dim).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-05)\n",
    "\n",
    "for epoch in range(3):\n",
    "    train_loss, train_accuracy = train_epoch(model, experiment_dataloader, loss_fn, optimizer, device)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.7f} Accuracy {train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9d6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dataloader = census_ml.experiment_dataloader(test_datapipe)\n",
    "X_batch, y_batch = next(iter(experiment_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f0a8a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1,\n",
       "        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 7, 1, 1, 1, 1, 1, 7,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 7, 7, 1, 1, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "model.to(device)\n",
    "outputs = model(X_batch.to(device))\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(outputs, 1)\n",
    "predictions = torch.argmax(probabilities, axis=1)\n",
    "\n",
    "display(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82ac91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e3a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a857404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cae82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8bc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f489a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ddfd0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "census = cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f4df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with cellxgene_census.open_soma(uri = \"/scratch/welchjd_root/welchjd99/fujoshua/soma\") as census:\n",
    "    cell_metadata = census[\"census_data\"][\"homo_sapiens\"].obs.read(\n",
    "        value_filter = \"sex == 'female' and cell_type in ['microglial cell', 'neuron']\",\n",
    "        column_names = [\"assay\", \"cell_type\", \"tissue\", \"tissue_general\", \"suspension_type\", \"disease\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1309ae24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tiledbsoma._read_iters.TableReadIter at 0x152b7f2edff0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302a947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf15d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment 'file:///scratch/welchjd_root/welchjd99/fujoshua/soma/census_data/homo_sapiens' (CLOSED for 'r')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census[\"census_data\"][\"homo_sapiens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce8ff43",
   "metadata": {},
   "outputs": [
    {
     "ename": "TileDBError",
     "evalue": "[TileDB::Array] Error: Cannot get array schema; Array is not open",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTileDBError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcensus\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcensus_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhomo_sapiens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_filter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex == \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfemale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m and cell_type in [\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmicroglial cell\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneuron\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcell_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtissue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtissue_general\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuspension_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisease\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cell_classification/env/lib/python3.10/site-packages/tiledbsoma/_dataframe.py:359\u001b[0m, in \u001b[0;36mDataFrame.read\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    349\u001b[0m sr \u001b[38;5;241m=\u001b[39m clib\u001b[38;5;241m.\u001b[39mSOMADataFrame\u001b[38;5;241m.\u001b[39mopen(\n\u001b[1;32m    350\u001b[0m     uri\u001b[38;5;241m=\u001b[39mhandle\u001b[38;5;241m.\u001b[39muri,\n\u001b[1;32m    351\u001b[0m     mode\u001b[38;5;241m=\u001b[39mclib\u001b[38;5;241m.\u001b[39mOpenMode\u001b[38;5;241m.\u001b[39mread,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     timestamp\u001b[38;5;241m=\u001b[39mhandle\u001b[38;5;241m.\u001b[39mtimestamp \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, handle\u001b[38;5;241m.\u001b[39mtimestamp),\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value_filter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     sr\u001b[38;5;241m.\u001b[39mset_condition(QueryCondition(value_filter), \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_reader_coords(sr, coords)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# # TODO: batch_size\u001b[39;00m\n",
      "\u001b[0;31mTileDBError\u001b[0m: [TileDB::Array] Error: Cannot get array schema; Array is not open"
     ]
    }
   ],
   "source": [
    "census[\"census_data\"][\"homo_sapiens\"].obs.read(\n",
    "        value_filter = \"sex == 'female' and cell_type in ['microglial cell', 'neuron']\",\n",
    "        column_names = [\"assay\", \"cell_type\", \"tissue\", \"tissue_general\", \"suspension_type\", \"disease\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1860a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
